<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Redis"><meta property="og:title" content="Redis" />
<meta property="og:description" content="Redis 线程模型 Redis 在处理网络请求是使用单线程模型，并通过 IO 多路复用来提高并发。但是在其他模块，比如：持久化，会使用多个线程。
Redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket ，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。
文件事件处理器的结构包含 4 个部分：
 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）  多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket ，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket ，根据 socket 的事件类型交给对应的事件处理器进行处理。
客户端与 Redis 的一次通信过程：
为啥 Redis 单线程模型也能效率这么高？  纯内存操作 核心是基于非阻塞的 IO 多路复用机制 单线程反而避免了多线程的频繁上下文切换问题  持久化 RDB RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化。
 RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，非常适合做冷备 RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。 一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟的数据。 RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。  AOF AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hadyang.github.io/interview/docs/basic/database/redis/" />
<meta property="article:published_time" content="2019-08-21T11:00:41+08:00" />
<meta property="article:modified_time" content="2020-03-10T13:19:07+08:00" />
<title>Redis | Interview</title>
<link rel="icon" href="/interview/favicon.png" type="image/x-icon">


<link rel="stylesheet" href="/interview/book.min.edc993575be58655f3e49634e3ca6db09cc38ac9aa03ecdbe81d941636e35273.css" integrity="sha256-7cmTV1vlhlXz5JY048ptsJzDismqA&#43;zb6B2UFjbjUnM=">


<script defer src="/interview/en.search.min.e86280f90b15c753162d55c8b4706910f8df0ff40e640d28f944362e01bda273.js" integrity="sha256-6GKA&#43;QsVx1MWLVXItHBpEPjfD/QOZA0o&#43;UQ2LgG9onM="></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-157595781-3', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body>
  <input type="checkbox" class="hidden" id="menu-control" />
  <main class="container flex">
    <aside class="book-menu">
      
  <nav>
<h2 class="book-brand">
  <a href="/interview"><span>Interview</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>









  <ul>
<li><a href="/interview/docs/basic/">计算机基础</a>
<ul>
<li><a href="/interview/docs/basic/algo/">算法</a>
<ul>
<li><a href="/interview/docs/basic/algo/tree/">树</a></li>
<li><a href="/interview/docs/basic/algo/hash/">Hash</a></li>
<li><a href="/interview/docs/basic/algo/mst/">最小生成树算法</a></li>
<li><a href="/interview/docs/basic/algo/path/">最短路径算法</a></li>
<li><a href="/interview/docs/basic/algo/kmp/">KMP算法</a></li>
<li><a href="/interview/docs/basic/algo/search/">查找算法</a></li>
<li><a href="/interview/docs/basic/algo/sort/">排序算法</a></li>
<li><a href="/interview/docs/basic/algo/skip_list/">跳跃表</a></li>
</ul>
</li>
<li><a href="/interview/docs/basic/os/">操作系统</a>
<ul>
<li><a href="/interview/docs/basic/os/arch/">计算机体系结构</a></li>
<li><a href="/interview/docs/basic/os/concurrency/">进程管理</a></li>
<li><a href="/interview/docs/basic/os/memory/">内存管理</a></li>
<li><a href="/interview/docs/basic/os/disk/">磁盘与文件</a></li>
<li><a href="/interview/docs/basic/os/device/">设备管理</a></li>
<li><a href="/interview/docs/basic/os/io/">I/O</a></li>
<li><a href="/interview/docs/basic/os/questions/">面试题</a></li>
</ul>
</li>
<li><a href="/interview/docs/basic/net/">计算机网络</a>
<ul>
<li><a href="/interview/docs/basic/net/protocol/">底层网络协议</a></li>
<li><a href="/interview/docs/basic/net/tcp/">TCP</a></li>
<li><a href="/interview/docs/basic/net/ip/">IP</a></li>
<li><a href="/interview/docs/basic/net/http/">HTTP</a></li>
<li><a href="/interview/docs/basic/net/https/">HTTPS</a></li>
<li><a href="/interview/docs/basic/net/websocket/">Websocket</a></li>
</ul>
</li>
<li><a href="/interview/docs/basic/database/mysql/">MySQL</a>
<ul>
<li><a href="/interview/docs/basic/database/sql/">SQL</a></li>
<li><a href="/interview/docs/basic/database/mysql/architecture/">MySQL架构</a></li>
<li><a href="/interview/docs/basic/database/mysql/innodb/">InnoDB</a>
<ul>
<li><a href="/interview/docs/basic/database/mysql/innodb/index/">InnoDB索引</a></li>
<li><a href="/interview/docs/basic/database/mysql/innodb/concurrent/">InnoDB并发控制</a></li>
<li><a href="/interview/docs/basic/database/mysql/innodb/transaction/">InnoDB事务</a></li>
</ul>
</li>
<li><a href="/interview/docs/basic/database/mysql/sharding/">MySQL集群</a></li>
</ul>
</li>
<li><a href="/interview/docs/basic/database/redis/"class=active>Redis</a></li>
<li><a href="/interview/docs/basic/cryptology/">密码学</a></li>
</ul>
</li>
<li><a href="/interview/docs/java/">Java</a>
<ul>
<li><a href="/interview/docs/java/oop/">OOP</a></li>
<li><a href="/interview/docs/java/serilaser/">序列化</a></li>
<li><a href="/interview/docs/java/operator/">运算符</a></li>
<li><a href="/interview/docs/java/exception/">异常</a></li>
<li><a href="/interview/docs/java/generics/">泛型</a></li>
<li><a href="/interview/docs/java/object/">Object</a></li>
<li><a href="/interview/docs/java/string-builder/">StringBuilder</a></li>
<li><a href="/interview/docs/java/proxy/">代理</a></li>
<li><a href="/interview/docs/java/annotation/">注解</a></li>
<li><a href="/interview/docs/java/nio/">NIO</a></li>
<li><a href="/interview/docs/java/">集合</a>
<ul>
<li><a href="/interview/docs/java/collection/HashMap/">HashMap</a></li>
<li><a href="/interview/docs/java/collection/Concurrenthashmap/">Concurrenthashmap</a></li>
<li><a href="/interview/docs/java/collection/BlockQueue/">BlockQueue</a></li>
</ul>
</li>
<li><a href="/interview/docs/java/concurrent/">并发</a>
<ul>
<li><a href="/interview/docs/java/concurrent/thread/">线程</a></li>
<li><a href="/interview/docs/java/concurrent/volatile/">Volatile</a></li>
<li><a href="/interview/docs/java/concurrent/atomic/">AtomicInteger</a></li>
<li><a href="/interview/docs/java/concurrent/synchronized/">Synchronized</a></li>
<li><a href="/interview/docs/java/concurrent/AQS/">AQS</a></li>
<li><a href="/interview/docs/java/concurrent/count-down-latch/">CountDownLatch</a></li>
<li><a href="/interview/docs/java/concurrent/threadlocal/">Threadlocal</a></li>
<li><a href="/interview/docs/java/concurrent/interrupt/">线程中断</a></li>
</ul>
</li>
<li><a href="/interview/docs/java/jvm/">Java虚拟机</a>
<ul>
<li><a href="/interview/docs/java/jvm/architecture/">JVM架构</a></li>
<li><a href="/interview/docs/java/jvm/classloader/">类加载器</a></li>
<li><a href="/interview/docs/java/jvm/runtime_area/">内存模型</a></li>
<li><a href="/interview/docs/java/jvm/gc/">垃圾收集</a></li>
<li><a href="/interview/docs/java/jvm/dispatcher/">Java分派机制</a></li>
<li><a href="/interview/docs/java/jvm/string-constant-pool/">String常量池</a></li>
<li><a href="/interview/docs/java/jvm/jvm-object-lifecycle/">对象生命周期</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/interview/docs/fromwork/">框架</a>
<ul>
<li><a href="/interview/docs/fromwork/netty/">Netty</a></li>
<li><a href="/interview/docs/fromwork/mybatis/">Mybatis</a>
<ul>
<li><a href="/interview/docs/fromwork/mybatis/question/">面试题</a></li>
<li><a href="/interview/docs/fromwork/mybatis/cache/">缓存</a></li>
<li><a href="/interview/docs/fromwork/mybatis/proxy/">代理</a></li>
</ul>
</li>
<li><a href="/interview/docs/fromwork/spring/">Spring</a>
<ul>
<li><a href="/interview/docs/fromwork/spring/ioc/">IOC</a></li>
<li><a href="/interview/docs/fromwork/spring/design-partten/">设计模式</a></li>
<li><a href="/interview/docs/fromwork/spring/aop/">AOP</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/interview/docs/architecture/">系统架构</a>
<ul>
<li><a href="/interview/docs/architecture/base/">基本概念</a></li>
<li><a href="/interview/docs/architecture/concurrent/">高并发</a>
<ul>
<li><a href="/interview/docs/architecture/concurrent/design/">高并发系统设计</a></li>
<li><a href="/interview/docs/architecture/concurrent/flow-control/">流量控制</a></li>
</ul>
</li>
<li><a href="/interview/docs/architecture/design/">系统设计</a>
<ul>
<li><a href="/interview/docs/architecture/design/tinyURL/">短链接系统</a></li>
<li><a href="/interview/docs/architecture/design/seckill/">秒杀系统</a></li>
</ul>
</li>
<li><a href="/interview/docs/architecture/distributed/">分布式</a>
<ul>
<li><a href="/interview/docs/architecture/distributed/consensus/">分布式一致性与共识算法</a></li>
<li><a href="/interview/docs/architecture/distributed/cache/">分布式缓存</a></li>
<li><a href="/interview/docs/architecture/distributed/lock/">分布式锁</a></li>
<li><a href="/interview/docs/architecture/distributed/transaction/">分布式事务</a></li>
<li><a href="/interview/docs/architecture/distributed/mq/">消息队列</a></li>
<li><a href="/interview/docs/architecture/distributed/zk/">Zookeeper</a></li>
<li><a href="/interview/docs/architecture/distributed/kafka/">Kafka</a></li>
<li><a href="/interview/docs/architecture/distributed/rpc/">远程调用</a></li>
<li><a href="/interview/docs/architecture/distributed/dubbo/">Dubbo</a></li>
</ul>
</li>
<li><a href="/interview/docs/architecture/bigdata/">大数据</a>
<ul>
<li><a href="/interview/docs/architecture/bigdata/algo/">基础算法</a></li>
<li><a href="/interview/docs/architecture/bigdata/hdfs/">HDFS</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/interview/docs/offer/">剑指offer</a>
<ul>
<li><a href="/interview/docs/offer/search-a-2d-matrix/">搜索二维矩阵</a></li>
<li><a href="/interview/docs/offer/replay-space/">替换空格</a></li>
<li><a href="/interview/docs/offer/print-link-from-tail/">从尾到头打印链表</a></li>
<li><a href="/interview/docs/offer/reConstructBinaryTree/">重建二叉树</a></li>
<li><a href="/interview/docs/offer/two-stack-fifo/">用两个栈实现一个队列</a></li>
<li><a href="/interview/docs/offer/find-minimum-in-rotated-sorted-array/">旋转数组的最小数字</a></li>
<li><a href="/interview/docs/offer/fibonacci/">斐波纳切数列</a></li>
<li><a href="/interview/docs/offer/number-of-one/">二进制中1的个数</a></li>
<li><a href="/interview/docs/offer/power/">数值的整数次方</a></li>
<li><a href="/interview/docs/offer/printn/">打印最大的 n 位数</a></li>
<li><a href="/interview/docs/offer/O1DeleteNode/">在O(1)的时间复杂度下删除节点</a></li>
<li><a href="/interview/docs/offer/reOrderArray/">调整数组顺序使奇数位于偶数前面</a></li>
<li><a href="/interview/docs/offer/FindKthToTail/">链表中倒数第k个结点</a></li>
<li><a href="/interview/docs/offer/revert-link/">反转链表</a></li>
<li><a href="/interview/docs/offer/merge-sort-link/">合并两个排序的链表</a></li>
<li><a href="/interview/docs/offer/HasSubtree/">树的子结构</a></li>
<li><a href="/interview/docs/offer/mirror-tree/">二叉树的镜像</a></li>
<li><a href="/interview/docs/offer/PrintMatrix/">顺时针打印矩阵</a></li>
<li><a href="/interview/docs/offer/MinStack/">包含min函数的栈</a></li>
<li><a href="/interview/docs/offer/IsPopOrder/">栈的压入、弹出序列</a></li>
<li><a href="/interview/docs/offer/PrintFromTopToBottom/">从上往下打印二叉树</a></li>
<li><a href="/interview/docs/offer/VerifySquenceOfBST/">二叉搜索树的后序遍历序列</a></li>
<li><a href="/interview/docs/offer/FindPath/">二叉树中和为某一值的路径</a></li>
<li><a href="/interview/docs/offer/CloneLink/">复杂链表的复制</a></li>
<li><a href="/interview/docs/offer/BST-Link-Convert/">二叉搜索树与双向链表</a></li>
<li><a href="/interview/docs/offer/Permutation/">字符串的排列</a></li>
<li><a href="/interview/docs/offer/MoreThanHalfNum/">数组中出现次数超过一半的数字</a></li>
<li><a href="/interview/docs/offer/GetLeastNumbers/">最小的K个数</a></li>
<li><a href="/interview/docs/offer/FindGreatestSumOfSubArray/">连续子数组的最大和</a></li>
<li><a href="/interview/docs/offer/NumberOfOneBetweenOneAndN/">从1到n整数中1出现的次数</a></li>
<li><a href="/interview/docs/offer/PrintMinNumber/">把数组排成最小的数</a></li>
<li><a href="/interview/docs/offer/GetUglyNumber/">丑数</a></li>
<li><a href="/interview/docs/offer/FirstNotRepeatingChar/">第一个只出现一次的字符</a></li>
<li><a href="/interview/docs/offer/InversePairs/">数组中的逆序对</a></li>
<li><a href="/interview/docs/offer/FindFirstCommonNode/">两个链表的第一个公共结点</a></li>
<li><a href="/interview/docs/offer/GetNumberOfK/">数字在排序数组中出现的次数</a></li>
<li><a href="/interview/docs/offer/TreeDepth/">二叉树的深度</a></li>
<li><a href="/interview/docs/offer/FindNumsAppearOnce/">数组中只出现一次的数字</a></li>
<li><a href="/interview/docs/offer/FindNumbersWithSum/">和为S的两个数字</a></li>
<li><a href="/interview/docs/offer/FindContinuousSequence/">和为S的连续正数序列</a></li>
<li><a href="/interview/docs/offer/ReverseSentence/">翻转单词顺序列</a></li>
<li><a href="/interview/docs/offer/LeftRotateString/">左旋转字符串</a></li>
<li><a href="/interview/docs/offer/SumOfNDice/">n个骰子的点数</a></li>
<li><a href="/interview/docs/offer/isContinuous/">扑克牌顺子</a></li>
<li><a href="/interview/docs/offer/LastRemaining/">圆圈中最后剩下的数</a></li>
<li><a href="/interview/docs/offer/sum/">求1+2+3+&hellip;+n</a></li>
<li><a href="/interview/docs/offer/Add/">不用加减乘除做加法</a></li>
<li><a href="/interview/docs/offer/Singleton/">单例</a></li>
<li><a href="/interview/docs/offer/Duplicate/">数组中重复的数字</a></li>
<li><a href="/interview/docs/offer/GetNext/">二叉树的下一个结点</a></li>
<li><a href="/interview/docs/offer/hasPath/">矩阵中的路径</a></li>
<li><a href="/interview/docs/offer/MovingCount/">机器人的运动范围</a></li>
<li><a href="/interview/docs/offer/CutRope/">剪绳子</a></li>
<li><a href="/interview/docs/offer/PatternMatch/">正则表达式匹配</a></li>
<li><a href="/interview/docs/offer/IsNumeric/">表示数值的字符串</a></li>
<li><a href="/interview/docs/offer/EntryNodeOfLoop/">链表中环的入口</a></li>
<li><a href="/interview/docs/offer/IsSymmetrical/">对称二叉树</a></li>
<li><a href="/interview/docs/offer/SerializeTree/">序列化二叉树</a></li>
<li><a href="/interview/docs/offer/StreamMid/">数据流中的中位数</a></li>
<li><a href="/interview/docs/offer/NOfNumberSerialize/">数字序列中的某一位的数字</a></li>
<li><a href="/interview/docs/offer/TranslateNumToStr/">把数字翻译成字符串</a></li>
<li><a href="/interview/docs/offer/MaxGift/">礼物的最大价值</a></li>
<li><a href="/interview/docs/offer/LongestNoRepeatSubString/">最长不含重复字符的子字符串</a></li>
<li><a href="/interview/docs/offer/CountOfSortedArray/">在排序数组中查找数字</a></li>
<li><a href="/interview/docs/offer/BSTKthNode/">二叉搜索树的第K大节点</a></li>
<li><a href="/interview/docs/offer/MaxInWindows/">滑动窗口的最大值</a></li>
<li><a href="/interview/docs/offer/MaxProfit/">股票的最大利润</a></li>
</ul>
</li>
<li><a href="/interview/docs/leetcode/">LeetCode</a>
<ul>
<li><a href="/interview/docs/leetcode/lengthOfLongestSubstring/">* 无重复字符的最长子串</a></li>
<li><a href="/interview/docs/leetcode/longestCommonPrefix/">最长公共前缀</a></li>
<li><a href="/interview/docs/leetcode/checkInclusion/">字符串的排列</a></li>
<li><a href="/interview/docs/leetcode/StringMultiply/">字符串相乘</a></li>
<li><a href="/interview/docs/leetcode/reverseWords/">翻转字符串里的单词</a></li>
<li><a href="/interview/docs/leetcode/simplifyPath/">* 简化路径</a></li>
<li><a href="/interview/docs/leetcode/restoreIpAddresses/">* 复原IP地址</a></li>
<li><a href="/interview/docs/leetcode/threeSum/">* 三数之和</a></li>
<li><a href="/interview/docs/leetcode/maxAreaOfIsland/">* 岛屿的最大面积</a></li>
<li><a href="/interview/docs/leetcode/searchRote/">* 搜索旋转排序数组</a></li>
<li><a href="/interview/docs/leetcode/findLengthOfLCIS/">最长连续递增序列</a></li>
<li><a href="/interview/docs/leetcode/findKthLargest/">数组中的第K个最大元素</a></li>
<li><a href="/interview/docs/leetcode/longestConsecutive/">最长连续序列</a></li>
<li><a href="/interview/docs/leetcode/findCircleNum/">* 朋友圈</a></li>
<li><a href="/interview/docs/leetcode/mergeRagen/">合并区间</a></li>
<li><a href="/interview/docs/leetcode/trap/">* 接雨水</a></li>
<li><a href="/interview/docs/leetcode/mergeTwoLists/">合并两个有序链表</a></li>
<li><a href="/interview/docs/leetcode/reverseList/">* 反转链表</a></li>
<li><a href="/interview/docs/leetcode/addTwoNumbers/">* 两数相加</a></li>
<li><a href="/interview/docs/leetcode/sortList/">* 排序链表</a></li>
<li><a href="/interview/docs/leetcode/detectCycle/">环形链表 II</a></li>
<li><a href="/interview/docs/leetcode/getIntersectionNode/">相交链表</a></li>
<li><a href="/interview/docs/leetcode/mergeKLists/">* 合并K个排序链表</a></li>
<li><a href="/interview/docs/leetcode/lowestCommonAncestor/">二叉树的最近公共祖先</a></li>
<li><a href="/interview/docs/leetcode/zigzagLevelOrder/">二叉树的锯齿形层次遍历</a></li>
<li><a href="/interview/docs/leetcode/maxProfit/">* 买卖股票的最佳时机</a></li>
<li><a href="/interview/docs/leetcode/maxProfit2/">* 买卖股票的最佳时机 II</a></li>
<li><a href="/interview/docs/leetcode/maxSubArray/">最大子序和</a></li>
<li><a href="/interview/docs/leetcode/MinStack/">* 最小栈</a></li>
<li><a href="/interview/docs/leetcode/LRUCache/">* LRU缓存机制</a></li>
<li><a href="/interview/docs/leetcode/AllOne/">全 O(1) 的数据结构</a></li>
<li><a href="/interview/docs/leetcode/mySqrt/">* x 的平方根</a></li>
<li><a href="/interview/docs/leetcode/validUtf8/">* UTF-8 编码验证</a></li>
<li><a href="/interview/docs/leetcode/salary/">* 第二高的薪水</a></li>
</ul>
</li>
</ul>








</nav>




  <script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script>


 
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/interview/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Redis</strong>

  <label for="toc-control">
    <img src="/interview/svg/toc.svg" class="book-icon" alt="Table of Contents" />
  </label>
</div>


  
    <input type="checkbox" class="hidden" id="toc-control" />
    <aside class="hidden clearfix">
      
  <nav id="TableOfContents">
  <ul>
    <li><a href="#线程模型">线程模型</a>
      <ul>
        <li><a href="#为啥-redis-单线程模型也能效率这么高">为啥 Redis 单线程模型也能效率这么高？</a></li>
      </ul>
    </li>
    <li><a href="#持久化">持久化</a>
      <ul>
        <li><a href="#rdb">RDB</a></li>
        <li><a href="#aof">AOF</a></li>
        <li><a href="#rdb-和-aof-到底该如何选择">RDB 和 AOF 到底该如何选择</a></li>
      </ul>
    </li>
    <li><a href="#一致性哈希算法">一致性哈希算法</a>
      <ul>
        <li><a href="#需求">需求</a></li>
        <li><a href="#实现">实现</a></li>
      </ul>
    </li>
    <li><a href="#实践httpsyikungithubio20160609e4b880e887b4e680a7e59388e5b88ce7ae97e6b395e79a84e79086e8a7a3e4b88ee5ae9ee8b7b5">实践</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#集群">集群</a>
      <ul>
        <li><a href="#主从复制">主从复制</a></li>
        <li><a href="#哨兵">哨兵</a></li>
        <li><a href="#redis-cluster">Redis Cluster</a></li>
      </ul>
    </li>
    <li><a href="#数据结构">数据结构</a>
      <ul>
        <li><a href="#string">string</a></li>
        <li><a href="#zset底层实现">zset底层实现</a></li>
        <li><a href="#bitmap-实现">BitMap 实现</a></li>
      </ul>
    </li>
    <li><a href="#缓存穿透缓存击穿缓存雪崩">缓存穿透、缓存击穿、缓存雪崩</a>
      <ul>
        <li><a href="#缓存穿透">缓存穿透</a></li>
        <li><a href="#缓存雪崩">缓存雪崩</a></li>
        <li><a href="#缓存击穿">缓存击穿</a></li>
      </ul>
    </li>
    <li><a href="#redis分布式锁">Redis分布式锁</a></li>
    <li><a href="#数据淘汰机制">数据淘汰机制</a>
      <ul>
        <li><a href="#对象过期">对象过期</a></li>
        <li><a href="#内存淘汰">内存淘汰</a></li>
      </ul>
    </li>
  </ul>
</nav>


    </aside>
  
 
      </header>

      
<article class="markdown"><h1 id="redis">Redis</h1>
<h2 id="线程模型">线程模型</h2>
<p>Redis 在处理网络请求是使用单线程模型，并通过 IO 多路复用来提高并发。但是在其他模块，比如：持久化，会使用多个线程。</p>
<p>Redis 内部使用文件事件处理器 <code>file event handler</code>，<strong>这个文件事件处理器是单线程的，所以 <code>Redis</code> 才叫做单线程的模型</strong>。它采用 IO 多路复用机制同时监听多个 <code>socket</code> ，将产生事件的 <code>socket</code> 压入内存队列中，事件分派器根据 <code>socket</code> 上的事件类型来选择对应的事件处理器进行处理。</p>
<p>文件事件处理器的结构包含 4 个部分：</p>
<ul>
<li>多个 socket</li>
<li>IO 多路复用程序</li>
<li>文件事件分派器</li>
<li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li>
</ul>
<p>多个 <code>socket</code> 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 <code>IO</code> 多路复用程序会监听多个 <code>socket</code> ，会将产生事件的 <code>socket</code> 放入队列中排队，事件分派器每次从队列中取出一个 <code>socket</code> ，根据 <code>socket</code> 的事件类型交给对应的事件处理器进行处理。</p>
<p>客户端与 Redis 的一次通信过程：</p>
<p><img src="images/f0dacdd3779b836ad75fe6b886af1fff.png" alt="image"></p>
<h3 id="为啥-redis-单线程模型也能效率这么高">为啥 Redis 单线程模型也能效率这么高？</h3>
<ul>
<li>纯内存操作</li>
<li>核心是基于非阻塞的 IO 多路复用机制</li>
<li>单线程反而避免了多线程的频繁上下文切换问题</li>
</ul>
<h2 id="持久化">持久化</h2>
<h3 id="rdb">RDB</h3>
<p>RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化。</p>
<ul>
<li>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，<strong>非常适合做冷备</strong></li>
<li>RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</li>
<li>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。</li>
<li>一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟的数据。</li>
<li>RDB 每次在 <code>fork</code> 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li>
</ul>
<h3 id="aof">AOF</h3>
<p>AOF 机制对每条写入命令作为日志，以 <code>append-only</code> 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集</p>
<ul>
<li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 <code>fsync</code> 操作，最多丢失 1 秒钟的数据。</li>
<li>AOF 日志文件以 <code>append-only</code> 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</li>
<li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 <strong><code>rewrite log</code></strong> 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 <code>merge</code> 后的日志文件 <code>ready</code> 的时候，再交换新老日志文件即可。</li>
<li>AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常 <strong>适合做灾难性的误删除的紧急恢复</strong>。比如某人不小心用 <code>flushall</code> 命令清空了所有数据，只要这个时候后台 <code>rewrite</code> 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 <code>flushall</code> 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。</li>
<li>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</li>
<li><strong>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低</strong>，因为 AOF 一般会配置成每秒 <code>fsync</code> 一次日志文件，当然，每秒一次 <code>fsync</code> ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低）</li>
<li>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</li>
</ul>
<h3 id="rdb-和-aof-到底该如何选择">RDB 和 AOF 到底该如何选择</h3>
<ol>
<li>不要仅仅使用 RDB，因为那样会导致你丢失很多数据；</li>
<li>也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；</li>
<li>Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</li>
</ol>
<h2 id="一致性哈希算法">一致性哈希算法</h2>
<p>一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 <code>K/n</code> 个关键字重新映射，其中 <code>K</code> 是关键字的数量，<code>n</code> 是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。</p>
<blockquote>
<p>一致哈希也可用于实现健壮缓存来减少大型 Web 应用中系统部分失效带来的负面影响</p>
</blockquote>
<h3 id="需求">需求</h3>
<p>在使用 <code>n</code> 台缓存服务器时，一种常用的负载均衡方式是，对资源 <code>o</code> 的请求使用 <code>hash(o)= o mod n</code> 来映射到某一台缓存服务器。当增加或减少一台缓存服务器时这种方式可能会改变所有资源对应的 <code>hash</code> 值，也就是所有的缓存都失效了，这会使得缓存服务器大量集中地向原始内容服务器更新缓存。</p>
<p>因此需要一致哈希算法来避免这样的问题。 一致哈希尽可能使同一个资源映射到同一台缓存服务器。这种方式要求增加一台缓存服务器时，新的服务器尽量分担存储其他所有服务器的缓存资源。减少一台缓存服务器时，其他所有服务器也可以尽量分担存储它的缓存资源。</p>
<p>一致哈希算法的主要思想是将每个缓存服务器与一个或多个哈希值域区间关联起来，其中区间边界通过计算缓存服务器对应的哈希值来决定。如果一个缓存服务器被移除，则它所对应的区间会被并入到邻近的区间，其他的缓存服务器不需要任何改变。</p>
<h3 id="实现">实现</h3>
<p>一致哈希将每个对象映射到圆环边上的一个点，系统再将可用的节点机器映射到圆环的不同位置。查找某个对象对应的机器时，需要用一致哈希算法计算得到对象对应圆环边上位置，沿着圆环边上查找直到遇到某个节点机器，这台机器即为对象应该保存的位置。</p>
<p>当删除一台节点机器时，这台机器上保存的所有对象都要移动到下一台机器。添加一台机器到圆环边上某个点时，这个点的下一台机器需要将这个节点前对应的对象移动到新机器上。更改对象在节点机器上的分布可以通过调整节点机器的位置来实现。</p>
<h2 id="实践httpsyikungithubio20160609e4b880e887b4e680a7e59388e5b88ce7ae97e6b395e79a84e79086e8a7a3e4b88ee5ae9ee8b7b5"><a href="https://yikun.github.io/2016/06/09/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E5%AE%9E%E8%B7%B5/">实践</a></h2>
<blockquote>
<p>假设有1000w个数据项，100个存储节点，请设计一种算法合理地将他们存储在这些节点上。</p>
</blockquote>
<p>看一看普通Hash算法的原理：</p>
<p><img src="images/1c5e07626a9cadd5f1ea8acd85838067.png" alt=""></p>
<pre><code>for item in range(ITEMS):
    k = md5(str(item)).digest()
    h = unpack_from(&quot;&gt;I&quot;, k)[0]
    # 通过取余的方式进行映射
    n = h % NODES
    node_stat[n] += 1
</code></pre><p>普通的Hash算法均匀地将这些数据项打散到了这些节点上，并且分布最少和最多的存储节点数据项数目小于 <code>1%</code>。之所以分布均匀，主要是依赖 Hash 算法（实现使用的MD5算法）能够比较随机的分布。</p>
<p>然而，我们看看存在一个问题，由于 <strong>该算法使用节点数取余的方法，强依赖 <code>node</code> 的数目</strong>，因此，当是 <code>node</code> 数发生变化的时候，<code>item</code> 所对应的 <code>node</code> 发生剧烈变化，而发生变化的成本就是我们需要在 <code>node</code> 数发生变化的时候，数据需要迁移，这对存储产品来说显然是不能忍的。</p>
<h4 id="一致性哈希">一致性哈希</h4>
<p>普通 <code>Hash</code> 算法的劣势，即当 <code>node</code> 数发生变化（增加、移除）后，数据项会被重新“打散”，导致大部分数据项不能落到原来的节点上，从而导致大量数据需要迁移。</p>
<p>那么，一个亟待解决的问题就变成了：当 <code>node</code> 数发生变化时，如何保证尽量少引起迁移呢？即当增加或者删除节点时，对于大多数 item ，保证原来分配到的某个 node ，现在仍然应该分配到那个 node ，将数据迁移量的降到最低。</p>
<p><img src="images/3de376ea57386b890483b27cf131f24d.png" alt=""></p>
<pre><code>for n in range(NODES):
    h = _hash(n)
    ring.append(h)
    ring.sort()
    hash2node[h] = n
for item in range(ITEMS):
    h = _hash(item)
    n = bisect_left(ring, h) % NODES
    node_stat[hash2node[ring[n]]] += 1
</code></pre><p><strong>虽然一致性Hash算法解决了节点变化导致的数据迁移问题，但是，数据项分布的均匀性很差</strong>。</p>
<p><img src="images/5e6b9afd23ff44415b434d05ed0449ce.png" alt=""></p>
<p>主要是因为这 100 个节点 Hash 后，在环上分布不均匀，导致了每个节点实际占据环上的区间大小不一造成的。</p>
<h4 id="改进----虚节点">改进 &ndash; 虚节点</h4>
<p>当我们将 node 进行哈希后，这些值并没有均匀地落在环上，因此，最终会导致，这些节点所管辖的范围并不均匀，最终导致了数据分布的不均匀。</p>
<p><img src="images/c807b7a0af060a874fdb27abf5caf289.png" alt=""></p>
<pre><code>for n in range(NODES):
    for v in range(VNODES):
        h = _hash(str(n) + str(v))
        # 构造ring
        ring.append(h)
        # 记录hash所对应节点
        hash2node[h] = n
ring.sort()
for item in range(ITEMS):
    h = _hash(str(item))
    # 搜索ring上最近的hash
    n = bisect_left(ring, h) % (NODES*VNODES)
    node_stat[hash2node[ring[n]]] += 1
</code></pre><p>通过增加虚节点的方法，使得每个节点在环上所“管辖”更加均匀。这样就既保证了在节点变化时，尽可能小的影响数据分布的变化，而同时又保证了数据分布的均匀。也就是靠增加“节点数量”加强管辖区间的均匀。</p>
<h2 id="集群">集群</h2>
<h3 id="主从复制">主从复制</h3>
<p>单机的 Redis ，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成 <strong>主从(Master-Slave)架构</strong> ，一主多从，主负责写，并且将数据复制到其它的 Slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。</p>
<p><img src="./images/redis-master-slave.png" alt=""></p>
<p>Redis 默认采用异步方式复制数据到 Slave Node，同时 Slave Node 会周期性地确认自己每次复制的数据量：</p>
<ol>
<li>当 Master 和 Slave 网络连接顺畅时，Master 会持续向 Slave 推送命令，以保持在 Master 数据集合上执行的：客户端写、Key 过期、Key 淘汰等均在 Slave 数据集合上执行。</li>
<li>当 Master 和 Slave 网络连接由于网络问题、超时等中断时， Slave 会尝试重连并进行连接断开期间的命令 <strong>部分同步（partial resynchronization）</strong>。</li>
<li>当部分同步不可用时，Slave 会请求全量同步。在这个过程中，Master 会创建当前所有数据的镜像，发送给 Slave 并继续推送命令。</li>
</ol>
<p>Redis 主从复制包含以下几个要点：</p>
<ol>
<li>一个 Master 可以有多个 Slave</li>
<li>Slave 支持级联结构，即 Slave 可以连接到其他 Slave 上</li>
<li>Redis 在复制过程中，不阻塞 Master ，不论是全量同步还是部分同步</li>
<li>在大部分时间里，复制也不会阻塞 Slave 。当 Slave 在进行初始化同步时，Slave 会先使用旧的数据集提供服务。但当初始化同步完成时，会删除旧数据集，这时 Slave 会拒绝服务。</li>
<li>Redis 主从复制可以用来做水平扩容，以提供读写分离，或作为数据备份和高可用</li>
<li>在主从复制的情况下，可以通过配置避免数据持久化，将 Slave 作为数据的备份或开启 Slave 的 AOF。但是这种情况下也会有风险：当 Master 重启后数据集将清空，这时如果 Slave 同步 Master 就会导致数据也被清空</li>
</ol>
<h4 id="当-master-不进行持久化如何保证数据安全">当 Master 不进行持久化如何保证数据安全</h4>
<p>在生产环境中，强烈建议开启 Redis 持久化，不论是在 Master 还是在 Slave。如果由于磁盘速度等问题，不能开启持久化，那么需要 <strong>避免 Redis 进程的自动重启</strong>。</p>
<h3 id="哨兵">哨兵</h3>
<p><code>Sentinel</code> 是 Redis 官方推荐的 <strong>高可用性( <code>HA</code> )解决方案</strong>，当用 Redis 做主从复制的高可用方案时，假如 Master 宕机了， Redis 本身都没有实现自动进行主备切换，而哨兵本身也是一个独立运行的进程，它能监控多个节点，发现 Master 宕机后能进行自动切换。</p>
<p>它的主要功能有以下几点</p>
<ul>
<li>集群监控：负责监控 Redis Master 和 Slave 进程是否正常工作。</li>
<li>消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。</li>
<li>故障转移：如果 Master node 挂掉了，会自动转移到 Slave node 上。</li>
<li>配置中心：如果故障转移发生了，通知 client 客户端新的 Master 地址。</li>
</ul>
<h4 id="哨兵的核心知识">哨兵的核心知识</h4>
<ol>
<li>哨兵至少需要 3 个实例，来保证自己的健壮性。</li>
<li>哨兵 + Redis 主从的部署架构，是 <strong>不保证数据零丢失</strong> 的，只能保证 Redis 集群的高可用性。</li>
<li>对于哨兵 + Redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。</li>
<li>哨兵的个数与集群节点个数无关，每个哨兵都会 Check 所有节点</li>
<li>当启用哨兵后，客户端的连接是通过哨兵连接到 Node 的</li>
</ol>
<p>哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，<code>Quorum</code> = 1。</p>
<pre><code class="language-log" data-lang="log">+----+         +----+
| M1 |---------| R1 |
| S1 |         | S2 |
+----+         +----+
</code></pre><p>如果 Master 宕机， <code>S1</code> 和 <code>S2</code> 中只要有 1 个哨兵认为 Master 宕机了，就可以进行切换，同时 <code>S1</code> 和 <code>S2</code> 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 <code>Majority</code> ，也就是超过半数的哨兵都是运行的。</p>
<p>如果此时仅仅是 <code>M1</code> 进程宕机了，哨兵 <code>s1</code> 正常运行，那么故障转移是 OK 的。但是如果是整个 <code>M1</code> 和 <code>S1</code> 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 <code>Majority</code> 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。</p>
<p>经典的 3 节点哨兵集群是这样的：</p>
<pre><code class="language-log" data-lang="log">       +----+
       | M1 |
       | S1 |
       +----+
          |
+----+    |    +----+
| R2 |----+----| R3 |
| S2 |         | S3 |
+----+         +----+
</code></pre><p>配置 <code>Quorum=2</code>，如果 <code>M1</code> 所在机器宕机了，那么三个哨兵还剩下 2 个， <code>S2</code> 和 <code>S3</code> 可以一致认为 Master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 <code>Majority</code> 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。</p>
<h4 id="slave-选主算法">Slave 选主算法</h4>
<p>如果一个 Master 被认为宕机，而且 <code>Majority</code> 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 Slave 来，会考虑 Slave 的一些信息：</p>
<ul>
<li>跟 Master 断开连接的时长</li>
<li>Slave 优先级</li>
<li>复制 offset</li>
<li>run id</li>
</ul>
<p>接下来会对 Slave 进行排序：</p>
<ul>
<li>按照 Slave 优先级进行排序，Slave Priority 越低，优先级就越高。</li>
<li>如果 Slave Priority 相同，那么看 Replica Offset，哪个 Slave 复制了越多的数据，Offset 越靠后，优先级就越高。</li>
<li>如果上面两个条件都相同，那么选择一个 run id 比较小的那个 Slave。</li>
</ul>
<h3 id="redis-cluster">Redis Cluster</h3>
<p>Redis Cluster 是一种服务器 <code>Sharding</code> 技术，提供内置的高可用支持，部分 master 不可用时，还可以继续工作。Redis Cluster 功能强大，直接集成了 <strong>主从复制</strong> 和 <strong>哨兵</strong> 的功能。</p>
<ul>
<li><strong>高性能</strong>：在 Cluster 集群中没有代理，主从之间使用异步复制，并且不会对 Key 进行合并操作；</li>
<li><strong>可接受的写入安全</strong>：当客户端连接到 majority master 时集群尽最大努力保留所有客户端的写操作。通常情况下，在一小段窗口时间内写请求会被丢失，当客户端连接到 minority master 时这个窗口时间会很大；</li>
<li><strong>可用性</strong>：当 Redis Cluster 中大部分 master 是可达的，并且不可达 master 均有一个可用的 slave 时，Redis Cluster 能够在 <code>NODE_TIMEOUT</code> 时间后进行故障转移，使 Cluster 重新可用。此外，Cluster 还提供 <strong>副本迁移（replicas migration）</strong>，当 master 没有 slave 时，可从其他 master 下重新分配一个 slave ；</li>
</ul>
<blockquote>
<p>majority master：能与大多数 master 连通的 master
minority master：未能与大多数 master 连通的 master</p>
</blockquote>
<h4 id="内部节点通信">内部节点通信</h4>
<p>在 Cluster 架构下，每个 Redis 都需要开启额外的端口来进行节点间通信，这种机制被称之为 <strong>Cluster Bus</strong>。</p>
<p>Redis 维护集群元数据采用 <strong>gossip 协议</strong>，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p>
<p>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</p>
<h4 id="寻址算法">寻址算法</h4>
<p>Redis Cluster 有固定的 16384 个 Hash Slot，对每个 key 计算 <code>CRC16</code> 值，然后对 <code>16384</code> 取模，可以获取 key 对应的 Hash Slot。Redis Cluster 中<strong>每个 Master 都会持有部分 Slot</strong>，Slot 的分配在 Cluster 未进行重配置（reconfiguration）时是稳定的。当 Cluster 稳定时，一个 Hash Slot 只在一个 master 上提供服务。不过一个 master 会有一个或多个 slave ，以在发生网络分区或故障时，替换 master。这些 slave 还可以缓解 master 的读请求的压力。</p>
<blockquote>
<p>重配置：Hash Slot 从一个节点转移到另一个节点</p>
</blockquote>
<p>Keys hash tags 可以破坏上述的分配规则，Hash tags 是一种保证多个键被分配到同一个槽位的方法。</p>
<h4 id="重定向">重定向</h4>
<p>Redis Cluster 为了提高性能，不会提供代理，而是使用重定向的方式让 client 连接到正确的节点。</p>
<h5 id="moved">MOVED</h5>
<p>Redis 客户端可以向集群的任意一个节点发送查询请求，节点接收到请求后会对其进行解析，如果是操作单个 key 的命令或者是包含多个在相同槽位 key 的命令，那么该节点就会去查找这个 key 是属于哪个槽位的。如果 key 所属的槽位由该节点提供服务，那么就直接返回结果。否则就会返回一个 <code>MOVED</code> 错误：</p>
<pre><code class="language-log" data-lang="log">GET x
-MOVED 3999 127.0.0.1:6381
</code></pre><p>这个错误包括了对应的 key 属于哪个槽位（3999）以及该槽位所在的节点的 IP 地址和端口号。client 收到这个错误信息后，就将这些信息存储起来以便可以更准确的找到正确的节点。</p>
<p>当客户端收到 <code>MOVED</code> 错误后，可以使用 <code>CLUSTER NODES</code> 或 <code>CLUSTER SLOTS</code> 命令来更新整个集群的信息，因为当重定向发生时，很少会是单个槽位的变更，一般都会是多个槽位一起更新。因此，在收到 <code>MOVED</code> 错误时，客户端应该尽早更新集群的分布信息。当集群达到稳定状态时，客户端保存的槽位和节点的对应信息都是正确的，cluster 的性能也会达到非常高效的状态。</p>
<h5 id="ask">ASK</h5>
<p>对于 Redis Cluster 来讲， <code>MOVED</code> 重定向意味着请求的 slot 永久的由另一个节点提供服务，而 <code>ASK</code> 重定向仅代表将当前查询重定向到指定节点，不影响后续查询。在 Redis Cluster 迁移的时候会用到 ASK 重定向，下面看下 ASK 的处理流程：</p>
<ol>
<li>Client 向节点 A 查询数据 <code>x</code>，A 发现数据 <code>x</code> 所在的 slot 状态为 <code>MIGRATING</code>，如果 <code>x</code> 存在则返回，否则返回 <code>ASK</code> 重定向；</li>
<li>Client 向 <code>ASK</code> 重定向节点 B 发送 <code>ASKING</code> ，再查询数据 <code>x</code>；</li>
<li>B 查找 <code>x</code> 发现其所在 slot 状态为 <code>IMPORTING</code>，则 B 会进行查询。若第二步未发送 <code>ASKING</code> ，则 B 会返回 <code>MOVED</code>命令，重定向到 A；</li>
</ol>
<p>Redis Cluster 的迁移是以槽位单位的，一个槽位从节点 A 迁移到节点 B 需要经过以下步骤：</p>
<ol>
<li>节点 A 将待迁移 slot 设置为 <code>MIGRATING</code> 状态，将 B 节点 slot 设置为 <code>IMPORTING</code> 状态</li>
<li>A 获取 slot 中的 key，逐个调用 <code>MIGRATE</code> 命令</li>
<li><code>MIGRATE</code> 会将特定的 key 从 A 迁移到 B，这个过程是原子操作（A、B均会进行加锁）</li>
</ol>
<h4 id="容错能力">容错能力</h4>
<p>Redis Cluster和大多数集群一样，是通过心跳来判断一个节点是否存活的。心跳包的内容可以分为 header 和 gossip 消息两部分，其中header包含以下信息：</p>
<ul>
<li>NODE ID 节点在集群中的唯一标识</li>
<li>currentEpoch 和 configEpoch 字段</li>
<li>node flag，标识节点是 master 还是 slave ，另外还有一些其他的标识位</li>
<li>节点提供服务的 hash slot 的 bitmap</li>
<li>发送者的 TCP 端口</li>
<li>发送者认为的集群状态（down or ok）</li>
<li>如果是slave，则包含 master 的 NODE ID</li>
</ul>
<p>gossip包含了该节点认为的其他节点的状态，不过不是集群的全部节点。具体有以下信息：</p>
<ul>
<li>NODE ID</li>
<li>节点的IP和端口</li>
<li>NODE flags</li>
</ul>
<h5 id="故障检测">故障检测</h5>
<p>故障检测用于识别集群中的不可达节点是否已下线，如果一个 master 下线，则会将它的 slave提 升为master。如果无法提升，则集群会处于错误状态。在 gossip 消息中，<code>NODE flags</code> 的值包括两种 PFAIL 和 FAIL。</p>
<p>如果一个节点发现另外一个节点不可达的时间超过 <code>NODE_TIMEOUT</code> ，则会将这个节点标记为 PFAIL，也就是 Possible failure。 PFAIL 标志只是一个节点本地的信息，为了使 slave 提升为 master ，需要将 PFAIL 升级为 FAIL 。当集群中大部分节点都将某个节点标记为 PFAIL 时，则可升级为 FAIL。</p>
<p>FAIL 状态是单向的，只能从 PFAIL 升级为 FAIL ，当节点重新可达时，可清除 FAIL 标记。</p>
<h2 id="数据结构">数据结构</h2>
<p>Redis的外围由一个键、值映射的字典构成。与其他非关系型数据库主要不同在于：Redis中值的类型不仅限于 <strong>字符串</strong>，还支持如下抽象数据类型：</p>
<ul>
<li><strong>List</strong>：字符串列表</li>
<li><strong>Set</strong>：无序不重复的字符串集合</li>
<li><strong>Soret Set</strong>：有序不重复的字符串集合</li>
<li><strong>HashTable</strong>：键、值都为字符串的哈希表</li>
</ul>
<p>值的类型决定了值本身支持的操作。Redis支持不同无序、有序的列表，无序、有序的集合间的交集、并集等高级服务器端原子操作。</p>
<h3 id="string">string</h3>
<p>Redis 没有直接使用 C 语言传统的字符串表示（以空字符结尾的字符数组，以下简称 C 字符串）， 而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型， 并将 SDS 用作 Redis 的默认字符串表示。</p>
<p>在 Redis 里面， C 字符串只会作为字符串字面量（string literal）， 用在一些无须对字符串值进行修改的地方， 比如打印日志。</p>
<p>当 Redis 需要的不仅仅是一个字符串字面量， 而是一个可以被修改的字符串值时， Redis 就会使用 SDS 来表示字符串值： 比如在 Redis 的数据库里面， 包含字符串值的键值对在底层都是由 SDS 实现的。</p>
<table>
<thead>
<tr>
<th align="left">C字符串</th>
<th align="left">SDS</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">获取字符串长度的复杂度为 O(N) 。</td>
<td align="left">获取字符串长度的复杂度为 O(1) 。</td>
</tr>
<tr>
<td align="left">API 是不安全的，可能会造成缓冲区溢出。</td>
<td align="left">API 是安全的，不会造成缓冲区溢出。</td>
</tr>
<tr>
<td align="left">修改字符串长度 N 次必然需要执行 N 次内存重分配。</td>
<td align="left">修改字符串长度 N 次最多需要执行 N 次内存重分配。</td>
</tr>
<tr>
<td align="left">只能保存文本数据。</td>
<td align="left">可以保存文本或者二进制数据。</td>
</tr>
<tr>
<td align="left">可以使用所有 &lt;string.h&gt; 库中的函数。</td>
<td align="left">可以使用一部分 &lt;string.h&gt; 库中的函数。</td>
</tr>
</tbody>
</table>
<h4 id="缓冲区溢出">缓冲区溢出</h4>
<p>因为 C 字符串不记录自身的长度， 所以 <code>strcat</code> 假定用户在执行这个函数时， 已经为 <code>dest</code> 分配了足够多的内存， 可以容纳 <code>src</code> 字符串中的所有内容， 而一旦这个假定不成立时， 就会产生缓冲区溢出。</p>
<p>举个例子， 假设程序里有两个在内存中紧邻着的 C 字符串 <code>s1</code> 和 <code>s2</code> ， 其中 s1 保存了字符串 <code>&quot;Redis&quot;</code> ， 而 s2 则保存了字符串 <code>&quot;MongoDB&quot;</code> ， 如图所示。</p>
<p><img src="images/a9832e14ba184a4049f979e521ef050b.png" alt=""></p>
<p>如果一个程序员决定通过执行：</p>
<pre><code>strcat(s1, &quot; Cluster&quot;);
</code></pre><p>将 <code>s1</code> 的内容修改为 <code>&quot;Redis Cluster&quot;</code> ， 但粗心的他却忘了在执行 <code>strcat</code> 之前为 <code>s1</code> 分配足够的空间， 那么在 <code>strcat</code> 函数执行之后， <code>s1</code> 的数据将溢出到 <code>s2</code> 所在的空间中， 导致 <code>s2</code> 保存的内容被意外地修改， 如图所示。</p>
<p><img src="images/cc9ac0419ae3f5059076c2d66f867931.png" alt=""></p>
<p>与 <code>C</code> 字符串不同， <code>SDS</code> 的空间分配策略完全杜绝了发生缓冲区溢出的可能性： <strong>当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求</strong>， 如果不满足的话， API 会自动将 <code>SDS</code> 的空间扩展至执行修改所需的大小， 然后才执行实际的修改操作， 所以使用 <code>SDS</code> 既不需要手动修改 <code>SDS</code> 的空间大小， 也不会出现前面所说的缓冲区溢出问题。</p>
<h4 id="减少修改字符串时带来的内存重分配次数">减少修改字符串时带来的内存重分配次数</h4>
<ul>
<li>空间预分配：解决 append 问题</li>
<li>惰性空间释放：解决 strim 问题</li>
</ul>
<h4 id="二进制安全">二进制安全</h4>
<p>C 字符串中的字符必须符合某种编码（比如 <code>ASCII</code>）， 并且 <strong>除了字符串的末尾之外， 字符串里面不能包含空字符</strong>， 否则最先被程序读入的空字符将被误认为是字符串结尾 —— 这些限制使得 C 字符串只能保存文本数据， 而不能保存像图片、音频、视频、压缩文件这样的二进制数据。</p>
<h3 id="zset底层实现">zset底层实现</h3>
<p><strong>跳跃表（skiplist）</strong> 是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的。</p>
<p><code>Redis</code> 使用跳跃表作为有序集合键的底层实现之一：</p>
<ul>
<li>如果一个有序集合包含的元素数量比较多，</li>
<li>有序集合中元素的成员（<code>member</code>）是比较长的字符串时</li>
</ul>
<p>Redis 就会使用跳跃表来作为有序集合键的底层实现。</p>
<p>和链表、字典等数据结构被广泛地应用在 Redis 内部不同， <strong>Redis 只在两个地方用到了跳跃表， 一个是实现有序集合键， 另一个是在集群节点中用作内部数据结构</strong>， 除此之外， 跳跃表在 Redis 里面没有其他用途。</p>
<h3 id="bitmap-实现">BitMap 实现</h3>
<p>Bitmaps 并不是实际的数据类型，而是定义在 String 类型上的一个面向字节操作的集合。因为字符串是二进制安全的，最大长度是 512M ，所以最长拥有 

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>



<span class="katex">
  \(2^32\)
</span>
 个不同字节。</p>
<p>Redis 提供以下 BitMap 操作接口：<code>setBit</code>、<code>getBit</code>、<code>bitCount</code>、<code>bitop</code>、<code>bitpos</code>。其中 <code>setBit</code>、<code>getBit</code>都是 

<span class="katex">
  \(O(1)\)
</span>
 复杂度的操作。</p>
<p>优势：</p>
<ol>
<li>基于最小的单位bit进行存储，所以非常省空间。</li>
<li>设置时候时间复杂度O(1)、读取时候时间复杂度O(n)，操作是非常快的。</li>
<li>二进制数据的存储，进行相关计算的时候非常快。</li>
<li>方便扩容</li>
</ol>
<p>限制：Redis中bit映射被限制在512MB之内，所以最大是 

<span class="katex">
  \(2^32\)
</span>
 位。</p>
<h2 id="缓存穿透缓存击穿缓存雪崩">缓存穿透、缓存击穿、缓存雪崩</h2>
<h3 id="缓存穿透">缓存穿透</h3>
<p>访问一个不存在的key，缓存不起作用，请求会穿透到 DB，流量大时 DB 会挂掉。</p>
<h4 id="解决方案">解决方案</h4>
<ul>
<li>
<p>采用布隆过滤器，使用一个足够大的<code>bitmap</code>，用于存储可能访问的 <code>key</code>，不存在的key直接被过滤；</p>
</li>
<li>
<p>访问key未在DB查询到值，也将空值写进缓存，但可以设置较短过期时间。</p>
</li>
</ul>
<h3 id="缓存雪崩">缓存雪崩</h3>
<p>大量的 key 设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。</p>
<h4 id="解决方案-1">解决方案</h4>
<p>可以给缓存设置过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。</p>
<h3 id="缓存击穿">缓存击穿</h3>
<p>对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一 key 缓存，前者则是很多key。</p>
<p>缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。</p>
<h4 id="解决方案-2">解决方案</h4>
<p>在缓存失效的时候（判断拿出来的值为空），不是立即去 <code>load db</code> ，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的 <code>SETNX</code>）去 <code>set</code> 一个 <code>mutex key</code> ，当操作返回成功时，再进行 <code>load db</code> 的操作并回设缓存；否则，就重试整个 <code>get</code> 缓存的方法。</p>
<h2 id="redis分布式锁">Redis分布式锁</h2>
<ul>
<li>加锁：<code>Redis.set(String key, String value, String nxxx, String expx, int time)</code></li>
<li>解锁：通过 Lua 脚本执行 <code>if Redis.call('get', KEYS[1]) == ARGV[1] then return Redis.call('del', KEYS[1]) else return 0 end</code></li>
</ul>
<h2 id="数据淘汰机制">数据淘汰机制</h2>
<h3 id="对象过期">对象过期</h3>
<p>Redis回收过期对象的策略：定期删除+惰性删除</p>
<ul>
<li><strong>惰性删除</strong>：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key</li>
<li><strong>定期删除</strong>：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key</li>
</ul>
<h3 id="内存淘汰">内存淘汰</h3>
<p>Redis提供了下面几种淘汰策略供用户选择，其中默认的策略为noeviction策略：</p>
<ul>
<li><code>noeviction</code>：当内存使用达到阈值的时候，所有引起申请内存的命令会报错。</li>
<li><code>allkeys-lru</code>：在主键空间中，优先移除最近未使用的key。</li>
<li><code>volatile-lru</code>：在设置了过期时间的键空间中，优先移除最近未使用的key。</li>
<li><code>allkeys-random</code>：在主键空间中，随机移除某个key。</li>
<li><code>volatile-random</code>：在设置了过期时间的键空间中，随机移除某个key。</li>
<li><code>volatile-ttl</code>：在设置了过期时间的键空间中，具有更早过期时间的key优先移除。</li>
</ul>
<blockquote>
<p>这里补充一下主键空间和设置了过期时间的键空间，举个例子，假设我们有一批键存储在Redis中，则有那么一个哈希表用于存储这批键及其值，如果这批键中有一部分设置了过期时间，那么这批键还会被存储到另外一个哈希表中，这个哈希表中的值对应的是键被设置的过期时间。设置了过期时间的键空间为主键空间的子集。</p>
</blockquote>
<h4 id="非精准的lru">非精准的LRU</h4>
<p>上面提到的LRU（Least Recently Used）策略，实际上 <strong>Redis 实现的 LRU 并不是可靠的 LRU</strong>，也就是名义上我们使用LRU算法淘汰键，但是实际上被淘汰的键并不一定是真正的最久没用的，这里涉及到一个权衡的问题，如果需要在全部键空间内搜索最优解，则必然会增加系统的开销，Redis是单线程的，也就是同一个实例在每一个时刻只能服务于一个客户端，所以耗时的操作一定要谨慎。</p>
<p>为了在一定成本内实现相对的LRU，早期的 Redis 版本是 <strong>基于采样的 LRU</strong> ，也就是放弃全部键空间内搜索解改为采样空间搜索最优解。自从 Redis3.0 版本之后，Redis 作者对于基于采样的 LRU 进行了一些优化，目的是在一定的成本内让结果更靠近真实的 LRU。</p>
</article>
 

      <footer class="book-footer">
        
  <div class="flex justify-between">



  <div>
    
    <a class="flex align-center" href="https://github.com/hadyang/interview/commit/fe1f5123fa0dea3c34db80fe37d3a0b656d722d7" title='Last modified by haoyang.shi | 2020-03-10' target="_blank" rel="noopener">
      <img src="/interview/svg/calendar.svg" class="book-icon" alt="Calendar" />
      <span>2020-03-10</span>
    </a>
  </div>



  <div>
    <a class="flex align-center" href="https://github.com/hadyang/interview/edit/master/content/docs/basic/database/redis/index.md" target="_blank" rel="noopener">
      <img src="/interview/svg/edit.svg" class="book-icon" alt="Edit" />
      <span>Edit this page</span>
    </a>
  </div>

</div>

 
        
  
  <div class="book-comments">

</div>
  
 
      </footer>
      
    </div>

    
    <aside class="book-toc">
      
  <nav id="TableOfContents">
  <ul>
    <li><a href="#线程模型">线程模型</a>
      <ul>
        <li><a href="#为啥-redis-单线程模型也能效率这么高">为啥 Redis 单线程模型也能效率这么高？</a></li>
      </ul>
    </li>
    <li><a href="#持久化">持久化</a>
      <ul>
        <li><a href="#rdb">RDB</a></li>
        <li><a href="#aof">AOF</a></li>
        <li><a href="#rdb-和-aof-到底该如何选择">RDB 和 AOF 到底该如何选择</a></li>
      </ul>
    </li>
    <li><a href="#一致性哈希算法">一致性哈希算法</a>
      <ul>
        <li><a href="#需求">需求</a></li>
        <li><a href="#实现">实现</a></li>
      </ul>
    </li>
    <li><a href="#实践httpsyikungithubio20160609e4b880e887b4e680a7e59388e5b88ce7ae97e6b395e79a84e79086e8a7a3e4b88ee5ae9ee8b7b5">实践</a>
      <ul>
        <li></li>
      </ul>
    </li>
    <li><a href="#集群">集群</a>
      <ul>
        <li><a href="#主从复制">主从复制</a></li>
        <li><a href="#哨兵">哨兵</a></li>
        <li><a href="#redis-cluster">Redis Cluster</a></li>
      </ul>
    </li>
    <li><a href="#数据结构">数据结构</a>
      <ul>
        <li><a href="#string">string</a></li>
        <li><a href="#zset底层实现">zset底层实现</a></li>
        <li><a href="#bitmap-实现">BitMap 实现</a></li>
      </ul>
    </li>
    <li><a href="#缓存穿透缓存击穿缓存雪崩">缓存穿透、缓存击穿、缓存雪崩</a>
      <ul>
        <li><a href="#缓存穿透">缓存穿透</a></li>
        <li><a href="#缓存雪崩">缓存雪崩</a></li>
        <li><a href="#缓存击穿">缓存击穿</a></li>
      </ul>
    </li>
    <li><a href="#redis分布式锁">Redis分布式锁</a></li>
    <li><a href="#数据淘汰机制">数据淘汰机制</a>
      <ul>
        <li><a href="#对象过期">对象过期</a></li>
        <li><a href="#内存淘汰">内存淘汰</a></li>
      </ul>
    </li>
  </ul>
</nav>

 
    </aside>
    
  </main>

  
</body>

</html>












