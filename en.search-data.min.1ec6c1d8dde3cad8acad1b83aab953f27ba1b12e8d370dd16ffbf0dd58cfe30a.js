'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/interview/docs/architecture/concurrent/','title':"Concurrent",'content':""});index.add({'id':1,'href':'/interview/docs/basic/','title':"Basic",'content':"计算机基础 "});index.add({'id':2,'href':'/interview/docs/basic/database/sql/','title':"SQL",'content':"SQL 连接 在 MySQL 中 JOIN、 CROSS JOIN 、 INNER JOIN 是等价的，都是内连接。\n内连接  JOIN、 CROSS JOIN 、 INNER JOIN 当使用这三个子句时，其结果都是笛卡尔积； 如果以上三个子句加上 ON，则为 等值连接：只会返回 ON 子句相等的结果  外连接 外连接分为 LEFT JOIN 、 RIGHT JOIN 和 NATURAL JOIN，所有外连接均可省略 OUTER 关键字，即 LEFT OUTER JOIN...ON... 与 LEFT JOIN...ON...等效。\n T1 LEFT JOIN T2 ON T1.id=T2.id：左外连接，返回所有列、T1 所有行、T2 中 条件符合的行 T1 RIGHT JOIN T2 ON T1.id=T2.id：右外连接，返回所有列、T2 所有行、T1 中 条件符合的行 T1 NATURAL JOIN T2：自然连接，返回 T1 所有行、T2 中与 T1 匹配的行，相同的属性被合并  对于自然连接要多做说明，现在有表 join_test1 、join_test2：\nmysql\u0026gt; select * from join_test1; +----+------+ | id | name | +----+------+ | 1 | A | | 2 | B | | 3 | C | +----+------+ 3 rows in set (0.00 sec) mysql\u0026gt; select * from join_test2; +----+------+ | id | sex | +----+------+ | 1 | 男 | | 2 | 女 | | 4 | 男 | +----+------+ 3 rows in set (0.00 sec) 自然连接的结果：\nmysql\u0026gt; select * from join_test1 NATURAL join join_test2; +----+------+------+ | id | name | sex | +----+------+------+ | 1 | A | 男 | | 2 | B | 女 | +----+------+------+ 上面三种子句，又可组合出 NATURAL LEFT|RIGHT JOIN...：这种子句就结合了 NATURAL JOIN 和 LEFT|RIGHT JOIN..ON... 的特点：在执行左|右连接的同时，将相同属性合并。\nmysql\u0026gt; select * from join_test1 NATURAL left join join_test2; +----+------+------+ | id | name | sex | +----+------+------+ | 1 | A | 男 | | 2 | B | 女 | | 3 | C | NULL | +----+------+------+ 3 rows in set (0.00 sec) 子查询 子查询作为标量 SELECT (SELECT s2 FROM t1); 子查询比较 non_subquery_operand comparison_operator (subquery)\n= \u0026gt; \u0026lt; \u0026gt;= \u0026lt;= \u0026lt;\u0026gt; != \u0026lt;=\u0026gt; LIKE\nANY IN SOME operand comparison_operator ANY (subquery) operand IN (subquery) operand comparison_operator SOME (subquery) EXISTS or NOT EXISTS SELECT column1 FROM t1 WHERE EXISTS (SELECT * FROM t2); ALL operand comparison_operator ALL (subquery)\nSELECT s1 FROM t1 WHERE s1 \u0026gt; ALL (SELECT s1 FROM t2); 关联查询 SELECT * FROM t1 WHERE column1 = ANY (SELECT column1 FROM t2 WHERE t2.column2 = t1.column2); select Score, (select count(distinct Score) from Scores b where b.Score\u0026gt;= s.Score) Rank from Scores s order by Score desc 派生表 SELECT ... FROM (subquery) [AS] tbl_name ... "});index.add({'id':3,'href':'/interview/docs/architecture/concurrent/design/','title':"高并发系统设计",'content':"高并发系统设计 总览 在高并发的情景下进行系统设计，\n可以分为以下 6 点：\n 系统拆分  熔断 降级   缓存 MQ 分库分表 读写分离 ElasticSearch  系统拆分 将一个系统拆分为多个子系统，用 RPC 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。\n缓存 大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟 Redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。\nMQ 可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改。那高并发绝对搞挂你的系统，你要是用 Redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 MySQL 还得用 MySQL 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，后边系统消费后慢慢写，控制在 MySQL 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。\n分库分表 分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 SQL 跑的性能。\n读写分离 读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。\nElasticSearch ES 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 ES 来承载，还有一些全文搜索类的操作，也可以考虑用 ES 来承载。\n参考链接  如何设计一个高并发系统？  "});index.add({'id':4,'href':'/interview/docs/basic/database/mysql/','title':"Mysql",'content':""});index.add({'id':5,'href':'/interview/docs/basic/database/mysql/innodb/','title':"Innodb",'content':""});index.add({'id':6,'href':'/interview/docs/basic/database/mysql/innodb/transaction/','title':"InnoDB 事务",'content':"InnoDB 事务隔离 几种隔离级别 事务的隔离性是数据库处理数据的几大基础之一，而隔离级别其实就是提供给用户用于在性能和可靠性做出选择和权衡的配置项。\nISO 和 ANIS SQL 标准制定了四种事务隔离级别，而 InnoDB 遵循了 SQL:1992 标准中的四种隔离级别：READ UNCOMMITED、READ COMMITED、REPEATABLE READ 和 SERIALIZABLE；每个事务的隔离级别其实都比上一级多解决了一个问题：\n  RAED UNCOMMITED：使用查询语句不会加锁，可能会读到未提交的行（Dirty Read）；\n 可以读取未提交记录。此隔离级别，不会使用，忽略。\n   READ COMMITED：只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read）；\n 快照读忽略，本文不考虑。针对当前读，RC隔离级别保证对读取到的记录加锁 (记录锁)，存在幻读现象。\n   REPEATABLE READ：快照读忽略，本文不考虑。针对当前读，RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)，不存在幻读现象。\n  SERIALIZABLE：从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。\n Serializable隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。\n   MySQL 中默认的事务隔离级别就是 REPEATABLE READ，但是它通过 Next-Key 锁也能够在某种程度上解决幻读的问题。\n接下来，我们将数据库中创建如下的表并通过个例子来展示在不同的事务隔离级别之下，会发生什么样的问题：\n CREATE TABLE test( id INT NOT NULL, UNIQUE(id) ); 脏读  在一个事务中，读取了其他事务未提交的数据。\n 当事务的隔离级别为 READ UNCOMMITED 时，我们在 SESSION 2 中插入的未提交数据在 SESSION 1 中是可以访问的。\n不可重复读  在一个事务中，同一行记录被访问了两次却得到了不同的结果。\n 当事务的隔离级别为 READ COMMITED 时，虽然解决了脏读的问题，但是如果在 SESSION 1 先查询了一行数据，在这之后 SESSION 2 中修改了同一行数据并且提交了修改，在这时，如果 SESSION 1 中再次使用相同的查询语句，就会发现两次查询的结果不一样。\n不可重复读的原因就是，在 READ COMMITED 的隔离级别下，存储引擎不会在查询记录时添加行锁，锁定 id = 3 这条记录。\n幻读  在一个事务中，同一个范围内的记录被读取时，其他事务向这个范围添加了新的记录。\n 重新开启了两个会话 SESSION 1 和 SESSION 2，在 SESSION 1 中我们查询全表的信息，没有得到任何记录；在 SESSION 2 中向表中插入一条数据并提交；由于 REPEATABLE READ 的原因，再次查询全表的数据时，我们获得到的仍然是空集，但是在向表中插入同样的数据却出现了错误。\n这种现象在数据库中就被称作幻读，虽然我们使用查询语句得到了一个空的集合，但是插入数据时却得到了错误，好像之前的查询是幻觉一样。\n在标准的事务隔离级别中，幻读是由更高的隔离级别 SERIALIZABLE 解决的，但是它也可以通过 MySQL 提供的 Next-Key 锁解决：\nREPEATABLE READ 和 READ UNCOMMITED 其实是矛盾的，如果保证了前者就看不到已经提交的事务，如果保证了后者，就会导致两次查询的结果不同，MySQL 为我们提供了一种折中的方式，能够在 REPEATABLE READ 模式下加锁访问已经提交的数据，其本身并不能解决幻读的问题，而是通过文章前面提到的 Next-Key 锁来解决。\n"});index.add({'id':7,'href':'/interview/docs/basic/database/mysql/innodb/concurrent/','title':"InnoDB 并发控制",'content':"InnoDB 并发控制 InnoDB 锁机制 InnoDB默认使用行锁，实现了两种标准的行锁——共享锁与排他锁；\n|行锁类型| 锁功能|锁兼容性| 加锁|释放锁| | :\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | :\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | |共享锁（读锁、S锁）| 允许获取共享锁的亊务读数据|与共享锁兼容，与排它锁不兼容| 只有 SerializaWe 隔离级别会默认为：读加共享锁；其他隔离级别下，可显示使用 select...lock in share model 为读加共享锁| 在事务提交或回滚后会自动同时释放锁；除了使用 start transaction 的方式显式开启事务，InnoDB 也会自动为增删改査语句开启事务，并自动提交或回滚；(autocommit=1)| |排它锁（写锁、X锁）|允许获取排它锁的事务更新或删除数据|与共享锁不兼容，与排它锁不兼容|在默认的 Reapeatable Read 隔离级别下，InnoDB 会自动为增删改操作的行加排它锁；也可显式使用 select...for update 为读加排它锁|\u0026hellip;|\n  除了显式加锁的情况，其他情况下的加锁与解锁都无需人工干预 InnoDB 所有的行锁算法都是基于索引实现的，锁定的也都是索引或索引区间   当前读 \u0026amp; 快照读 当前读：即加锁读，读取记录的最新版本，会加锁保证其他并发事务不能修改当前记录，直至获取锁的事务释放锁；使用当前读的操作主要包括：显式加锁的读操作与插入/更新/删除等写操作，如下所示：\nselect * from table where ? lock in share mode; select * from table where ? for update; insert into table values (…); update table set ? where ?; delete from table where ?;  注：当 Update SQL 被发给 MySQL 后， MySQL Server 会根据where条件，读取第一条满足条件的记录，然后 InnoDB 引擎会将第一条记录返回，并加锁，待 MySQL Server 收到这条加锁的记录之后，会再发起一个 Update 请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此， Update 操作内部，就包含了当前读。同理， Delete 操作也一样。 Insert 操作会稍微有些不同，简单来说，就是 Insert 操作可能会触发 Unique Key 的冲突检查，也会进行一个当前读。\n 快照读：即不加锁读，读取记录的快照版本而非最新版本，通过MVCC实现；\nInnoDB 默认的 RR 事务隔离级别下，不显式加lock in share mode与for update的 select 操作都属于快照读，保证事务执行过程中只有第一次读之前提交的修改和自己的修改可见，其他的均不可见；\n共享锁与独占锁 意向锁 InnoDB 支持多粒度的锁，允许表级锁和行级锁共存。一个类似于 LOCK TABLES ... WRITE 的语句会获得这个表的 x 锁。为了实现多粒度锁，InnoDB 使用了意向锁（简称 I 锁）。I 锁是表明一个事务稍后要获得针对一行记录的某种锁（s or x）的对应表的表级锁，有两种：\n 意向排它锁（简称 IX 锁）表明一个事务意图在某个表中设置某些行的 x 锁 意向共享锁（简称 IS 锁）表明一个事务意图在某个表中设置某些行的 s 锁  SELECT ... LOCK IN SHARE MODE 设置一个 IS 锁, SELECT ... FOR UPDATE 设置一个 IX 锁。意向锁的原则如下：\n 一个事务必须先持有该表上的 IS 或者更强的锁才能持有该表中某行的 S 锁 一个事务必须先持有该表上的 IX 锁才能持有该表中某行的 X 锁  新请求的锁只有兼容已有锁才能被允许，否则必须等待不兼容的已有锁被释放。一个不兼容的锁请求不被允许是因为它会引起死锁，错误会发生。意向锁只会阻塞全表请求（比如 LOCK TABLES ... WRITE ）。意向锁的主要目的是展示某人正在锁定表中一行，或者将要锁定一行。\nRecord Lock 记录锁（Record Lock）是加到索引记录上的锁，假设我们存在下面的一张表 users：\n CREATE TABLE users( id INT NOT NULL AUTO_INCREMENT, last_name VARCHAR(255) NOT NULL, first_name VARCHAR(255), age INT, PRIMARY KEY(id), KEY(last_name), KEY(age) ); 如果我们使用 id 或者 last_name 作为 SQL 中 WHERE 语句的过滤条件，那么 InnoDB 就可以通过索引建立的 B+ 树找到行记录并添加索引，但是如果使用 first_name 作为过滤条件时，由于 InnoDB 不知道待修改的记录具体存放的位置，也无法对将要修改哪条记录提前做出判断就会锁定整个表。\nGap Lock 记录锁是在存储引擎中最为常见的锁，除了记录锁之外，InnoDB 中还存在间隙锁（Gap Lock），间隙锁是对索引记录中的一段连续区域的锁；当使用类似 SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE; 的 SQL 语句时，就会阻止其他事务向表中插入 id = 15 的记录，因为整个范围都被间隙锁锁定了。\n 间隙锁是存储引擎对于性能和并发做出的权衡，并且只用于某些事务隔离级别。\n 虽然间隙锁中也分为共享锁和互斥锁，不过它们之间并不是互斥的，也就是不同的事务可以同时持有一段相同范围的共享锁和互斥锁，它唯一阻止的就是其他事务向这个范围中添加新的记录。\n间隙锁的缺点  间隙锁有一个比较致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害 当Query无法利用索引的时候， InnoDB会放弃使用行级别锁定而改用表级别的锁定，造成并发性能的降低； 当Quuery使用的索引并不包含所有过滤条件的时候，数据检索使用到的索引键所指向的数据可能有部分并不属于该Query的结果集的行列，但是也会被锁定，因为间隙锁锁定的是一个范围，而不是具体的索引键； 当Query在使用索引定位数据的时候，如果使用的索引键一样但访问的数据行不同的时候（索引只是过滤条件的一部分），一样会被锁定  Next-Key Lock Next-Key 锁相比前两者就稍微有一些复杂，它是记录锁和记录前的间隙锁的结合，在 users 表中有以下记录：\n +------|-------------|--------------|-------+ | id | last_name | first_name | age | |------|-------------|--------------|-------| | 4 | stark | tony | 21 | | 1 | tom | hiddleston | 30 | | 3 | morgan | freeman | 40 | | 5 | jeff | dean | 50 | | 2 | donald | trump | 80 | +------|-------------|--------------|-------+ 如果使用 Next-Key 锁，那么 Next-Key 锁就可以在需要的时候锁定以下的范围：\n (-∞, 21] (21, 30] (30, 40] (40, 50] (50, 80] (80, ∞)  既然叫 Next-Key 锁，锁定的应该是当前值和后面的范围，但是实际上却不是，Next-Key 锁锁定的是当前值和前面的范围。\n 当我们更新一条记录，比如 SELECT * FROM users WHERE age = 30 FOR UPDATE;，InnoDB 不仅会在范围 (21, 30] 上加 Next-Key 锁，还会在这条该记录索引增长方向的范围 (30, 40] 加间隙锁，所以插入 (21, 40] 范围内的记录都会被锁定。\n Next-Key 锁的作用其实是为了解决幻读的问题。\n 插入意向锁 插入意向锁是在插入一行记录操作之前设置的一种间隙锁，这个锁释放了一种插入方式的信号，亦即多个事务在相同的索引间隙插入时如果不是插入间隙中相同的位置就不需要互相等待。假设有索引值4、7，几个不同的事务准备插入5、6，每个锁都在获得插入行的独占锁之前用插入意向锁各自锁住了4、7之间的间隙，但是不阻塞对方因为插入行不冲突。\n自增锁 自增锁是一个特殊的表级锁，事务插入自增列的时候需要获取，最简单情况下如果一个事务插入一个值到表中，任何其他事务都要等待，这样第一个事物才能获得连续的主键值。\n锁选择 +——-+————-+ | id | name | +——-+————-+ | 1 | title1 | +——-+————-+ | 2 | title2 | +——-+————-+ | 3 | title3 | +——-+————-+ | 9 | title9 | +——-+————-+ | 10 | title10 | +——-+————-+ 按照原理来说，id\u0026gt;5 and id\u0026lt;7这个查询条件，在表中找不到满足条件的项，因此会对第一个不满足条件的项(id = 9)上加GAP锁，防止后续其他事务插入满足条件的记录。\n而 GAP 锁与GAP 锁是不冲突的，那么为什么两个同时执行id\u0026gt;5 and id\u0026lt;7查询的事务会冲突呢？\n原因在于，MySQL Server并没有将id\u0026lt;7这个查询条件下降到InnoDB引擎层，因此InnoDB看到的查询，是id\u0026gt;5，正向扫描。读出的记录id=9，先加上next key锁(Lock X + GAP lock)，然后返回给 MySQL Server 进行判断。 MySQL Server 此时才会判断返回的记录是否满足id\u0026lt;7的查询条件。此处不满足，查询结束。\n因此，id=9记录上，真正持有的锁是next key锁，而next key锁之间是相互冲突的，这也说明了为什么两个id\u0026gt;5 and id\u0026lt;7查询的事务会冲突的原因。\nMVCC InnoDB 引擎支持 MVCC(Multiversion Concurrency Control)：InnoDB 保存了行的历史版本，以支持事务的并发控制和回滚。这些历史信息保存在表空间的 回滚段（Rollback Segment） 里，回滚段中存储着 Undo Log。当事务需要进行回滚时，InnoDB 就会使用这些信息来进行 Undo 操作，同时这些信息也可用来实现 一致性读。\nInnoDB 在存储的每行数据中都增加了三列隐藏属性：\n DB_TRX_ID：最后一次插入或更新的事务ID DB_ROLL_PTR：指向已写入回滚段的 Undo Log 记录。如果这行记录是更新的，那么就可以根据这个 Undo Log 记录重建之间的数据 DB_ROW_ID：自增序列，如果表未指定主键，则由该列作为主键  在回滚段的 Undo Log 被分为 Insert Undo Log 和 Update Undo Log。Insert Undo Log 只是在事务回滚的时候需要，在事务提交后就可丢弃。Update Undo Log 不仅仅在回滚的时候需要，还要提供一致性读，所以只有在所有需要该 Update Undo Log 构建历史版本数据的事务都提交后才能丢弃。MySQL 建议尽量频繁的提交事务，这样可以保证 InnoDB 快速的丢弃 Update Undo Log，防止其过大。\n在 InnoDB 中，行数据的物理删除不是立刻执行，InnoDB 会在行删除的 Undo Log 被丢弃时才会进行物理删除。这个过程被称之为 清理（Purge），其执行过程十分迅速。\nMVCC 二级索引 InnoDB 在更新时对 二级索引 和 聚集索引的处理方式不一样。在聚集索引上的更新是原地更新（in-place），其中的隐藏属性 DB_ROLL_PTR 指向的 Undo Log 可以重建历史数据。但是二级索引没有隐藏属性，所以不能原地更新。\n当二级索引的数据被更新时，旧的二级索引记录标记为 标记删除（delete-marked），然后插入一条新的索引记录，最终标记删除的索引记录会被清除。当二级索引记录被标记为 delete-marked 或者有更新的事务更新时，InnoDB 会查找聚集索引。在聚集索引中检查行的 DB_TRX_ID，如果事务修改了记录，则从 Undo Log 中构建行数据的正确版本。如果二级索引记录被标记为 delete-marked 或者 二级索引有更新的事务更新，覆盖索引技术不会被使用（获取行任意数据均需要回表）。\nMVCC vs 乐观锁 MVCC 并不是一个与乐观和悲观并发控制对立的东西，它能够与两者很好的结合以增加事务的并发量，在目前最流行的 SQL 数据库 MySQL 和 PostgreSQL 中都对 MVCC 进行了实现；但是由于它们分别实现了悲观锁和乐观锁，所以 MVCC 实现的方式也不同。\nMVCC 可以保证不阻塞地读到一致的数据。但是，MVCC 并没有对实现细节做约束，为此不同的数据库的语义有所不同，比如：\n  postgres 对写操作也是乐观并发控制；在表中保存同一行数据记录的多个不同版本，每次写操作，都是创建，而回避更新；在事务提交时，按版本号检查当前事务提交的数据是否存在写冲突，则抛异常告知用户，回滚事务；\n  innodb 则只对读无锁，写操作仍是上锁的悲观并发控制，这也意味着，innodb 中只能见到因死锁和不变性约束而回滚，而见不到因为写冲突而回滚，不像 postgres 那样对数据修改在表中创建新纪录，而是每行数据只在表中保留一份，在更新数据时上行锁，同时将旧版数据写入 undo log。表和 undo log 中行数据都记录着事务ID，在检索时，只读取来自当前已提交的事务的行数据。\n  可见 MVCC 中的写操作仍可以按悲观并发控制实现，而 CAS 的写操作只能是乐观并发控制。还有一个不同在于，MVCC 在语境中倾向于 “对多行数据打快照造平行宇宙”，然而 CAS 一般只是保护单行数据而已。比如 mongodb 有 CAS 的支持，但不能说这是 MVCC。\n"});index.add({'id':8,'href':'/interview/docs/basic/database/mysql/innodb/index/','title':"InnoDB 索引",'content':"InnoDB 索引 数据存储 当 InnoDB 存储数据时，它可以使用不同的行格式进行存储；MySQL 5.7 版本支持以下格式的行存储方式：\n Antelope 是 InnoDB 最开始支持的文件格式，它包含两种行格式 Compact 和 Redundant ，它最开始并没有名字； Antelope 的名字是在新的文件格式 Barracuda 出现后才起的， Barracuda 的出现引入了两种新的行格式 Compressed 和 Dynamic ；InnoDB 对于文件格式都会向前兼容，而官方文档中也对之后会出现的新文件格式预先定义好了名字：Cheetah、Dragon、Elk 等等。\n 两种行记录格式 Compact 和 Redundant 在磁盘上按照以下方式存储：\nCompact 和 Redundant 格式最大的不同就是记录格式的第一个部分；在 Compact 中，行记录的第一部分倒序存放了一行数据中列的长度（Length），而 Redundant 中存的是每一列的偏移量（Offset），从总体上上看， Compact 行记录格式相比 Redundant 格式能够减少 20% 的存储空间。\n行溢出数据 当 InnoDB 使用 Compact 或者 Redundant 格式存储极长的 VARCHAR 或者 BLOB 这类大对象时，我们并不会直接将所有的内容都存放在数据页节点中，而是将数据中的前 768 个字节存储在数据页中，后面会通过偏移量指向溢出页（off-page），最大768字节的作用是便于创建 前缀索引。溢出页（off-page）不存储在 B+tree 中，使用的是uncompress BLOB page，并且每个字段的溢出都是存储独享。\n但是当我们使用新的行记录格式 Compressed 或者 Dynamic 时都只会在行记录中保存 20 个字节的指针，实际的数据都会存放在溢出页面中。\n当然在实际存储中，可能会对不同长度的 TEXT 和 BLOB 列进行优化。\n 想要了解更多与 InnoDB 存储引擎中记录的数据格式的相关信息，可以阅读 InnoDB Record Structure\n 数据页结构 与现有的大多数存储引擎一样，InnoDB 使用页作为磁盘管理的最小单位；数据在 InnoDB 存储引擎中都是按行存储的，每个 16KB 大小的页中可以存放 2-200 行的记录。\n页是 InnoDB 存储引擎管理数据的最小磁盘单位，而 B-Tree 节点就是实际存放表中数据的页面，我们在这里将要介绍页是如何组织和存储记录的；首先，一个 InnoDB 页有以下七个部分：\n每一个页中包含了两对 header/trailer：内部的 Page Header/Page Directory 关心的是页的状态信息，而 Fil Header/Fil Trailer 关心的是记录页的头信息。\n在页的头部和尾部之间就是用户记录和空闲空间了，每一个数据页中都包含 Infimum 和 Supremum 这两个虚拟的记录（可以理解为占位符）， Infimum 记录是比该页中任何主键值都要小的值， Supremum 是该页中的最大值：\nUser Records 就是整个页面中真正用于存放行记录的部分，而 Free Space 就是空余空间了，它是一个链表的数据结构，为了保证插入和删除的效率，整个页面并不会按照主键顺序对所有记录进行排序，它会自动从左侧向右寻找空白节点进行插入，行记录在物理存储上并不是按照顺序的，它们之间的顺序是由 next_record 这一指针控制的。\nB+ 树在查找对应的记录时，并不会直接从树中找出对应的行记录，它只能获取记录所在的页，将整个页加载到内存中，再通过 Page Directory 中存储的稀疏索引和 n_owned、next_record 属性取出对应的记录，不过因为这一操作是在内存中进行的，所以通常会忽略这部分查找的耗时。这样就存在一个命中率的问题，如果一个page中能够相对的存放足够多的行，那么命中率就会相对高一些，性能就会有提升。\nB+树底层的叶子节点为一双向链表，因此 每个页中至少应该有两行记录，这就决定了 InnoDB 在存储一行数据的时候不能够超过 8kb，但事实上应该更小，因为还有一些 InnoDB 内部数据结构要存储。\n通常我们认为 blob 这类的大对象的存储会把数据存放在 off-page，其实不然，关键点还是要看一个 page 中到底能否存放两行数据，blob 可以完全存放在数据页中(单行长度没有超过 8kb)，而 varchar 类型的也有可能存放在溢出页中(单行长度超过 8kb，前 768byte 存放在数据页中)。\n索引 索引是数据库中非常非常重要的概念，它是存储引擎能够快速定位记录的秘密武器，对于提升数据库的性能、减轻数据库服务器的负担有着非常重要的作用；索引优化是对查询性能优化的最有效手段，它能够轻松地将查询的性能提高几个数量级。\nInnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，这是关系型数据库中查找最为常用和有效的索引，但是 B+ 树索引并不能找到一个给定键对应的具体值，它只能找到数据行对应的页，然后正如上一节所提到的，数据库把整个页读入到内存中，并在内存中查找具体的数据行。\nB+ 树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是 B+ 树的高度；\n B+ 树的叶子节点存放所有指向关键字的指针，节点内部关键字记录和节点之间都根据关键字的大小排列。当顺序递增插入的时候，只有最后一个节点会在满掉的时候引起索引分裂，此时无需移动记录，只需创建一个新的节点即可。而当非递增插入的时候，会使得旧的节点分裂，还可能伴随移动记录，以便使得新数据能够插入其中。一般建议使用一列顺序递增的 ID 来作为主键，但不必是数据库的 autoincrement 字段，只要满足顺序增加即可，如 twitter 的 snowflake 即为顺序递增的 ID 生成器。\n B+ 树的高度 这里我们先假设 B+ 树高为2，即存在一个根节点和若干个叶子节点，那么这棵 B+ 树的存放总记录数为：根节点指针数*单个叶子节点记录行数。这里假设一行记录的大小为1k，那么一个页上的能放 16 行数据。假设主键ID为 bigint 类型，长度为 8 字节，而指针大小在 InnoDB 源码中设置为 6 字节，这样一共14字节，那么可以算出一棵高度为 2 的 B+ 树，能存放   \\(16 \\times 1024\\div 14\\times 16=18720\\)  条这样的数据记录。\n根据同样的原理我们可以算出一个高度为3的B+树可以存放： \\(1170\\times 1170\\times 16=21,902,400\\)  条这样的记录。所以在 InnoDB 中 B+ 树高度一般为 1~3 层，它就能满足千万级的数据存储。\n聚集索引 InnoDB 存储引擎中的表都是使用索引组织的，也就是按照键的顺序存放；聚集索引就是按照表中主键的顺序构建一颗 B+ 树，并在叶节点中存放表中的行记录数据。\n 如果没有定义主键，则会使用非空的 UNIQUE键 做主键 ; 如果没有非空的 UNIQUE键 ，则系统生成一个6字节的 rowid 做主键;\n CREATE TABLE users( id INT NOT NULL, first_name VARCHAR(20) NOT NULL, last_name VARCHAR(20) NOT NULL, age INT NOT NULL, PRIMARY KEY(id), KEY(last_name, first_name, age) KEY(first_name) ); 如果使用上面的 SQL 在数据库中创建一张表，B+ 树就会使用 id 作为索引的键，并在叶子节点中存储一条记录中的所有信息。\n 图中对 B+ 树的描述与真实情况下 B+ 树中的数据结构有一些差别，不过这里想要表达的主要意思是：聚集索引叶节点中保存的是整条行记录，而不是其中的一部分。\n 聚集索引与表的物理存储方式有着非常密切的关系，所有正常的表应该 有且仅有一个 聚集索引（绝大多数情况下都是主键），表中的所有行记录数据都是按照 聚集索引 的顺序存放的。\n当我们使用聚集索引对表中的数据进行检索时，可以直接获得聚集索引所对应的整条行记录数据所在的页，不需要进行第二次操作。\n辅助索引 数据库将 所有的非聚集索引都划分为辅助索引，但是这个概念对我们理解辅助索引并没有什么帮助；辅助索引也是通过 B+ 树实现的，但是它的叶节点并不包含行记录的全部数据，仅包含索引中的所有键和一个用于查找对应行记录的『书签』，在 InnoDB 中这个书签就是当前记录的主键。\n辅助索引的存在并不会影响聚集索引，因为聚集索引构成的 B+ 树是数据实际存储的形式，而辅助索引只用于加速数据的查找，所以一张表上往往有多个辅助索引以此来提升数据库的性能。\n 一张表一定包含一个聚集索引构成的 B+ 树以及若干辅助索引的构成的 B+ 树。\n 如果在表 users 中存在一个辅助索引 (first_name, age)，那么它构成的 B+ 树大致就是上图这样，按照 (first_name, age) 的字母顺序对表中的数据进行排序，当查找到主键时，再通过聚集索引获取到整条行记录。\n上图展示了一个使用辅助索引查找一条表记录的过程：通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录，这也是通常情况下行记录的查找方式。\n覆盖索引 聚簇索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录，这种行为被称之为 回表。回表会导致查询时多次读取磁盘，为减少IO MySQL 在辅助索引上进行优化，将辅助索引作为 覆盖索引（Covering index）。在查询的时候，如果 SELECT 子句中的字段为主键、辅助索引的键则不进行回表。\n索引失效 索引并不是时时都会生效的，比如以下几种情况，将导致索引失效：\n 如果条件中有 or，即使其中有条件带索引也不会使用。要想使用or，又想让索引生效，只能将 or 条件中的每个列都加上索引 对于多列索引，不是使用的最左匹配，则不会使用索引。 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不使用索引。 如果 mysql 估计使用全表扫描要比使用索引快，则不使用索引。例如，使用\u0026lt;\u0026gt;、not in 、not exist，对于这三种情况大多数情况下认为结果集很大，MySQL 就有可能不使用索引。  索引使用  (7) - SELECT (8) - DISTINCT \u0026lt;select_list\u0026gt; (1) - FROM \u0026lt;left_table\u0026gt; (3) - \u0026lt;join_type\u0026gt; JOIN \u0026lt;right_table\u0026gt; (2) - ON \u0026lt;join_condition\u0026gt; (4) - WHERE \u0026lt;where_condition\u0026gt; (5) - GROUP BY \u0026lt;group_by_list\u0026gt; (6) - HAVING \u0026lt;having_condition\u0026gt; (9) - ORDER BY \u0026lt;order_by_condition\u0026gt; (10) - LIMIT \u0026lt;limit_number\u0026gt;  关于 SQL 语句的执行顺序，有三个值得我们注意的地方：\n FROM 才是 SQL 语句执行的第一步，并非 SELECT。 数据库在执行 SQL 语句的第一步是将数据从硬盘加载到数据缓冲区中，以便对这些数据进行操作。 SELECT 是在大部分语句执行了之后才执行的，严格的说是在 FROM 和 GROUP BY 之后执行的。理解这一点是非常重要的，这就是你不能在 WHERE 中使用在 SELECT 中设定别名的字段作为判断条件的原因。 无论在语法上还是在执行顺序上， UNION 总是排在在 ORDER BY 之前。很多人认为每个 UNION 段都能使用 ORDER BY 排序，但是根据 SQL 语言标准和各个数据库 SQL 的执行差异来看，这并不是真的。尽管某些数据库允许 SQL 语句对子查询（subqueries）或者派生表（derived tables）进行排序，但是这并不说明这个排序在 UNION 操作过后仍保持排序后的顺序。  虽然SQL的逻辑查询是根据上述进行查询，但是数据库也许并不会完全按照逻辑查询处理的方式来进行查询。 MySQL 数据库有两个组件 Parser（分析SQL语句）和 Optimizer（优化）。\n从官方手册上看，可以理解为， MySQL 采用了基于开销的优化器，以确定处理查询的最解方式，也就是说执行查询之前，都会先选择一条自以为最优的方案，然后执行这个方案来获取结果。在很多情况下， MySQL 能够计算最佳的可能查询计划，但在某些情况下， MySQL 没有关于数据的足够信息，或者是提供太多的相关数据信息，估测就不那么友好了。\n存在索引的情况下，优化器优先使用条件用到索引且最优的方案。当 SQL 条件有多个索引可以选择， MySQL 优化器将直接使用效率最高的索引执行。\n"});index.add({'id':9,'href':'/interview/docs/basic/database/mysql/sharding/','title':"分库分表",'content':"分库分表 目前绝大多数应用采取的两种分库分表规则\n mod方式 dayofweek系列日期方式（所有星期1的数据在一个库/表,或所有?月份的数据在一个库表）  这两种方式有个本质的特点，就是 离散性加周期性。例如以一个表的主键对 3 取余数的方式分库或分表：\n那么随着数据量的增大，每个表或库的数据量都是各自增长。当一个表或库的数据量增长到了一个极限，要加库或加表的时候， 介于这种分库分表算法的离散性，必需要做数据迁移才能完成。例如从3个扩展到5个的时候：\n需要将原先以 mod3 分类的数据，重新以 mod5 分类，不可避免的带来数据迁移。每个表的数据都要被重新分配到多个新的表 相似的例子比如从 dayofweek 分的 7 个库/表,要扩张为以 dayofmonth 分的 31 张库/表，同样需要进行数据迁移。\n数据迁移带来的问题是\n 业务至少要两次发布 要专门写工具来导数据。由于各业务之间的差别，很难做出统一的工具。目前几乎都是每个业务写一套 要解决增量、全量、时间点，数据不一致等问题  如何在数据量扩张到现有库表极限，加库加表时避免数据迁移呢？\n通常的数据增长往往是随着时间的推移增长的。随着业务的开展，时间的推移，数据量不断增加。\n考虑到数据增长的特点，如果我们以代表时间增长的字段，按递增的范围分库，则可以避免数据迁移。这样的方式下，在数据量再增加达到前几个库/表的上限时，则继续水平增加库表，原先的数据就不需要迁移了。但是这样的方式会带来一个 热点问题：当前的数据量达到某个库表的范围时，所有的插入操作，都集中在这个库/表了。\n所以在满足基本业务功能的前提下，分库分表方案应该尽量避免的两个问题：\n 数据迁移 热点  如何既能避免数据迁移又能避免插入更新的热点问题呢？\n结合离散分库/分表和连续分库/分表的优点，如果一定要写热点和新数据均匀分配在每个库，同时又保证易于水平扩展，可以考虑这样的模式：\n水平扩展scale-out方案 \u0026ndash; 模式一 阶段一 一个库 DB0 之内分4个表，id%4 ：\n阶段二 增加 DB1 库，t2和t3整表搬迁到 DB1\n阶段三 增加 DB2 和 DB3 库，t1 整表搬迁到 DB2 ，t3整表搬迁的 DB3：\n为了规则表达，通过内部名称映射或其他方式，我们将DB1和DB2的名称和位置互换得到下图：\ndbRule: “DB” + (id % 4) tbRule: “t” + (id % 4) 即逻辑上始终保持4库4表，每个表一个库。这种做法也是目前店铺线图片空间采用的做法。\n上述方案有一个缺点，就是在从一个库到 4 个库的过程中，单表的数据量一直在增长。当单表的数据量超过一定范围时，可能会带来性能问题。比如索引的问题，历史数据清理的问题。另外当开始预留的表个数用尽，到了 4 物理库每库 1 个表的阶段，再进行扩容的话，不可避免的要从表上下手。\n水平扩展scale-out方案 \u0026ndash; 模式二 阶段一 一个数据库，两个表，rule0 = id % 2\n分库规则dbRule: “DB0″ 分表规则tbRule: “t” + (id % 2) 阶段二 当单库的数据量接近 1千万，单表的数据量接近 500 万时，进行扩容（数据量只是举例，具体扩容量要根据数据库和实际压力状况决定）：增加一个数据库 DB1，将 DB0.t0 整表迁移到新库 DB1.t1。每个库各增加1个表，未来10M-20M的数据mod2分别写入这2个表：t0_1，t1_1：\n分库规则dbRule:\n“DB” + (id % 2) 分表规则tbRule:\n if(id \u0026lt; 1千万){ return \u0026quot;t\u0026quot;+ (id % 2); //1千万之前的数据，仍然放在t0和t1表。t1表从DB0搬迁到DB1库 }else if(id \u0026lt; 2千万){ return \u0026quot;t\u0026quot;+ (id % 2) +\u0026quot;_1\u0026quot;; //1千万之后的数据，各放到两个库的两个表中: t0_1,t1_1 }else{ throw new IllegalArgumentException(\u0026quot;id outof range[20000000]:\u0026quot; + id); } 这样 10M 以后的新生数据会均匀分布在 DB0 和 DB1; 插入更新和查询热点仍然能够在每个库中均匀分布。每个库中同时有老数据和不断增长的新数据。每表的数据仍然控制在 500万 以下。\n阶段三 当两个库的容量接近上限继续水平扩展时，进行如下操作：\n 新增加两个库：DB2和DB3，以id % 4分库。余数0、1、2、3分别对应DB的下标. t0和t1不变， 将DB0.t0_1整表迁移到DB2; 将DB1.t1_1整表迁移到DB3  20M-40M的数据 mod4 分为 4 个表：t0_2，t1_2，t2_2，t3_2，分别放到4个库中：\n新的分库分表规则如下：\n分库规则dbRule:\n if(id \u0026lt; 2千万){ //2千万之前的数据，4个表分别放到4个库 if(id \u0026lt; 1千万){ return \u0026quot;db\u0026quot;+ (id % 2); //原t0表仍在db0, t1表仍在db1 }else{ return \u0026quot;db\u0026quot;+ ((id % 2) +2); //原t0_1表从db0搬迁到db2; t1_1表从db1搬迁到db3 } }else if(id \u0026lt; 4千万){ return \u0026quot;db\u0026quot;+ (id % 4); //超过2千万的数据，平均分到4个库 }else{ throw new IllegalArgumentException(\u0026quot;id out of range. id:\u0026quot;+id); } 分表规则tbRule:\n if(id \u0026lt; 2千万){ //2千万之前的数据，表规则和原先完全一样，参见阶段二 if(id \u0026lt; 1千万){ return \u0026quot;t\u0026quot;+ (id % 2); //1千万之前的数据，仍然放在t0和t1表 }else{ return \u0026quot;t\u0026quot;+ (id % 2) +\u0026quot;_1\u0026quot;; //1千万之后的数据，仍然放在t0_1和t1_1表 } }else if(id \u0026lt; 4千万){ return \u0026quot;t\u0026quot;+ (id % 4)+\u0026quot;_2\u0026quot;; //超过2千万的数据分为4个表t0_2，t1_2，t2_2，t3_2 }else{ throw new IllegalArgumentException(\u0026quot;id out of range. id:\u0026quot;+id); } 随着时间的推移，当第一阶段的t0/t1，第二阶段的t0_1/t1_1逐渐成为历史数据，不再使用时，可以直接truncate掉整个表。省去了历史数据迁移的麻烦。\n水平扩展scale-out方案 \u0026ndash; 模式三 非倍数扩展：如果从上文的阶段二到阶段三不希望一下增加两个库呢？尝试如下方案：\n迁移前：\n新增库为DB2，t0、t1都放在 DB0，\nt0_1整表迁移到 DB1 t1_1整表迁移到 DB2 迁移后：\n这时 DB0 退化为旧数据的读库和更新库。新增数据的热点均匀分布在 DB1 和 DB2 4无法整除3，因此如果从4表2库扩展到3个库，不做行级别的迁移而又保证热点均匀分布看似无法完成。\n当然如果不限制每库只有两个表，也可以如下实现：\n小于 10M 的 t0 和 t1 都放到 DB0 ，以 mod2 分为两个表，原数据不变 10M-20M的，以 mod2 分为两个表 t0_1、t1_1，原数据不变，分别搬迁到 DB1 ，和 DB2 20M 以上的以 mod3 平均分配到 3 个 DB 库的 t_0、t_2、t_3表中\n这样 DB1 包含最老的两个表，和最新的 1/3 数据。DB1 和 DB2 都分表包含次新的两个旧表 t0_1、t1_1 和最新的 1/3 数据。新旧数据读写都可达到均匀分布。\n总结 总而言之，两种规则映射（函数）：\n 离散映射：如mod或dayofweek， 这种类型的映射能够很好的解决热点问题，但带来了数据迁移和历史数据问题。 连续映射；如按id或gmt_create_time的连续范围做映射。这种类型的映射可以避免数据迁移，但又带来热点问题。  离散映射和连续映射这两种相辅相成的映射规则，正好解决热点和迁移这一对相互矛盾的问题。\n我们之前只运用了离散映射，引入连续映射规则后，两者结合，精心设计，应该可以设计出满足避免热点和减少迁移之间任意权衡取舍的规则。\n基于以上考量，分库分表规则的设计和配置，长远说来必须满足以下要求\n 可以动态推送修改 规则可以分层级叠加，旧规则可以在新规则下继续使用，新规则是旧规则在更宽尺度上的拓展，以此支持新旧规则的兼容，避免数据迁移 用 mod 方式时，最好选 2 的指数级倍分库分表，这样方便以后切割。  全局ID  数据库自增 id 设置数据库 sequence 或者表自增字段步长 UUID 获取系统当前时间 Snowflake 算法  Snowflake twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id ，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id ，12 bit 作为序列号。\n|–1位符号位–|--41位时间戳–|--10位机器ID–|--12位序列号–|\n 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。 41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 2^41 - 1，也就是可以标识 2^41 - 1 个毫秒值，换算成年就是表示69年的时间。 10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 2^5个机房（32个机房），每个机房里可以代表 2^5 个机器（32台机器）。 12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 2^12 - 1 = 4096，也就是说可以用这个 12 bit 代表的数字来区分同一个毫秒内的 4096 个不同的 id。  Snowflake 的问题 Snowflake 这样依赖时间的ID生成算法注定存在一个问题：时间的准确度问题。这一算法有一个默认前提：分布式环境下时间获取总是准确的，即时间总是递增的。而现实环境中，这样的条件很难满足。总会因为硬件、软件、人的原因造成时间变化。如果你的硬件时间本身就比正常时间快，而你接入了一个 NTP 服务，每当进行 NTP 时间校准时，你的机器时间总会向后 回拨 一段时间，这时悲剧就来了：有极大可能性生成重复ID。\n针对上面提到的两个问题，可如下改进：\n 时间戳由毫秒变为秒 使用环形列表对时间戳对应的序列进行缓存 使用CAS操作避免大粒度悲观锁  为了 缓解 时钟回拨问题，对之前的序列进行缓存，而原生算法很显然是不利于缓存的，最坏的情况下每秒需要缓存 1000 个值，这显然对内存很不友好。于是我将时间戳改为秒为单位，同时可以把省出来的位交给序列。此时缓存一个小时的数据（即可以容忍一个小时的时钟回拨）也就只需要缓存 3600 个序列，完全可以接受。改进后的 Snowflake 生成的ID是这样组成的：\n|–1位符号位–|--32位时间戳–|--10位机器ID–|--21位序列号–|\n 环形列表：即整个列表的容量是一定的，当列表满了以后再加入的元素会按照入列的先后顺序覆盖之前的元素。\n "});index.add({'id':10,'href':'/interview/docs/basic/database/mysql/architecture/','title':"MySQL 架构",'content':"MySQL 架构 总体来说 MySQL 可以分为两层，第一层是 MySQL 的服务层，包含 MySQL 核心服务功能：解析、分析、优化、缓存以及内置函数，所有跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等。\n第二层是 MySQL 的 存储引擎层，MySQL 中可使用多种存储引擎：InnoDB、MyISAM、Memory。存储引擎负责 MySQL 中数据的存取。服务层通过统一的 API 与存储引擎进行通信，这些 API 屏蔽来同步存储引擎之间的差异，使得这些差异对上层的查询过程透明。\nMySQL Server 连接器 连接器负责跟客户端建立连接、获取权限、维持和管理连接。\n查询缓存 查询缓存将查询结果按 K-V 的形式进行缓存，K 是查询的语句，V 是查询的结果。当一个表发生更新后，该表对应的所有缓存均会失效。\n分析器 分析器有两个功能：词法分析、语法分析。对于一个 SQL 语句，分析器首先进行词法分析，对 SQL 语句进行拆分，识别出各个字符串代表的含义。然后就是语法分析，分析器根据定义的语法规则判断 SQL 是否满足 MySQL 语法。\n优化器 优化器在获取到分析器的结果后，通过表结构和 SQL 语句选择执行方案，比如：多表关联时，各个表如何进行连接；当表中有索引时，应该怎样选择索引 等等。\n执行器 获取到执行方案后，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。在进行查询时，MySQL 执行器内部执行步骤如下：\n 调用引擎接口取这个表的第一行，判断该行是否满足 WHERE 子句，如果满足则将这行存在结果集中，否则跳过。 调用引擎接口取下一行，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。  对于走索引的查询，执行的逻辑也差不多。第一次调用的是 取满足条件的第一行 这个接口，之后循环取 满足条件的下一行 这个接口，这些接口都是引擎中已经定义好的。\nUpdate 处理逻辑 这里简单的分析下 Update 的处理逻辑\n MySQL Server 发送更新请求到 InnoDB 引擎 从 Buffer Pool 加载对应记录的 Data Page（P1）  若 Buffer Pool 中没有该记录，则从磁盘加载该记录   将 P1 存储到 Undo Page 中，并在 Redo Log Buffer 中记录 Undo 操作 更新 P1 为 P1\u0026rsquo; ，并将 P1\u0026rsquo; 写入 Dirty Page ，记录变更到 Redo Log Buffer（Prepare 状态） 返回 MySQL Server 执行完成 MySQL Server 记录 binlog MySQL Server 提交 Commit Redo Log Buffer 状态有 Prepare 更改为 Commit，并刷入磁盘 当 Dirty Page 过多时，启动 ChcekPoint 机制，将脏页刷入磁盘  "});index.add({'id':11,'href':'/interview/docs/java/jvm/','title':"Jvm",'content':""});index.add({'id':12,'href':'/interview/docs/java/jvm/gc/','title':"垃圾回收",'content':"垃圾回收 对象存活检测 Java堆中存放着大量的Java对象实例，在垃圾收集器回收内存前，第一件事情就是确定哪些对象是活着的，哪些是可以回收的。\n引用计数算法 引用计数算法是判断对象是否存活的基本算法：给每个对象添加一个引用计数器，没当一个地方引用它的时候，计数器值加1；当引用失效后，计数器值减1。但是这种方法有一个致命的缺陷，当两个对象相互引用时会导致这两个都无法被回收。\n根搜索算法 引用计数是通过为堆中每个对象保存一个计数来区分活动对象和垃圾。根搜索算法实际上是追踪从根结点开始的 引用图。\n在根搜索算法追踪的过程中，起点即 GC Root，GC Root 根据 JVM 实现不同而不同，但是总会包含以下几个方面：\n 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中的类静态属性引用的变量。 方法区中的常量引用的变量。 本地方法 JNI 的引用对象。  根搜索算法是从 GC Root 开始的引用图，引用图是一个有向图，其中节点是各个对象，边为引用类型。JVM 中的引用类型分为四种：强引用（StrongReference）、软引用（SoftReference）、弱引用（WeakReference） 和 虚引用（PhantomReference）。\n除强引用外，其他引用在Java 由 Reference 的子类封装了指向其他对象的连接：被指向的对象称为 引用目标。\n若一个对象的引用类型有多个，那到底如何判断它的回收策略呢？其实规则如下：\n 单条引用链以链上最弱的一个引用类型来决定； 多条引用链以多个单条引用链中最强的一个引用类型来决定；  在引用图中，当一个节点没有任何路径可达时，我们认为它是可回收的对象。\nStrongReference 强引用在Java中是普遍存在的，类似 Object o = new Object(); 。强引用和其他引用的区别在于：强引用禁止引用目标被垃圾收集器收集，而其他引用不禁止。\nSoftReference 对象可以从根节点通过一个或多个(未被清除的)软引用对象触及，垃圾收集器在要发生内存溢出前将这些对象列入回收范围中进行回收，如果该软引用对象和引用队列相关联，它会把该软引用对象加入队列。\nJVM 的实现需要在抛出 OutOfMemoryError 之前清除 SoftReference，但在其他的情况下可以选择清理的时间或者是否清除它们。\nWeakReference 对象可以从 GC Root 开始通过一个或多个(未被清除的)弱引用对象触及， 垃圾收集器在 GC 的时候会回收所有的 WeakReference，如果该弱引用对象和引用队列相关联，它会把该弱引用对象加入队列。\nPhantomReference 垃圾收集器在 GC 不会清除 PhantomReference，所有的虚引用都必须由程序明确的清除。同时也不能通过虚引用来取得一个对象的实例。\n垃圾回收算法 复制回收算法 将可用内存分为大小相等的两份，在同一时刻只使用其中的一份。当这一份内存使用完了，就将还存活的对象复制到另一份上，然后将这一份上的内存清空。复制算法能有效避免内存碎片，但是算法需要将内存一分为二，导致内存使用率大大降低。\n标记清除算法 先暂停整个程序的全部运行线程，让回收线程以单线程进行扫描标记，并进行直接清除回收，然后回收完成后，恢复运行线程。标记清除后会产生大量不连续的内存碎片，造成空间浪费。\n标记整理算法 和 标记清除 相似，不同的是，回收期间同时会将保留的存储对象搬运汇集到连续的内存空间，从而集成空闲空间。\n增量回收 需要程序将所拥有的内存空间分成若干分区（Region）。程序运行所需的存储对象会分布在这些分区中，每次只对其中一个分区进行回收操作，从而避免程序全部运行线程暂停来进行回收，允许部分线程在不影响回收行为而保持运行，并且降低回收时间，增加程序响应速度。\n分代回收 在 JVM 中不同的对象拥有不同的生命周期，因此对于不同生命周期的对象也可以采用不同的垃圾回收算法，以提高效率，这就是分代回收算法的核心思想。\n垃圾回收触发条件 堆内内存 针对 HotSpot VM 的实现，它里面的 GC 其实准确分类只有两大种：\n Partial GC：并不收集整个 GC 堆的模式  Young GC（Minor GC）：只收集 Young Gen 的 GC Old GC：只收集 Old Gen 的 GC。只有 CMS的 Concurrent Collection 是这个模式 Mixed GC：收集整个 Young Gen 以及部分 Old Gen 的 GC。只有 G1 有这个模式   Full GC（Major GC）：收集整个堆，包括 Young Gen、Old Gen、Perm Gen（如果存在的话）等所有部分的 GC 模式。  最简单的分代式GC策略，按 HotSpot VM 的 serial GC 的实现来看，触发条件是\n Young GC：当 Young Gen 中的 eden 区分配满的时候触发。把 Eden 区存活的对象将被复制到一个 Survivor 区，当这个 Survivor 区满时，此区的存活对象将被复制到另外一个 Survivor 区。 Full GC：  当准备要触发一次 Young GC 时，如果发现之前 Young GC 的平均晋升大小比目前 Old Gen剩余的空间大，则不会触发 Young GC 而是转为触发 Full GC  除了 CMS 的 Concurrent Collection 之外，其它能收集 Old Gen 的GC都会同时收集整个 GC 堆，包括 Young Gen，所以不需要事先触发一次单独的Young GC\n  如果有 Perm Gen 的话，要在 Perm Gen分配空间但已经没有足够空间时 System.gc() Heap dump    并发 GC 的触发条件就不太一样。以 CMS GC 为例，它主要是定时去检查 Old Gen 的使用量，当使用量超过了触发比例就会启动一次 GC，对 Old Gen做并发收集。\n堆外内存 DirectByteBuffer 的引用是直接分配在堆得 Old 区的，因此其回收时机是在 FullGC 时。因此，需要避免频繁的分配 DirectByteBuffer ，这样很容易导致 Native Memory 溢出。\nDirectByteBuffer 申请的直接内存，不再GC范围之内，无法自动回收。JDK 提供了一种机制，可以为堆内存对象注册一个钩子函数(其实就是实现 Runnable 接口的子类)，当堆内存对象被GC回收的时候，会回调run方法，我们可以在这个方法中执行释放 DirectByteBuffer 引用的直接内存，即在run方法中调用 Unsafe 的 freeMemory 方法。注册是通过sun.misc.Cleaner 类来实现的。\n垃圾收集器 垃圾收集器是内存回收的具体实现，下图展示了 7 种用于不同分代的收集器，两个收集器之间有连线表示可以搭配使用，每种收集器都有最适合的使用场景。\nSerial 收集器 Serial 收集器是最基本的收集器，这是一个单线程收集器，它只用一个线程去完成垃圾收集工作。\n虽然 Serial 收集器的缺点很明显，但是它仍然是 JVM 在 Client 模式下的默认新生代收集器。它有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比较），Serial 收集器由于没有线程交互的开销，专心只做垃圾收集自然也获得最高的效率。在用户桌面场景下，分配给 JVM 的内存不会太多，停顿时间完全可以在几十到一百多毫秒之间，只要收集不频繁，这是完全可以接受的。\nParNew 收集器 ParNew 是 Serial 的多线程版本，在回收算法、对象分配原则上都是一致的。ParNew 收集器是许多运行在Server 模式下的默认新生代垃圾收集器，其主要与 CMS 收集器配合工作。\nParallel Scavenge 收集器 Parallel Scavenge 收集器是一个新生代垃圾收集器，也是并行的多线程收集器。\nParallel Scavenge 收集器更关注可控制的吞吐量，吞吐量等于运行用户代码的时间/(运行用户代码的时间+垃圾收集时间)。\nSerial Old收集器 Serial Old 收集器是 Serial 收集器的老年代版本，也是一个单线程收集器，采用“标记-整理算法”进行回收。\nParallel Old 收集器 Parallel Old 收集器是 Parallel Scavenge 收集器的老年代版本，使用多线程进行垃圾回收，其通常与 Parallel Scavenge 收集器配合使用。\nCMS 收集器 CMS（Concurrent Mark Sweep）收集器是一种以获取最短停顿时间为目标的收集器， CMS 收集器采用 标记--清除 算法，运行在老年代。主要包含以下几个步骤：\n 初始标记 并发标记 重新标记 并发清除  其中初始标记和重新标记仍然需要 Stop the world。初始标记仅仅标记 GC Root 能直接关联的对象，并发标记就是进行 GC Root Tracing 过程，而重新标记则是为了修正并发标记期间，因用户程序继续运行而导致标记变动的那部分对象的标记记录。\n由于整个过程中最耗时的并发标记和并发清除，收集线程和用户线程一起工作，所以总体上来说， CMS 收集器回收过程是与用户线程并发执行的。虽然 CMS 优点是并发收集、低停顿，很大程度上已经是一个不错的垃圾收集器，但是还是有三个显著的缺点：\n  CMS收集器对CPU资源很敏感：在并发阶段，虽然它不会导致用户线程停顿，但是会因为占用一部分线程（CPU资源）而导致应用程序变慢。\n  CMS收集器不能处理浮动垃圾：所谓的“浮动垃圾”，就是在并发标记阶段，由于用户程序在运行，那么自然就会有新的垃圾产生，这部分垃圾被标记过后，CMS 无法在当次集中处理它们，只好在下一次 GC 的时候处理，这部分未处理的垃圾就称为“浮动垃圾”。\n  GC 后产生大量内存碎片：当内存碎片过多时，将会给分配大对象带来困难，这是就会进行 Full GC。\n  正是由于在垃圾收集阶段程序还需要运行，即还需要预留足够的内存空间供用户使用，因此 CMS 收集器不能像其他收集器那样等到老年代几乎填满才进行收集，需要预留一部分空间提供并发收集时程序运作使用。要是 CMS 预留的内存空间不能满足程序的要求，这是 JVM 就会启动预备方案：临时启动 Serial Old 收集器来收集老年代，这样停顿的时间就会很长。\nG1收集器 G1收集器与CMS相比有很大的改进：\n 标记整理算法：G1 收集器采用标记整理算法实现 增量回收模式：将 Heap 分割为多个 Region，并在后台维护一个优先列表，每次根据允许的时间，优先回收垃圾最多的区域  因此 G1 收集器可以实现在基本不牺牲吞吐量的情况下完成低停顿的内存回收，这是正是由于它极力的避免全区域的回收。\n   垃圾收集器 特性 算法 优点 缺点     Serial 串行 复制 高效：无线程切换 无法利用多核CPU   ParNew 并行 复制 可利用多核CPU、唯一能与CMS配合的并行收集器    Parallel Scavenge 并行 复制 高吞吐量    Serial Old 串行 标记整理 高效 无法利用多核CPU   Parallel Old 并行 标记整理 高吞吐量    CMS 并行 标记清除 低停顿 CPU敏感、浮动垃圾、内存碎片   G1 并行 增量回收 低停顿、高吞吐量 内存使用效率低：分区导致内存不能充分使用    "});index.add({'id':13,'href':'/interview/docs/java/jvm/architecture/','title':"JVM 架构",'content':"JVM 架构 Java 源码通过 javac 编译为 Java 字节码 ，Java 字节码是 Java 虚拟机执行的一套代码格式，其抽象了计算机的基本操作。大多数指令只有一个字节，而有些操作符需要参数，导致多使用了一些字节。\nJVM 的基本架构如上图所示，其主要包含三个大块：\n 类加载器：负责动态加载Java类到Java虚拟机的内存空间中。 运行时数据区：存储 JVM 运行时所有数据 执行引擎：提供 JVM 在不同平台的运行能力  线程 在 JVM 中运行着许多线程，这里面有一部分是应用程序创建来执行代码逻辑的 应用线程，剩下的就是 JVM 创建来执行一些后台任务的 系统线程。\n主要的系统线程有：\n Compile Threads：运行时将字节码编译为本地代码所使用的线程 GC Threads：包含所有和 GC 有关操作 Periodic Task Thread：JVM 周期性任务调度的线程，主要包含 JVM 内部的采样分析 Singal Dispatcher Thread：处理 OS 发来的信号 VM Thread：某些操作需要等待 JVM 到达 安全点（Safe Point），即堆区没有变化。比如：GC 操作、线程 Dump、线程挂起 这些操作都在 VM Thread 中进行。  按照线程类型来分，在 JVM 内部有两种线程：\n  守护线程：通常是由虚拟机自己使用，比如 GC 线程。但是，Java程序也可以把它自己创建的任何线程标记为守护线程（public final void setDaemon(boolean on)来设置，但必须在start()方法之前调用）。\n  非守护线程：main方法执行的线程，我们通常也称为用户线程。\n  只要有任何的非守护线程在运行，Java程序也会继续运行。当该程序中所有的非守护线程都终止时，虚拟机实例将自动退出（守护线程随 JVM 一同结束工作）。\n守护线程中不适合进行IO、计算等操作，因为守护线程是在所有的非守护线程退出后结束，这样并不能判断守护线程是否完成了相应的操作，如果非守护线程退出后，还有大量的数据没来得及读写，这将造成很严重的后果。\n"});index.add({'id':14,'href':'/interview/docs/java/jvm/classloader/','title':"类加载器",'content':"类加载器 类加载器是 Java 运行时环境（Java Runtime Environment）的一部分，负责动态加载 Java 类到 Java 虚拟机的内存空间中。类通常是按需加载，即第一次使用该类时才加载。 由于有了类加载器，Java 运行时系统不需要知道文件与文件系统。每个 Java 类必须由某个类加载器装入到内存。\n类装载器除了要定位和导入二进制 class 文件外，还必须负责验证被导入类的正确性，为变量分配初始化内存，以及帮助解析符号引用。这些动作必须严格按一下顺序完成：\n 装载：查找并装载类型的二进制数据。 链接：执行验证、准备以及解析(可选) - 验证：确保被导入类型的正确性 - 准备：为类变量分配内存，并将其初始化为默认值。 - 解析：把类型中的符号引用转换为直接引用。 初始化：把类变量初始化为正确的初始值。  装载 类加载器分类 在Java虚拟机中存在多个类装载器，Java应用程序可以使用两种类装载器：\n Bootstrap ClassLoader：此装载器是 Java 虚拟机实现的一部分。由原生代码（如C语言）编写，不继承自 java.lang.ClassLoader 。负责加载核心 Java 库，启动类装载器通常使用某种默认的方式从本地磁盘中加载类，包括 Java API。 Extention Classloader：用来在\u0026lt;JAVA_HOME\u0026gt;/jre/lib/ext ,或 java.ext.dirs 中指明的目录中加载 Java 的扩展库。 Java 虚拟机的实现会提供一个扩展库目录。 Application Classloader：根据 Java应用程序的类路径（ java.class.path 或 CLASSPATH 环境变量）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader() 来获取它。 自定义类加载器：可以通过继承 java.lang.ClassLoader 类的方式实现自己的类加载器，以满足一些特殊的需求而不需要完全了解 Java 虚拟机的类加载的细节。  全盘负责双亲委托机制 在一个 JVM 系统中，至少有 3 种类加载器，那么这些类加载器如何配合工作？在 JVM 种类加载器通过 全盘负责双亲委托机制 来协调类加载器。\n 全盘负责：指当一个 ClassLoader 装载一个类的时，除非显式地使用另一个 ClassLoader ，该类所依赖及引用的类也由这个 ClassLoader 载入。 双亲委托机制：指先委托父装载器寻找目标类，只有在找不到的情况下才从自己的类路径中查找并装载目标类。  全盘负责双亲委托机制只是 Java 推荐的机制，并不是强制的机制。实现自己的类加载器时，如果想保持双亲委派模型，就应该重写 findClass(name) 方法；如果想破坏双亲委派模型，可以重写 loadClass(name) 方法。\n装载入口 所有Java虚拟机实现必须在每个类或接口首次主动使用时初始化。以下六种情况符合主动使用的要求：\n 当创建某个类的新实例时(new、反射、克隆、序列化) 调用某个类的静态方法 使用某个类或接口的静态字段，或对该字段赋值(用final修饰的静态字段除外，它被初始化为一个编译时常量表达式) 当调用Java API的某些反射方法时。 初始化某个类的子类时。 当虚拟机启动时被标明为启动类的类。  除以上六种情况，所有其他使用Java类型的方式都是被动的，它们不会导致Java类型的初始化。\n对于接口来说，只有在某个接口声明的非常量字段被使用时，该接口才会初始化，而不会因为事先这个接口的子接口或类要初始化而被初始化。\n父类需要在子类初始化之前被初始化。当实现了接口的类被初始化的时候，不需要初始化父接口。然而，当实现了父接口的子类(或者是扩展了父接口的子接口)被装载时，父接口也要被装载。(只是被装载，没有初始化)\n验证 确认装载后的类型符合Java语言的语义，并且不会危及虚拟机的完整性。\n 装载时验证：检查二进制数据以确保数据全部是预期格式、确保除 Object 之外的每个类都有父类、确保该类的所有父类都已经被装载。 正式验证阶段：检查 final 类不能有子类、确保 final 方法不被覆盖、确保在类型和超类型之间没有不兼容的方法声明(比如拥有两个名字相同的方法，参数在数量、顺序、类型上都相同，但返回类型不同)。 符号引用的验证：当虚拟机搜寻一个被符号引用的元素(类型、字段或方法)时，必须首先确认该元素存在。如果虚拟机发现元素存在，则必须进一步检查引用类型有访问该元素的权限。  准备 在准备阶段，Java虚拟机为类变量分配内存，设置默认初始值。但在到到初始化阶段之前，类变量都没有被初始化为真正的初始值。\n   类型 默认值     int 0   long 0L   short (short)0   char \u0026rsquo;\\u0000\u0026rsquo;   byte (byte)0   blooean false   float 0.0f   double 0.0d   reference null    解析 解析的过程就是在类型的常量池总寻找类、接口、字段和方法的符号引用，把这些符号引用替换为直接引用的过程。\n  类或接口的解析：判断所要转化成的直接引用是数组类型，还是普通的对象类型的引用，从而进行不同的解析。\n  字段解析：对字段进行解析时，会先在本类中查找是否包含有简单名称和字段描述符都与目标相匹配的字段，如果有，则查找结束；如果没有，则会按照继承关系从上往下递归搜索该类所实现的各个接口和它们的父接口，还没有，则按照继承关系从上往下递归搜索其父类，直至查找结束，\n  初始化 所有的类变量(即静态量)初始化语句和类型的静态初始化器都被Java编译器收集在一起，放到一个特殊的方法中。 对于类来说，这个方法被称作类初始化方法；对于接口来说，它被称为接口初始化方法。在类和接口的 class 文件中，这个方法被称为\u0026lt;clinit\u0026gt;。\n 如果存在直接父类，且直接父类没有被初始化，先初始化直接父类。 如果类存在一个类初始化方法，执行此方法。  这个步骤是递归执行的，即第一个初始化的类一定是Object。\nJava虚拟机必须确保初始化过程被正确地同步。 如果多个线程需要初始化一个类，仅仅允许一个线程来进行初始化，其他线程需等待。\n 这个特性可以用来写单例模式。\n Clinit 方法  对于静态变量和静态初始化语句来说：执行的顺序和它们在类或接口中出现的顺序有关。 并非所有的类都需要在它们的class文件中拥有\u0026lt;clinit\u0026gt;()方法， 如果类没有声明任何类变量，也没有静态初始化语句，那么它就不会有\u0026lt;clinit\u0026gt;()方法。如果类声明了类变量，但没有明确的使用类变量初始化语句或者静态代码块来初始化它们，也不会有\u0026lt;clinit\u0026gt;()方法。如果类仅包含静态final常量的类变量初始化语句，而且这些类变量初始化语句采用编译时常量表达式，类也不会有\u0026lt;clinit\u0026gt;()方法。只有那些需要执行Java代码来赋值的类才会有\u0026lt;clinit\u0026gt;() final常量：Java虚拟机在使用它们的任何类的常量池或字节码中直接存放的是它们表示的常量值。  "});index.add({'id':15,'href':'/interview/docs/java/jvm/runtime_area/','title':"运行时数据区",'content':"运行时数据区 运行时数据区用于保存 JVM 在运行过程中产生的数据，结构如图所示：\nHeap Java 堆是可供各线程共享的运行时内存区域，是 Java 虚拟机所管理的内存区域中最大的一块。此区域非常重要，几乎所有的对象实例和数组实例都要在 Java 堆上分配，但随着 JIT 编译器及逃逸分析技术的发展，也可能会被优化为栈上分配。\nHeap 中除了作为对象分配使用，还包含字符串字面量 常量池（Internd Strings） 。 除此之外 Heap 中还包含一个 新生代（Yong Generation）、一个 老年代（Old Generation）。\n新生代分三个区，一个Eden区，两个Survivor区，大部分对象在Eden区中生成。Survivor 区总有一个是空的。\n老年代中保存一些生命周期较长的对象，当一个对象经过多次的 GC 后还没有被回收，那么它将被移动到老年代。\nMethoad Area 方法区的数据由所有线程共享，因此为安全的使用方法区的数据，需要注意线程安全问题。\n方法区主要保存类级别的数据，包括：\n ClassLoader Reference Runtime Constant Pool  数字常量 类属性引用 方法引用   Field Data：每个类属性的名称、类型等 Methoad Data：每个方法的名称、返回值类型、参数列表等 Methoad Code：每个方法的字节码、本地变量表等  方法区的实现在不同的 JVM 版本有不同，在 JVM 1.8 之前，方法区的实现为 永久代（PermGen），但是由于永久代的大小限制， 经常会出现内存溢出。于是在 JVM 1.8 方法区的实现改为 元空间（Metaspace），元空间是在 Native 的一块内存空间。\nStack 对于每个 JVM 线程，当线程启动时，都会分配一个独立的运行时栈，用以保存方法调用。每个方法调用，都会在栈顶增加一个栈帧（Stack Frame）。\n每个栈帧都保存三个引用：本地变量表（Local Variable Array）、 操作数栈（Operand Stack） 和 当前方法所属类的运行时常量池（Runtime Constant Pool）。由于本地变量表和操作数栈的大小都在编译时确定，所以栈帧的大小是固定的。\n当被调用的方法返回或抛出异常，栈帧会被弹出。在抛出异常时 printStackTrace() 打印的每一行就是一个栈帧。同时得益于栈帧的特点，栈帧内的数据是线程安全的。\n栈的大小可以动态扩展，但是如果一个线程需要的栈大小超过了允许的大小，就会抛出 StackOverflowError。\nPC Register 对于每个 JVM 线程，当线程启动时，都会有一个独立的 PC（Program Counter） 计数器，用来保存当前执行的代码地址（方法区中的内存地址）。如果当前方法是 Native 方法，PC 的值为 NULL。一旦执行完成，PC 计数器会被更新为下一个需要执行代码的地址。\nNative Method Stack 本地方法栈和 Java 虚拟机栈的作用相似，Java 虚拟机栈执行的是字节码，而本地方法栈执行的是 native 方法。本地方法栈使用传统的栈（C Stack）来支持 native 方法。\nDirect Memory Native Memory Tracking\n在 JDK 1.4 中新加入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为 避免了在 Java 堆和 Native 堆中来回复制数据。\n"});index.add({'id':16,'href':'/interview/docs/architecture/bigdata/','title':"Bigdata",'content':""});index.add({'id':17,'href':'/interview/docs/java/concurrent/','title':"Concurrent",'content':""});index.add({'id':18,'href':'/interview/docs/java/concurrent/atomic/','title':"AtomicInteger",'content':"AtomicInteger AtomicInteger 是 Java 中常见的原子类，每种基础类型都对应 Atomic***。AtomicInteger 中最重要的就属于原子更新操作，这里我们来分析下 getAndAdd 的实现。\nprivate static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { //获取 value 的偏移量  valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\u0026#34;value\u0026#34;)); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; public final int getAndAdd(int delta) { //调用 unsafe.getAndAddInt  return unsafe.getAndAddInt(this, valueOffset, delta); } getAndAdd 中直接调用 unsafe.getAndAddInt，原子更新的逻辑都在 UnSafe 类中：\npublic final int getAndAddInt(Object var1, long var2, int var4) { int var5; //循环 CAS  do { //获取 volatile 字段值  var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } getAndAdd 就是通过循环CAS，来执行原子更新的逻辑。\nABA 问题 CAS 并不是万能的，CAS 更新有 ABA 问题。即 T1 读取内存变量为 A ,T2 修改内存变量为 B ,T2 修改内存变量为 A ,这时 T1 再 CAS 操作 A 时是可行的。但实际上在 T1 第二次操作 A 时，已经被其他线程修改过了。举一个现实情况下的例子：\n小明账户上有100元。现在小明取钱，小强汇钱，诈骗分子盗刷三个动作同时进行。\n 小明取50元。 诈骗分子盗刷50元。 小强给小明汇款50元。  此时，银行交易系统出问题，每笔交易无法通过短信告知小明。ABA问题就是：\n 小明验证账户上有100元后，取出50元。—— 账上有50元。 小强不会验证小明账户的余额，直接汇款50元。—— 账上有100元。 诈骗分子验证账户有100元后，取出50元。—— 账上有50元。  小强没有告诉小明自己汇钱，小明也没收到短信，那么小明就一直以为只有自己取款操作，最后损失了50元。\nAtomicStampedReference 对于 ABA 问题，比较有效的方案是引入版本号，内存中的值每发生一次变化，版本号都 +1；在进行CAS操作时，不仅比较内存中的值，也会比较版本号，只有当二者都没有变化时，CAS才能执行成功。 AtomicStampedReference 便是使用版本号来解决ABA问题的。类似的还有 AtomicMarkableReference ， AtomicStampedReference 是使用 pair 的 int stamp 作为计数器使用， AtomicMarkableReference 的 pair 使用的是 boolean mark。\n"});index.add({'id':19,'href':'/interview/docs/architecture/bigdata/algo/','title':"大数据基础算法",'content':"Bloom filter 适用范围 实现数据字典，进行数据的判重，或者集合求交集\n基本原理 　对于原理来说很简单，Bit-Map + K个独立 Hash 函数。将 Hash 函数对应的值的位数组置1，查找时如果发现所有 Hash 函数对应位都是1说明存在。很明显这个过程并不保证查找的结果是 100% 正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是 Counting Bloom filter，用一个 Counter 数组代替位数组，就可以支持删除了。\n对于元素个数：   \\(n\\)  ，错误率（假阳率）： \\(P\\)  。我们可以计算：\n Bit-Map 大小： \\(m\\ge -\\frac{n\\times ln^P}{(ln^2)^2}\\)   Hash 函数个数： \\(k=log_2^\\frac{1}{P}\\)     参数在线计算工具：https://hur.st/bloomfilter\n 举个例子我们假设 \\(P=0.01\\)  ， \\(n=4000\\)  ，则此时 m 应大概是 \\(9.5\\times n=38000\\)  bit， \\(k=7\\)  注意这里 m 与 n 的单位不同，m是 bit 为单位，而n则是以元素个数为单位(准确的说是不同元素的个数)。通常单个元素的长度都是有很多 bit 的。所以使用bloom filter内存上通常都是节省的。\n扩展 　Bloom filter 将集合中的元素映射到位数组中，用 k 个映射位是否全1表示元素在不在这个集合中。Counting bloom filter（CBF）将 位数组中的每一位扩展为一个 Counter，从而支持了元素的删除操作。Spectral Bloom Filter（SBF）将其与集合元素的出现次数关联。SBF采用 Counter 中的最小值来近似表示元素的出现频率。\n问题实例 给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？\n答：根据这个问题我们来计算下内存的占用，4G=2^32大概是40亿*8大概是 340亿，n=50亿，如果按出错率 0.01 算需要的大概是 475 亿个bit。现在可用的是 340 亿，相差并不多，这样可能会使出错率上升些。另外如果这些url ip是一一对应的，就可以转换成ip，则大大简单了。\n Hashing 适用范围 快速查找，删除的基本数据结构，通常需要总数据量可以放入内存\n基本原理 　- hash函数选择，针对字符串，整数，排列，具体相应的hash方法。\n 碰撞处理，一种是open hashing，也称为拉链法；另一种就是closed hashing，也称开地址法。  扩展 　d-left hashing中 的 d 是多个的意思，我们先简化这个问题，看一看 2-left hashing。2-left hashing指的是将一个哈希表分成长度相等的两半，分别叫做 T1 和 T2 ，给 T1 和 T2 分别配备一个哈希函数， h1 和 h2 。在存储一个新的key时，同时用两个哈希函数进行计算，得出两个地址 h1[key]和 h2[key]。这时需要检查 T1 中的 h1[key] 位置和 T2 中的 h2[key] 位置，哪一个位置已经存储的（有碰撞的）key比较多，然后 将新key存储在负载少的位置。如果两边一样多，比如两个位置都为空或者都存储了一个key，就把新key存储在左边的T1子表中，2-left也由此而来。在查找一个key时，必须进行两次hash，同时查找两个位置。 但是这种方法只能使用在静态集合上，一旦集合发生变化，就需要进行重新计算。\n问题实例： 海量日志数据，提取出某日访问百度次数最多的那个IP。\n答：IP的数目还是有限的，最多2^32个，所以可以考虑使用hash将 ip 直接存入内存，然后进行统计。\n bit-map 适用范围 可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下\n基本原理 使用bit数组来表示某些元素是否存在，比如8位电话号码。例如bit数组 001101001001101001 代表实际数组 [2,3,5,8] 。新加入一个元素，只需要将已有的bit数组和新加入的数字做按位或 or 计算。bitmap中 1 的数量就是集合的基数值。\nbitmap 有一个很明显的优势是可以轻松合并多个统计结果，只需要对多个结果求异或就可以。也可以大大减少存储内存，可以做个简单的计算，如果要统计1亿个数据的基数值，大约需要内存： \\(100000000/8/1024/1024 \\approx≈ 12\\)  M 如果用 32bit 的 int 代表每个统计数据，大约需要内存： \\(32*100000000/8/1024/1024 \\approx≈ 381\\)  M\nbitmap 对于内存的节约量是显而易见的，但还是不够。统计一个对象的基数值需要12M，如果统计 10000 个对象，就需要将近 120G 了，同样不能广泛用于大数据场景。\n扩展 bloom filter可以看做是对bit-map的扩展\n问题实例   已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。 答：8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。\n  2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。 答：将bit-map扩展一下，用2bit表示一个数即可，0表示未出现，1表示出现一次，2表示出现2次及以上。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map。\n   HyperLogLog 算法演示\n上面我们计算过用 bitmap 存储 1亿 个统计数据大概需要 12M 内存；而在 HLL 中，只需要不到 1K 内存就能做到；redis中实现的 HyperLogLog ，只需要 12K 内存，在标准误差 0.81% 的前提下，能够统计 \\(2^{64}\\)  个数据。首先容我感叹一下数学的强大和魅力，那么概率算法是怎样做到如此节省内存的，又是怎样控制误差的呢？\nHLL中实际存储的是一个长度为 m 的大数组 S ，将待统计的数据集合划分成 m 组，每组根据算法记录一个统计值存入数组中。数组的大小 m 由算法实现方自己确定，redis中这个数组的大小是 16834，m 越大，基数统计的误差越小，但需要的内存空间也越大。\n 通过hash函数计算输入值对应的比特串 比特串的低 \\(t(t=log_2^m)t\\)  位对应的数字用来找到数组 S 中对应的位置 i  \\(t+1\\)  位开始找到第一个 1 出现的位置 k，将 k 记入数组 \\(S_i\\)  位置 基于数组 S 记录的所有数据的统计值，计算整体的基数值，计算公式可以简单表示为： \\(\\hat{n}=f(S)\\)    原理 举一个我们最熟悉的抛硬币例子，出现正反面的概率都是 1/2 ，一直抛硬币直到出现正面，记录下投掷次数 k ，将这种抛硬币多次直到出现正面的过程记为一次伯努利过程，对于 n 次伯努利过程，我们会得到nn个出现正面的投掷次数值 \\(k_1\\)  , \\(k_2\\)  …… \\(k_n\\)  ，其中最大值记为 \\(k_{max}\\)  ，那么可以得到下面结论：\n n 次伯努利过程的投掷次数都不大于 \\(k_{max}\\)   n 次伯努利过程，至少有一次投掷次数等于 \\(k_{max}\\)  ​​ 回到基数统计的问题，我们需要统计一组数据中不重复元素的个数，集合中每个元素的经过hash函数后可以表示成 0 和 1 构成的二进制数串，一个二进制串可以类比为一次抛硬币实验，1 是抛到正面，0 是反面。二进制串中从低位开始第一个 1 出现的位置可以理解为抛硬币试验中第一次出现正面的抛掷次数 k ，那么基于上面的结论，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，同样可以可以通过第一个 1 出现位置的最大值 \\(k_{max}\\)  来预估总共有多少个不同的数字（整体基数）。  这种通过局部信息预估整体数据流特性的方法似乎有些超出我们的基本认知，需要用概率和统计的方法才能推导和验证这种关联关系。HyperLogLog 核心在于观察集合中每个数字对应的比特串，通过统计和记录比特串中最大的出现 1 的位置来估计集合整体的基数，可以大大减少内存耗费。\n Simhash SimHash算法可计算文本间的相似度，实现文本去重。\n 首先，对原始内容分词，并且计算每个词的权重； 对每个词哈希成一个整数，并且把这个整数对应的二进制序列中的 0 变成 -1，1 还是 1，得到一个 1 和 -1 组成的向量； 把每个词哈希后的向量乘以词的权重，得到一个新的加权向量； 把每个词的加权向量相加，得到一个最终向量，这个向量中每个元素有正有负； 把最终这个向量中元素为正的替换成 1，为负的替换成 0，这个向量变成一个二进制位序列，也就是最终变成了一个整数。  Simhash 为每一个内容生成一个整数指纹，其中的关键是把每个词哈希成一个整数，这一步常常采用 Jenkins 算法。这里简单示意的整数只有 8 个二进制位，实际上可能需要 64 个二进制位的整数，甚至范围更大。\n得到每个内容的 Simhash 指纹后，可以两两计算 汉明距离，比较二进制位不同个数，其实就是计算两个指纹的异或，异或结果中如果包含 3 个以下的 1，则认为两条内容重复。\n 堆 适用范围 海量数据前n大，并且n比较小，堆可以放入内存\n基本原理 最大堆求前n小，最小堆求前n大。适合大数据量，求前n小，n的大小比较小的情况，这样可以扫描一遍即可得到所有的前n元素，效率很高。\n扩展 双堆，一个最大堆与一个最小堆结合，可以用来维护中位数。\n问题实例：  100w个数中找最大的前100个数。 答：用一个100个元素大小的最小堆即可。   双层桶划分 适用范围 第k大，中位数，不重复或重复的数字\n基本原理 因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。可以通过多次缩小，双层只是一个例子。\n 其实本质上就是【分而治之】的思想，重在分的技巧上！\n 扩展 当有时候需要用一个小范围的数据来构造一个大数据，也是可以利用这种思想，相比之下不同的，只是其中的逆过程。\n问题实例   2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。 答：有点像鸽巢原理，整数个数为 2^32 ,也就是，我们可以将这 2^32 个数，划分为 2^8 个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用 bitmap 就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。\n  5亿个 int 找它们的中位数。 答一：这个例子比上面那个更明显。首先我们将 int 划分为 2^16个 区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。 答二：实际上，如果不是 int 是 int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将 int64 分成 2^24 个区域，然后确定区域的第几大数，在将该区域分成 2^20 个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有 2^20 ，就可以直接利用 direct addr table 进行统计了。\n   数据库索引 适用范围 大数据量的增删改查\n基本原理 利用数据的设计实现方法，对海量数据的增删改查进行处理。\n 倒排索引(Inverted index) 适用范围 搜索引擎，关键字查询\n基本原理 用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。\n以英文为例，下面是要被索引的文本：\nT0 = \u0026quot;it is what it is\u0026quot; T1 = \u0026quot;what is it\u0026quot; T2 = \u0026quot;it is a banana\u0026quot; 我们就能得到下面的反向文件索引：\n\u0026quot;a\u0026quot;: {2} \u0026quot;banana\u0026quot;: {2} \u0026quot;is\u0026quot;: {0, 1, 2} \u0026quot;it\u0026quot;: {0, 1, 2} \u0026quot;what\u0026quot;: {0, 1} 检索的条件\u0026quot;what\u0026rdquo;,\u0026ldquo;is\u0026quot;和\u0026quot;it\u0026quot;将对应集合的交集。\n正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而反向索引则是单词指向了包含它的文档，很容易看到这个反向的关系。\n扩展 问题实例 文档检索系统，查询那些文件包含了某单词，比如常见的学术论文的关键字搜索。\n K 路归并 适用范围 大数据的排序，去重。\n基本原理 一般来说外排序分为两个步骤：预处理和合并排序。\n 按照内存大小，将大文件分成若干长度为 l 的子文件（l 应小于内存的可使用容量），然后将各个子文件依次读入内存，使用适当的内部排序算法对其进行排序（排好序的子文件统称为“归并段”或者“顺段”），将排好序的归并段重新写入外存，为下一个子文件排序腾出内存空间； 对得到的顺段进行合并，直至得到整个有序的文件为止。  问题实例  有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M。返回频数最高的100个词。   败/胜者树 对于外部排序算法来说，其直接影响算法效率的因素为读写外存的次数，即次数越多，算法效率越低。若想提高算法的效率，即减少算法运行过程中读写外存的次数，可以增加 k 路平衡归并中的 k 值。但是如果毫无限度地增加 k 值，虽然会减少读写外存数据的次数，但会增加内部归并的时间，得不偿失。\n为了避免在增加 k 值的过程中影响内部归并的效率，在进行 k-路归并时可以使用 败者树 来实现，该方法在增加 k 值时不会影响其内部归并的效率。\n基本原理 败/胜者树实际上是保存部分数据的比较结果，以减少新增数据的比较次数，以减少IO。对于无序表 {49，38，65，97，76，13，27，49} 创建的完全二叉树如图所示，构建此树的目的是选出无序表中的最小值。\n这是一棵 胜者树 。因为树中每个非终端结点（除叶子结点之外的其它结点）中的值都表示的是左右孩子相比较后的较小值（谁最小即为胜者）。例如叶子结点 49 和 38 相对比，由于 38 更小，所以其双亲结点中的值保留的是胜者 38。然后用 38 去继续同上层去比较，一直比较到树的根结点。\n 胜者树和败者树的区别就是：胜者树中的非终端结点中存储的是胜利的一方；而败者树中的非终端结点存储的是失败的一方。而在比较过程中，都是拿胜者去比较。\n 对于 10 个临时文件，采用 5-路平衡归并时，若每次从 5 个文件中想得到一个最小值就需要比较 4 次。而采用败者树，只需要进行 2 次比较。以上仅仅是得到一个最小值记录，如要得到整个临时文件，其耗费的时间就会相差很大。\n 置换选择排序 除了增加 k-路归并排序中的 k 值来提高外部排序效率的方法，还有另外一条路可走，即减少初始归并段的个数：置换选择排序 是为在较小的空间内，得到更大的有序段。相比于按照内存容量大小对初始文件进行等分，大大减少了初始归并段的数量，从而提高了外部排序的整体效率。\n 通过置换选择排序算法得到的初始归并段，其长度并不会受内存容量的限制，且通过证明得知使用该方法所获得的归并段的平均长度为内存工作区大小的两倍。\n 例如已知初始文件中总共有 24 个记录，假设内存工作区最多可容纳 6 个记录，按照之前的选择排序算法最少也只能分为 4 个初始归并段。而如果使用置换—选择排序，可以实现将 24 个记录分为 3 个初始归并段：\n置换—选择排序算法的具体操作过程为：\n 首先从初始文件中输入 6 个记录到内存工作区中； 从内存工作区中选出关键字最小的记录，将其记为 MINIMAX 记录； 然后将 MINIMAX 记录输出到归并段文件中； 此时内存工作区中还剩余 5 个记录，若初始文件不为空，则从初始文件中输入下一个记录到内存工作区中； 从内存工作区中的所有比 MINIMAX 值大的记录中选出值最小的关键字的记录，作为新的 MINIMAX 记录； 重复过程 3—5，直至在内存工作区中选不出新的 MINIMAX 记录为止，由此就得到了一个初始归并段； 重复 2—6，直至内存工作为空，由此就可以得到全部的初始归并段。   最佳归并树 无论是通过等分还是置换-选择排序得到的归并段，如何设置它们的归并顺序，可以使得对外存的访问次数降到最低？现有通过置换选择排序算法所得到的 9 个初始归并段，其长度分别为：9，30，12，18，3，17，2，6，24。在对其采用 3-路平衡归并的方式时可能出现如图所示的情况：\n 图中的叶子结点表示初始归并段，各自包含记录的长度用结点的权重来表示；非终端结点表示归并后的临时文件。\n 假设在进行平衡归并时，操作每个记录都需要单独进行一次对外存的读写，那么图中的归并过程需要对外存进行读或者写的次数为：\n$$(9+30+12+18+3+17+2+6+24)\\times 2 \\times 2 = 484$$\n 图中涉及到了两次归并，对外存的读和写各进行 2 次\n 从计算结果上看，对于图中的 3 叉树来讲，其操作外存的次数恰好是树的带权路径长度的 2 倍。所以，对于如何减少访问外存的次数的问题，就等同于考虑如何使 k 路归并所构成的 k 叉树的带权路径长度最短。\n若想使树的带权路径长度最短，就是构造赫夫曼树。若对上述 9 个初始归并段构造一棵赫夫曼树作为归并树，如图所示：\n归并过程中需要对外存进行IO的次数为：\n$$(2\\times3+3\\times3+6\\times3+9\\times2+12\\times2+17\\times2+18\\times2+24\\times2+30)\\times2=446$$\n通过以构建赫夫曼树的方式构建归并树，使其对读写外存的次数降至最低（k-路平衡归并，需要选取合适的 k 值，构建赫夫曼树作为归并树），所以称此归并树为 最佳归并树 。\n Trie树 适用范围 数据量大，重复多，但是数据种类小可以放入内存\n 字符串的快速检索 字符串排序 最长公共前缀 自动匹配前缀显示后缀  基本原理 Trie树的创建要考虑的是父节点如何保存孩子节点，主要有链表和数组两种方式\n 链表：空间占用少，查找效率低 数组：空间占用多，查找效率高 Hash：  扩展 压缩Trie Patricia Tree 基数树（也叫基数特里树或压缩前缀树）是一种数据结构，是一种更节省空间的Trie（前缀树），其中作为唯一子节点的每个节点都与其父节点合并，边既可以表示为元素序列又可以表示为单个元素。\n基数树的查找方式也与常规树不同（常规的树查找一开始就对整个键进行比较，直到不相同为止），基数树查找时节点时，对于节点上的键都按块进行逐块比较，其中该节点中块的长度是基数r； 当 \\(r\\)  为2时，基数树为二进制的（即该节点的键的长度为1比特位），能最大程度地减小树的深度来最小化稀疏性（最大限度地合并键中没有分叉的节点）。 当 \\(r≥4\\)  且为2的整数次幂时，基数树是 \\(r\\)  元基数树，能以潜在的稀疏性为代价降低基数树的深度。\n后缀Trie 压缩的后缀字典树\n 查找某个字符串s1是否在另外一个字符串s2中 指定字符串s1在字符串s2中重复的次数 两个字符串S1，S2的最长公共部分 最长回文串  双数组字典树 Double-Array Trie 双数组Trie (Double-Array Trie)结构由日本人JUN-ICHI AOE于1989年提出的，是 Trie结构的压缩形式，仅用两个线性数组来表示Trie树，该结构有效结合了数字搜索树(Digital Search Tree)检索时间高效的特点和链式表示的Trie空间结构紧凑的特点。双数组Trie的本质是一个确定有限状态自动机（DFA），每个节点代表自动机的一个状态，根据变量不同，进行状态转移，当到达结束状态或无法转移时，完成一次查询操作。在双数组所有键中包含的字符之间的联系都是通过简单的数学加法运算表示，不仅提高了检索速度，而且省去了链式结构中使用的大量指针，节省了存储空间。\n DAT的生成如上说的只能对 排序 好的单词进行构建\n 双数组Trie树归根结底还是属于Trie树，所以免不了有一颗树的构造过程。不过这棵树并没有保存下来，而是边构造树边维护双数组以表示整棵树。\n//i 为状态值 c为当前字符 parent(i) 为i的前置状态 base[i]=base[parent(i)+c] check[i]=base[parent(i)] base[i]\u0026lt;0 即为结束 问题实例  有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。 1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？ 寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。   map-reduce 适用范围 数据量大，但是数据种类小可以放入内存\n基本原理及要点 将数据交给不同的机器去处理，数据划分，结果归约。\n问题实例  The canonical example application of MapReduce is a process to count the appearances ofeach different word in a set of documents: 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。 一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到N^2个数的中数(median)？  经典问题分析 如何从大量的 URL 中找出相同的 URL？ 给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。\n解答思路：\n 分而治之，进行哈希取余； 对每个子文件进行 HashSet 统计。  如何从大量数据中找出高频词？ 有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。\n解答思路：\n 分而治之，进行哈希取余； 使用 HashMap 统计频数； 求解最大的 TopN 个，用小顶堆；求解最小的 TopN 个，用大顶堆。  如何在大量的数据中找出不重复的整数？ 在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。\n解题思路：位图法\n如何在大量的数据中判断一个数是否存在？ 给定 40 亿个不重复的没排过序的 unsigned int 型整数，然后再给定一个数，如何快速判断这个数是否在这 40 亿个整数当中？\n解题思路：位图法\n如何查询最热门的查询串？ 搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询串的长度不超过 255 字节。\n假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。）\n解题思路：HashMap、前缀树+小顶堆\n如何统计不同电话号码的个数？ 已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。\n解题思路：位图法（将电话号码作为整型）\n如何从 5 亿个数中找出中位数？ 从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 (N+1)/2 个数；当样本数为偶数时，中位数为 第 N/2 个数与第 1+N/2 个数的均值。\n解题思路：双堆法、分治法\n如何按照 query 的频度排序？ 有 10 个文件，每个文件大小为 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求按照 query 的频度排序。\n解题思路：外排序\n如何找出排名前 500 的数？ 有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 20*500 个数中找出前 500 的数？\n解题思路：败者树\n参考链接  360 搜索的百亿级网页搜索引擎架构实现 最佳归并树 海量数据处理  "});index.add({'id':20,'href':'/interview/docs/basic/net/websocket/','title':"Websocket",'content':"Websocket 简介 WebSocket 是一种与 HTTP 不同的协议。两者都位于 OSI 模型的应用层，并且都依赖于传输层的 TCP 协议。 虽然它们不同，但 RFC 6455 规定：WebSocket设计为通过 80 和 443 端口工作，以及支持HTTP代理和中介，从而使其与HTTP协议兼容。为了实现兼容性， WebSocket 握手使用 HTTP Upgrade 头从 HTTP 协议更改为 WebSocket 协议。\n与HTTP不同，WebSocket 提供全双工通信。此外，WebSocket 还可以在 TCP 之上启用消息流。 TCP 单独处理字节流，没有固有的消息概念。\nWebSocket协议规范将 ws（WebSocket）和 wss （WebSocket Secure）定义为两个新的统一资源标识符（URI）方案，分别对应明文和加密连接。\n优点  较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。 更强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少； 保持连接状态。与 HTTP 不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。 更好的二进制支持。 Websocket 定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。 可以支持扩展。Websocket 定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。 更好的压缩效果。相对于HTTP压缩，Websocket 在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率  连接过程 WebSocket 是独立的、创建在 TCP 上的协议。Websocket 通过 HTTP/1.1 协议的101状态码进行握手。为了创建Websocket连接，需要通过浏览器发出请求，之后服务器进行回应，这个过程通常称为 握手（handshaking）。\n客户端请求\nGET / HTTP/1.1 Upgrade: websocket Connection: Upgrade Host: example.com Origin: http://example.com Sec-WebSocket-Key: sN9cRrP/n9NdMgdcy2VJFQ== Sec-WebSocket-Version: 13 服务器回应\nHTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: fFBooB7FAkLlXgRSz0BT3v4hq5s= Sec-WebSocket-Location: ws://example.com/ 参考链接  WebSocket  "});index.add({'id':21,'href':'/interview/docs/architecture/distributed/','title':"Distributed",'content':""});index.add({'id':22,'href':'/interview/docs/architecture/distributed/consensus/','title':"分布式一致性和共识协议",'content':"一致性 在分布式系统中，一致性(Consistency，早期也叫 Agreement)是指对于系统中的多个服务节点，给定一系列操作，在协议（往往通过某种共识算法）保障下，试图使得它们对处理结果达成某种程度的一致。\n 一致性并不代表结果正确与否，而是系统对外呈现的状态一致与否，例如，所有节点都达成失败状态也是一种一致。\n 分布式的挑战 在实际的计算机集群系统（看似强大的计算机系统，很多地方都比人类世界要脆弱的多）中，存在如下的问题：\n 节点之间的网络通讯是不可靠的，包括任意延迟和内容故障； 节点的处理可能是错误的，甚至节点自身随时可能宕机； 同步调用会让系统变得不具备可扩展性。  要解决这些挑战，愿意动脑筋的读者可能会很快想出一些不错的思路。为了简化理解，仍然以两个电影院一起卖票的例子。可能有如下的解决思路：\n 每次要卖一张票前打电话给另外一家电影院，确认下当前票数并没超售； 两家电影院提前约好，奇数小时内一家可以卖票，偶数小时内另外一家可以卖； 成立一个第三方的存票机构，票都放到他那里，每次卖票找他询问；  这些思路大致都是可行的。实际上，这些方法背后的思想，将可能引发不一致的并行操作进行串行化，就是现在计算机系统里处理分布式一致性问题的基础思路和唯一秘诀。只是因为计算机系统比较傻，需要考虑得更全面一些；而人们又希望计算机系统能工作的更快更稳定，所以算法需要设计得再精巧一些。\n规范的说，理想的分布式系统一致性应该满足：\n 可终止性（Termination）：一致的结果在有限时间内能完成； 共识性（Consensus）：不同节点最终完成决策的结果应该相同； 合法性（Validity）：决策的结果必须是其它进程提出的提案。  第一点很容易理解，这是计算机系统可以被使用的前提。需要注意，在现实生活中这点并不是总能得到保障的，例如取款机有时候会是 服务中断 状态，电话有时候是 无法连通 的。\n第二点看似容易，但是隐藏了一些潜在信息。算法考虑的是任意的情形，凡事一旦推广到任意情形，就往往有一些惊人的结果。例如现在就剩一张票了，中关村和西单的电影院也分别刚确认过这张票的存在，然后两个电影院同时来了一个顾客要买票，从各自观察看来，自己的顾客都是第一个到的……怎么能达成结果的共识呢？记住我们的唯一秘诀：核心在于需要把两件事情进行排序，而且这个顺序还得是大家都认可的。\n第三点看似绕口，但是其实比较容易理解，即达成的结果必须是节点执行操作的结果。仍以卖票为例，如果两个影院各自卖出去一千张，那么达成的结果就是还剩八千张，决不能认为票售光了。\n强一致性 线性一致性 线性一致性或称 原子一致性 或 严格一致性 指的是程序在执行的历史中在存在可线性化点P的执行模型，这意味着一个操作将在程序的调用和返回之间的某个点P起作用。这里“起作用”的意思是被系统中并发运行的所有其他线程所感知。要求如下：\n 写后读 这里写和读是两个操作，如果写操作在完成之后，读才开始，读要能读到最新的数据，而且保证以后也能读操作也都能读到这个最新的数据。 所有操作的时序与真实物理时间一致，要求即使不相关的两个操作，如果执行有先后顺序，线性一致性要求最终执行的结果也需要满足这个先后顺序。比如，操作序列(写A，读A，写B，读B)，那么不仅，读A，读B能读到最新A值和B值；而且要保证，如果读B读到最新值时，读A一定也能读到最新值，也就是需要保证执行时序与真实时序相同。 如果两个操作是并发的(比如读A没有结束时，写B开始了)，那么这个并发时序不确定，但从最终执行的结果来看，要确保所有线程(进程，节点)看到的执行序列是一致的。  顺序一致性 相比线性一致性，主要区别在于，对于物理上有先后顺序的操作，不保证这个时序。具体而言，对于单个线程，操作的顺序仍然要保留，对于多个线程(进程，节点)，执行的事件的先后顺序与物理时钟顺序不保证。但是要求，从执行结果来看，所有线程(进程，节点)看到的执行序列是一样的。\n线性一致性和顺序一致性。  图1 是顺序一致性：从这两个进程的角度来看，顺序应该是这样的 write(y,2) -\u0026gt; read(x,0) -\u0026gt; write(x,4) -\u0026gt; read(y,2) ，每个进程内部的读写顺序都是合理的，但是这个顺序与全局时钟下看到的顺序并不一样，write(x,4) 先于 read(x,0) 执行，但是 read 却没有读到最新值。 图2 是线性一致性：每个读操作都读到了该变量的最新写的结果，同时 两个进程看到的操作顺序与全局时钟的顺序一样，都是 write(y,2) -\u0026gt; write(x,4) -\u0026gt; read(x,4) -\u0026gt; read(y,2)。 图3 不符合顺序一致性，更加不符合线性一致性，两个进程内部的顺序可能是：write(x,4) -\u0026gt; read(y,0) -\u0026gt; write(y,2) -\u0026gt; read(x,0)、或者：write(y,2) -\u0026gt; read(x,0) -\u0026gt; write(x,4) -\u0026gt; read(y,0) 显然两个顺序又不能同时被 P1、P2 满足，因此这个顺序是有冲突的，不满足顺序一致性。  因果一致性 因果一致性，被认为是比 顺序一致性 更弱的一致性，在因果一致性中，只对有因果关系的事件有顺序要求。\n对于 P1 和 P2 的操作是没有先后关系的，因此谁先发生都是可以的。\n 从 P3 的视角来看，操作执行序列是 w(x,7) -\u0026gt; r(x,7) -\u0026gt; w(x,2) -\u0026gt; r(x,2) -\u0026gt; w(x,4) 从 P4 的视角来看，操作执行序列是 w(x,2) -\u0026gt; w(x,4) -\u0026gt; r(x,4) -\u0026gt; w(x,7) -\u0026gt; r(x,7)  但是不同进程看到的执行序列不一样，所以不符合顺序一致性。\n带约束的一致性 绝对理想的 强一致性（Strong Consistency） 代价很大。除非不发生任何故障，所有节点之间的通信无需任何时间，这个时候其实就等价于一台机器了。实际上，越强的一致性要求往往意味着越弱的性能、越低的可用性。\n强一致的系统往往比较难实现。很多时候，人们发现实际需求并没有那么强，可以适当放宽一致性要求，降低系统实现的难度。例如在一定约束下实现所谓 最终一致性（Eventual Consistency），即总会存在一个时刻（而不是立刻），系统达到一致的状态，这对于大部分的 Web 系统来说已经足够了。这一类弱化的一致性，被笼统称为 弱一致性（Weak Consistency）。\n最终一致性 最终一致性也被称为 乐观复制(optimistic replication)，用户只能读到某次更新后的值，但系统保证数据将最终达到完全一致的状态，只是所需时间不能保障。这个达成一致所需要的时间，我们称为 窗口时间。\n我们常见的 异步复制的主从架构实现的是最终一致性 。它的一个典型常见是用户读取异步从库时，可能读取到较旧的信息，因为该从库尚未完全与主库同步。注意，同步复制的主从架构会出现任一节点宕机导致的单点问题。\n共识算法 共识算法解决的是对某个提案（Proposal），大家达成一致意见的过程。提案的含义在分布式系统中十分宽泛，如多个事件发生的顺序、某个键对应的值、谁是领导……等等，可以认为任何需要达成一致的信息都是一个提案。\n 实践中，一致性的结果往往还需要客户端的特殊支持，典型地通过访问足够多个服务节点来验证确保获取共识后结果。\n 拜占庭问题 拜占庭将军问题描述了一个如下的场景，有一组将军分别指挥一部分军队，每一个将军都不知道其它将军是否是可靠的，也不知道其他将军传递的信息是否可靠，但是它们需要通过投票选择是否要进攻或者撤退。\n在这时，无论将军是否可靠，只要所有的将军达成了统一的方案，选择进攻或者撤退其实就是没有任何问题的。上述的情况不会对当前的战局有太多的影响，也不会造成损失，但是如果其中的一个将军告诉其中一部分将军选择进攻、另一部分选择撤退，就会出现非常严重的问题了。\n由于将军的队伍中出了一个叛徒或者信息在传递的过程中被拦截，会导致一部分将军会选择进攻，剩下的一部分会选择撤退，它们都认为自己的选择是大多数人的选择，这时就出现了严重的不一致问题。\n拜占庭将军问题是对分布式系统容错的最高要求，然而这不是日常工作中使用的大多数分布式系统中会面对的问题，我们遇到更多的还是节点故障宕机或者不响应等情况，这就大大简化了系统对容错的要求。\n问题挑战 实际上，如果分布式系统中各个节点都能保证以十分强大的性能（瞬间响应、高吞吐）无故障的运行，则实现共识过程并不复杂，简单通过多播过程投票即可。\n很可惜的是，现实中这样完美的系统并不存在，如响应请求往往存在时延、网络会发生中断、节点会发生故障、甚至存在恶意节点故意要破坏系统。\n一般地，把故障（不响应）的情况称为 非拜占庭错误 ，恶意响应的情况称为 拜占庭错误（对应节点为拜占庭节点）。\n常见算法 针对非拜占庭错误的情况，一般包括 Paxos、Raft 及其变种。\n对于要能容忍拜占庭错误的情况，一般包括 PBFT 系列、 PoW 系列算法等。从概率角度，PBFT 系列算法是确定的，一旦达成共识就不可逆转；而 PoW 系列算法则是不确定的，随着时间推移，被推翻的概率越来越小。\n理论界限 搞学术的人都喜欢对问题先确定一个界限，那么，这个问题的最坏界限在哪里呢？很不幸，一般情况下，分布式系统的共识问题无解。\n当节点之间的通信网络自身不可靠情况下，很显然，无法确保实现共识。但好在，一个设计得当的网络可以在大概率上实现可靠的通信。然而，即便在网络通信可靠情况下，一个可扩展的分布式系统的共识问题的下限是无解。\n这个结论，被称为 FLP 不可能性 原理，可以看做分布式领域的“测不准原理”。\nFLP FLP 不可能定理是分布式系统领域最重要的定理之一，它给出了一个非常重要的结论：在网络可靠并且存在节点失效的异步模型系统中，不存在一个可以解决一致性问题的确定性算法。\n这个定理其实也就是告诉我们不要浪费时间去为异步分布式系统设计在任意场景上都能够实现共识的算法，异步系统完全没有办法保证能在有限时间内达成一致。理解这一原理的一个不严谨的例子是：\n三个人在不同房间，进行投票（投票结果是 0 或者 1）。三个人彼此可以通过电话进行沟通，但经常会有人时不时地睡着。比如某个时候，A 投票 0，B 投票 1，C 收到了两人的投票，然后 C 睡着了。A 和 B 则永远无法在有限时间内获知最终的结果。如果可以重新投票，则类似情形每次在取得结果前发生。\n这岂不是意味着研究一致性问题压根没有意义吗？\n先别这么悲观，学术界做研究，考虑的是数学和物理意义上最极端的情形，很多时候现实生活要美好的多。Paxos算法的场景比FLP的系统模型还要松散，除了异步通信，Paxos允许消息丢失（通信不健壮），但Paxos却被认为是最牛的一致性算法，其作者 Lamport 也获得2014年的图灵奖，这又是为什么？\n其实仔细回忆Paxos论文会发现， Paxos 中存在活锁，理论上的活锁会导致 Paxos 算法无法满足 Termination 属性，也就不算一个正确的一致性算法。Lamport 在自己的论文中也提到 FLP结果表明，不存在完全满足一致性的异步算法... ，因此他建议通过 Leader 来代替 Paxos 中的 Proposer ，而 Leader 则通过随机或其他方式来选定（Paxos中假如随机过程会极大降低FLP发生的概率）。也就是说Paxos算法其实也不算理论上完全正确的，只是在工程实现中避免了一些理论上存在的问题。\n 科学告诉你什么是不可能的；工程则告诉你，付出一些代价，我可以把它变成可能。\n 一致性（Consistency）与共识（Consensus） 我们常说的 一致性（Consistency） 在分布式系统中指的是 副本（Replication） 问题中对于同一个数据的多个副本，其对外表现的数据一致性，如 线性一致性 、因果一致性、最终一致性等，都是用来描述副本问题中的一致性的。\n而 共识（Consensus） 则不同，共识问题中所有的节点要最终达成共识，由于最终目标是所有节点都要达成一致，所以根本 不存在一致性强弱 之分。\n只有当你使用像 Paxos 这样的共识算法作为解决副本问题的核心组件时，才会对外展现出不同的一致性级别。但是，即使是在这样的场景下，讨论一个共识算法的一致性也是不合适的，因为 整个副本系统最终的一致性并不单单取决于共识算法 ，Client 访问所遵循的规范也会有决定性的作用。比如说：即使副本系统使用 multi-paxos 在所有副本服务器上同步了日志序号，但如果 Client 被允许从非 Leader 节点获取数据，则整个副本系统仍然不是强一致的。\nCAP 分布式计算系统不可能同时确保一致性（Consistency）、可用性（Availablity）和分区容忍性（Partition），设计中往往需要弱化对某个特性的保证。\n 一致性（Consistency - 线性一致性）：任何操作应该都是原子的，发生在后面的事件能看到前面事件发生导致的结果，注意这里指的是强一致性； 可用性（Availablity）：在有限时间内，任何非失败节点都能应答请求； 分区容忍性（Partition）：网络可能发生分区，即节点之间的通信不可保障。  比较直观地理解，当网络可能出现分区时候，系统是无法同时保证一致性和可用性的。要么，节点收到请求后因为没有得到其他人的确认就不应答，要么节点只能应答非一致的结果。\n好在大部分时候网络被认为是可靠的，因此系统可以提供一致可靠的服务；当网络不可靠时，系统要么牺牲掉一致性（大部分时候都是如此），要么牺牲掉可用性。\n既然 CAP 不可同时满足，则设计系统时候必然要弱化对某个特性的支持。\n弱化一致性 对结果一致性不敏感的应用，可以允许在新版本上线后过一段时间才更新成功，期间不保证一致性。例如网站静态页面内容、实时性较弱的查询类数据库等，CouchDB、Cassandra 等为此设计。\n弱化可用性 对结果一致性很敏感的应用，例如银行取款机，当系统故障时候会拒绝服务。MongoDB、Redis 等为此设计。Paxos、Raft 等算法，主要处理这种情况。\n弱化分区容忍性 现实中，网络分区出现概率减小，但较难避免。某些关系型数据库、ZooKeeper 即为此设计。实践中，网络通过双通道等机制增强可靠性，达到高稳定的网络通信。\nPaxos Paxos 其实是一类能够解决分布式一致性问题的协议，它能够让分布式网络中的节点在出现错误时仍然保持一致；Leslie Lamport 提出的 Paxos 可以在没有恶意节点的前提下保证系统中节点的一致性，也是第一个被证明完备的共识算法，目前的完备的共识算法包括 Raft 本质上都是 Paxos 的变种。\nBasic Paxos Basic Paxos 是 Paxos 中最为基础的协议，每一个 Basic Paxos 的协议实例最终都会选择唯一一个结果；使用 Paxos 作为共识算法的分布式系统中，节点都会有三种身份，分别是 Proposer、Acceptor 和 Learner。\nPaxos 的运行过程分为两个阶段，分别是准备阶段（Prepare）和接受阶段（Accept），当 Proposer 接收到来自客户端的请求时，就会进入如下流程：\n在整个共识算法运行的过程中，Proposer 负责提出提案并向 Acceptor 分别发出两次 RPC 请求，Prepare 和 Accept；Acceptor 会根据其持有的信息 minProposal、acceptedProposal 和 acceptedValue 选择接受或者拒绝当前的提案，当某一个提案被过半数的 Acceptor 接受之后，我们就认为当前提案被整个集群接受了。\nMulti-Paxos 由于大多数的分布式集群都需要接受一系列的值，如果使用 Basic Paxos 来处理数据流，那么就会导致非常明显的性能损失，而 Multi-Paxos 是前者的加强版，如果集群中的 Leader 是非常稳定的，那么我们往往不需要准备阶段的工作，这样就能够将 RPC 的数量减少一半。\n上述图片中描述的就是稳定阶段 Multi-Paxos 的处理过程，S1 是整个集群的 Leader，当其他的服务器接收到来自客户端的请求时，都会将请求转发给 Leader 进行处理。\n当然，Leader 角色的出现自然会带来另一个问题，也就是 Leader 究竟应该如何选举，在 Paxos Made Simple 一文中并没有给出 Multi-Paxos 的具体实现方法和细节，所以不同 Multi-Paxos 的实现上总有各种各样细微的差别。\nRaft Raft 其实就是 Multi-Paxos 的一个变种，Raft 通过简化 Multi-Paxos 的模型，实现了一种更容易让人理解的共识算法，它们两者都能够对一系列连续的问题达成一致。\nRaft 在 Multi-Paxos 的基础之上做了两个限制，首先是 Raft 中追加日志的操作必须是连续的，而 Multi-Paxos 中追加日志的操作是并发的，但是对于节点内部的状态机来说两者都是有序的，第二就是 Raft 对 Leader 选举的条件做了限制，只有拥有最新、最全日志的节点才能够当选 Leader，但是 Multi-Paxos 由于任意节点都可以写日志，所以在选择 Leader 上也没有什么限制，只是在选择 Leader 之后需要将 Leader 中的日志补全。\n在 Raft 中，所有 Follower 的日志都是 Leader 的子集，而 Multi-Paxos 中的日志并不会做这个保证，由于 Raft 对日志追加的方式和选举过程进行了限制，所以在实现上会更加容易和简单。\n从理论上来讲，支持并发日志追加的 Paxos 会比 Raft 有更优秀的性能，不过其理解和实现上还是比较复杂的，很多人都会说 Paxos 是科学，而 Raft 是工程，当作者需要去实现一个共识算法，会选择使用 Raft 和更简洁的实现，避免因为一些边界条件而带来的复杂问题。\nRaft协议将一致性协议的核心内容分拆成为几个关键阶段，以简化流程，提高协议的可理解性。\nLeader election Raft协议的每个副本都会处于三种状态之一：\n Leader：所有请求的处理者，Leader副本接受client的更新请求，本地处理后再同步至多个其他副本 Follower：请求的被动更新者，从Leader接受更新请求，然后写入本地日志文件 Candidate：如果 Follower 副本在一段时间内没有收到 Leader 副本的心跳，则判断 Leader 可能已经故障，此时启动选主过程，此时副本会变成 Candidate 状态，直到选主结束。  时间被分为很多连续的随机长度的 term ， term 有唯一的 id，每个 term 最多只有一个 Leader 。每个 term 一开始就进行选主：\n Follower 将自己维护的 current_term_id 加 1。 然后将自己的状态转成 Candidate 发送 RequestVoteRPC 消息(带上 current_term_id ) 给 其它所有 Server  本轮选举成功，当收到了 majority 的投票后，状态切成 Leader ，并且定期给其它的所有 Server 发心跳消息（不带 Log 的 AppendEntriesRPC ）以告诉对方自己是 current_term_id 所标识的 term 的 Leader 。term id 作为Logical clock，在每个 RPC 消息中都会带上，用于检测过期的消息。\n 当一个 Server 收到的 RPC 消息中的 rpc_term_id 比本地的 current_term_id 更大时，就更新 current_term_id 为 rpc_term_id ，并且如果当前 state 为 Leader 或者 candidate 时，将自己的状态切成 follower。 当 rpc_term_id 比本地的 current_term_id 更小，则拒绝这个RPC消息。  本轮选举失败，则没有任何一个 candidate 收到了 majority 的 vote 时，没有 Leader 被选出。这种情况下，每个 candidate 等待的投票的过程就超时了，接着 candidates 都会将本地的 current_term_id 再加1，再等待 150ms ~ 300ms 之后随机发起 RequestVoteRPC 进行新一轮的 Leader election，以避免再次选主失败。\nLog Replication 当 Leader 被选出来后，就可以接受客户端发来的请求了，每个请求包含一条需要被 replicated state machines 执行的命令。 Leader 会把它作为一个 Log Entry append 到日志中，然后给其它的 Server 发 AppendEntriesRPC 请求。当 Leader 确定一个 Log Entry 被 safely replicated 了（大多数副本已经将该命令写入日志当中），就 apply 这条 Log Entry 到状态机中然后返回结果给客户端。如果某个 Follower 宕机了或者运行的很慢，或者网络丢包了，则会一直给这个 Follower 发 AppendEntriesRPC 直到日志一致。\n当一条日志是 commited 时，Leader 才可以将它应用到状态机中。Raft 保证一条 commited 的 Log Entry 已经持久化了并且会被所有的节点执行。当一个新的 Leader 被选出来时，它的日志和其它的 Follower 的日志可能不一样，这个时候，就需要一个机制来保证日志的一致性。\n因此，需要有一种机制来让 Leader 和 Follower 对 Log 达成一致， Leader 会为每个 Follower 维护一个 nextIndex ，表示 Leader 给各个 Follower 发送的下一条 Log Entry 在 Log 中的 index ，初始化为 Leader 的最后一条 Log Entry 的下一个位置。leader 给 Follower 发送 AppendEntriesRPC 消息，带着 (term_id, nextIndex-1)， term_id 即 nextIndex-1 这个槽位的 Log Entry 的term_id ，Follower 接收到 AppendEntriesRPC 后，会从自己的 Log 中找是不是存在这样的 Log Entry，如果不存在，就给 Leader 回复拒绝消息，然后 Leader 则将 nextIndex 减1，再重复，直到 AppendEntriesRPC 消息被接收。\nSafety Raft 保证被选为新 Leader 的节点拥有所有已提交的 Log Entry。这个保证是在 RequestVoteRPC 阶段做的，candidate 在发送 RequestVoteRPC 时，会带上自己的最后一条日志记录的 term_id,index ，其他节点收到消息时，如果发现自己的日志比 RPC 请求中携带的更新，拒绝投票。日志比较的原则是，如果本地的最后一条 Log Entry 的 term id 更大，则更新，如果 term id 一样大，则 index 更大的更大。\nLog Compaction 在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响 availability 。Raft 采用对整个系统进行 snapshot 来处理， snapshot 之前的日志都可以丢弃。Snapshot 技术在 Chubby 和 ZooKeeper 系统中都有采用。\nRaft使用的方案是：每个副本独立的对自己的系统状态进行 Snapshot ，并且只能对已经提交的日志记录（已经应用到状态机）进行snapshot。\nPOW 无论是 Paxos 还是 Raft 其实都只能解决非拜占庭将军容错的一致性问题，不能够应对分布式网络中出现的极端情况，但是这在传统的分布式系统都不是什么问题，无论是分布式数据库还是消息队列集群，它们内部的节点并不会故意的发送错误信息，在类似系统中，最常见的问题就是节点失去响应或者失效，所以它们在这种前提下是有效可行的，也是充分的。\n工作量证明（POW，Proof-of-Work） 是一个用于阻止拒绝服务攻击和类似垃圾邮件等服务错误问题的协议，它在 1993 年被 Cynthia Dwork 和 Moni Naor 提出，它能够帮助分布式系统达到拜占庭容错。\n工作量证明的关键特点就是，分布式系统中的请求服务的节点必须解决一个一般难度但是可行（feasible）的问题，但是验证问题答案的过程对于服务提供者来说却非常容易，也就是一个不容易解答但是容易验证的问题。\n工作量证明的原理其实非常简单，比特币网络选择的谜题非常好的适应了工作量证明定义中的问题，比较难以寻找同时又易于证明，我们可以简单理解为工作量证明防止错误或者无效请求的原理就是增加客户端请求服务的工作量，而适合难度的谜题又能够保证合法的请求不会受到影响。\n由于工作量证明需要消耗大量的算力，同时比特币大约 10min 才会产生一个区块，区块的大小也只有 1MB，仅仅能够包含 3、4000 笔交易，平均下来每秒只能够处理 5~7（个位数）笔交易，所以比特币网络的拥堵状况非常严重。\n可靠性指标 很多领域一般都喜欢谈服务可靠性，用几个 9 来说事。这几个 9 其实是粗略代表了概率意义上系统能提供服务的可靠性指标，最初是电信领域提出的概念。\n下表给出不同指标下，每年允许服务出现不可用时间的参考值。\n   指标 概率可靠性 每年允许不可用时间 典型场景     一个九 90% 1.2 个月 不可用   二个九 99% 3.6 天 普通单点   三个九 99.9% 8.6 小时 普通企业   四个九 99.99% 51.6 分钟 高可用   五个九 99.999% 5 分钟 电信级   六个九 99.9999% 31 秒 极高要求   七个九 99.99999% 3 秒 N/A   八个九 99.999999% 0.3 秒 N/A   九个九 99.9999999% 30 毫秒 N/A    一般来说，单点的服务器系统至少应能满足两个九；普通企业信息系统三个九就肯定足够了（大家可以统计下自己企业内因系统维护每年要停多少时间），系统能达到四个九已经是业界领先水平了（参考 AWS）。电信级的应用一般号称能达到五个九，这已经很厉害了，一年里面最多允许五分钟的服务停用。\n那么，该如何提升可靠性呢？有两个思路：一是让系统中的单点变得更可靠；二是消灭单点。然而，依靠单点实现的可靠性毕竟是有限的，要想进一步的提升，那就只好消灭单点，通过主从、多活等模式让多个节点集体完成原先单点的工作。这可以从概率意义上改善服务的可靠性，也是分布式系统的一个重要用途。\n参考链接  分布式一致性与共识算法 分布式一致性和分布式共识协议 被误用的一致性 FLP Impossibility 一致性问题 Raft协议详解 当数据库遇到分布式  "});index.add({'id':23,'href':'/interview/docs/architecture/bigdata/hdfs/','title':"HDFS",'content':"HDFS 相关概念 HDFS要实现有以下优势：\n 兼容廉价硬件设备 流数据读写 大数据集 简单的文件模型 强大的跨平台兼容性  HDFS 在满足上述优势的同时，也不可避免的有一些自身的局限性，主要包括以下几个方面：\n 不适合低延时的数据访问 无法高效的存储大量小文件 不支持多用户写入及任意修改文件  块 HDFS 同计算机系统一样，有一个存储块的概念，默认大小为 64M，一个文件被分成多个块存储。块的大小远远大于计算机文件系统，可以减小寻址开销。其优势有：\n 支持大规模文件存储：以块为单位进行存储，一个大文件可被分割为多个块，并分发到不同节点，因此单个节点的存储容量不会限制存储文件的上限 简化系统设计：首先简化了存储管理，因为文件块大小固定，这样很容易计算节点可存储文件块的数量；其次，方便了元数据管理，元数据不与文件块存储，可由其他系统负责管理元数据。 适合数据备份：每个文件块都可冗余存储到多个节点，大大提高了系统的容错性和可用性。  名称节点（NameNode）和数据节点（DataNode）    NameNode DataNode     存储元数据 存储文件内容   元数据存储在内存 文件内容存储在磁盘   保存文件、block、 DataNode 之间的映射关系 维护block、本地文件系统的映射关系    名称节点（NameNode）数据结构 在 HDFS 中，名称节点复杂管理分布式文件系统的命名空间（NameSpace），保存两大核心数据结构：FSImage 和 EditLog。名称节点中还记录了每个文件中各个块所在的数据节点的位置信息。\nFSImage 文件用于维护文件系统树以及文件树中所有文件和文件夹的元数据。FSImage 文件中包含文件系统所有目录和文件 inode 的序列化形式，每个 inode 是一个文件或目录的元数据表示，包含：文件复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。\nFSImage 中并没有记录块存储在哪个数据节点。而是由名称节点把这些映射保存在内存中，当数据节点加入 HDFS 集群时，数据节点会报告自己所包含的数据块给名称节点，并定期执行告知，以确保名称节点的映射关系是正确的。\nEditLog 记录了所有针对文件的创建、删除、重命名等操作。\nNameNode 将对文件系统的改动追加保存到本地文件系统上的一个日志文件（EditLog）。当一个 NameNode 启动时，它首先从一个映像文件（FSImage）中读取 HDFS 的状态，接着应用日志文件中的 EditLog 操作。然后它将新的HDFS状态写入（FSImage）中，并使用一个空的 EditLog 文件开始正常操作。因为NameNode只有在启动阶段才合并 FSImage 和 EditLog ，所以久而久之日志文件可能会变得非常庞大，特别是对大型的集群。日志文件太大的另一个副作用是下一次 NameNode 启动会花很长时间。\nSecondary NameNode 定期合并 FSImage 和 EditLog 日志，将 EditLog 日志文件大小控制在一个限度下。\n名称节点的启动  名称节点启动后，会将 FSImage 文件中的内容加载到内存，之后再执行 EditLog 文件中的各项操作，使得内存中的元数据与实际数据一致。 一旦内存中管理文件系统元数据的映射，则会创建一个新的 FSImage 文件和一个空白的 EditLog 文件。 名称节点启动后， HDFS 中的更新操作会重新写入 EditLog，因为 FSImage 文件一般很大，所以不直接向 FSImage 文件中写入数据，但是 EditLog 每次启动后都是空白的。每次执行完写操作，且在向客户端发送成功消息之前，EditLog 文件都需要同步更新。  数据节点 数据节点是 HDFS 的工作节点，负责数据的存储和读取，会根据客户端或者名称节点的调度来进行数据的存储和检索，并定期向名称节点发送自己所存储的块信息。每个数据节点中的数据都会被保存在各自节点的本地 Linux 文件系统中。\nHDFS 体系结构 HDFS 采取主从模型，一个 HDFS 集群包含一个 NameNode 和若干个 DataNode 。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。\n命名空间 HDFS 的命名空间包含块映射、以及相关属性，存储在 FSImage 中。在 HDFS 1.0 体系结构中，整个 HDFS 集群中只有一个命名空间，并且只有唯一一个名称节点，该节点对这个命名空间进行管理。在 HDFS 2.0 中提出了 联邦 （Federation） 的概念。\nFederation Federation 的设计就是为了解决 HDFS 1.0 中的单一 NameNode 的问题，采用 Federation 的最主要原因是设计实现简单。\n block pool 存储在 DataNode 上，并通过 BPOfferService 提供服务\n Federation 的核心思想是将一个大的 namespace 划分多个子 namespace ，并且每个 namespace 分别由单独的 NameNode 负责，这些 NameNode 之间互相独立，不会影响，不需要做任何协调工作（其实跟拆集群有一些相似），集群的所有 DataNode 会被多个 NameNode 共享。\n其中，每个子 namespace 和 DataNode 之间会由数据块管理层作为中介建立映射关系，数据块管理层由若干 数据块池（Pool） 构成，每个数据块只会唯一属于某个固定的数据块池，而一个子 namespace 可以对应多个数据块池。每个 DataNode 需要向集群中所有的 NameNode 注册，且周期性地向所有 NameNode 发送心跳和块报告，并执行来自所有 NameNode 的命令。\n 一个 block pool 由属于同一个 namespace 的数据块组成，每个 DataNode 可能会存储集群中所有 block pool 的数据块； 每个 block pool 内部自治，也就是说各自管理各自的 block，不会与其他 block pool 交流，如果一个 NameNode 挂掉了，不会影响其他 NameNode; 某个 NameNode 上的 namespace 和它对应的 block pool 一起被称为 namespace volume，它是管理的基本单位。当一个 NameNode/namespace 被删除后，其所有 DataNode 上对应的 block pool 也会被删除，当集群升级时，每个 namespace volume 可以作为一个基本单元进行升级。  HA 在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。\n所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。\nNameNode 的高可用架构主要分为下面几个部分：\n Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。 主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。 Zookeeper 集群：为主备切换控制器提供主备选举支持。 共享存储系统：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和 备份 NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。 DataNode 节点：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。  NameNode 主备切换主要由 ZKFailoverController、HealthMonitor 和 ActiveStandbyElector 这 3 个组件来协同实现：\nHDFS 脑裂问题 在实际中，NameNode 可能会出现这种情况，NameNode 在垃圾回收（GC）时，可能会在长时间内整个系统无响应，因此，也就无法向 ZK 写入心跳信息，这样的话可能会导致临时节点掉线，备 NameNode 会切换到 Active 状态。这种情况，可能会导致整个集群会有同时有两个 NameNode，这就是脑裂问题。\n脑裂问题的解决方案是隔离（Fencing），主要是在以下三处采用隔离措施：\n 第三方共享存储：任一时刻，只有一个 NN 可以写入 DataNode：需要保证只有一个 NN 发出与管理数据副本有关的删除命令 Client：需要保证同一时刻只有一个 NN 能够对 Client 的请求发出正确的响应  共享存储 上述 HA 方案还有一个明显缺点，那就是第三方存储节点有可能失效，目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案作为默认的共享存储实现。QJM（Quorum Journal Manager）本质上是利用 Paxos 协议来实现的，QJM 在 2F+1 个 JournalNode 上存储 NameNode 的 EditLog ，每次写入操作都通过 Paxos 保证写入的一致性，它最多可以允许有 F 个 JournalNode 节点同时故障。\nActive NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog 。还有一点需要注意的是，在 2.0 中不再有 SNN 这个角色了，NameNode 在启动后，会先加载 FSImage 文件和共享目录上的 EditLog Segment 文件，之后 NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式，其中：\n EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点  通信协议  客户端与 NameNode 通过 TCP 连接，并使用客户端协议进行通信 NameNode 和 DataNode 之间使用数据节点协议通信 客户端与 DataNode 之间通过 RPC 进行交互  局限性  命名空间的限制（Hadoop 2.0 已解决） 性能瓶颈：受限于单节点吞吐量 隔离问题：单个 NameSpace 无法对不同应用程序进行隔离（Hadoop 2.0 已解决） 可用性：单个 NameNode 故障无法快速切换（Hadoop 2.0 已解决）  HDFS 存储原理 冗余数据保存 HDFS 采用多副本方式对数据进行冗余存储，通常一个数据库的多个副本会被分布到不同的数据节点。这样多副本具有以下几个优点：\n 加速数据传输 容易检查数据错误 保证数据可靠性  数据存取策略 HDFS 使用的是传统的分级文件体系，因此，用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录之间移动、重命名文件，但不支持修改。\n存储类型  DISK：普通磁盘 SSD：SSD盘 RAM_DISK：内存盘 ARCHIVE：归档/压缩，不是实际的磁盘类型，而是数据被压缩存储。  存储策略 存储策略允许不同的文件存储在不同的存储类型上。目前有以下策略：\n Hot：存储和计算都热。 如果是热快，那么复制的目标也是DISK（普通的磁盘）。 Cold：用于有限计算的存储。 数据不再使用，或者需要归档的数据被移动到冷存储。如果数据块是冷的，则复制使用ARCHIVE. Warm：半冷半热。warm块的复制内容，部分放置在DISK，其它的在ARCHIVE. All_SSD：所有数据存储在SSD. One_SSD：一个复制在SSD，其它的在DISK. Lazy_Persist：只针对只有一个复制的数据块，它们被放在RAM_DISK,之后会被写入DISK。  当创建文件/目录的时候，并未为它们设定了存储策略。 但可以通过hdfs storagepolicies 命令来管理。文件/路径的存储策略按照如下规则解析：\n 如果有设定特定的策略，那么就是那个策略 如果没有设定，就返回上级目录的存储策略。如果是没有策略的根目录，那么返回默认的存储策略（Hot)。  存储时 DataNode 选择 默认情况下，Hadoop 机架感知是没有启用的，需要在NameNode机器的hadoop-site.xml 里配置一个选项。\n当没有配置机架信息时，所有的机器 Hadoop 都默认在同一个默认的机架下，名为 /default-rack，这种情况下，任何一台 DataNode 机器，不管物理上是否属于同一个机架，都会被认为是在同一个机架下，此时，就很容易出现之前提到的增添机架间网络负载的情况。在没有机架信息的情况下， NameNode 默认将所有的 slaves 机器全部默认为在 /default-rack 下，此时写 block 时，三个 DataNode 机器的选择完全是随机的。\n当配置了机架感知信息以后，hadoop在选择三个datanode时，就会进行相应的判断。\n数据读取策略  HDFS 提供 API 可以确定一个数据节点所属机架ID，客户端也可以调用 API 获取自己的机架ID 从名称节点获取数据块不同副本的存放位置列表，列表中包含副本所在的数据节点 客户端调用 API 获取数据节点所属的机架ID，如果与客户端机架ID 相同则优先选择，否则就随机读取  数据错误与恢复 NameNode 出错 HDFS 有备份机制，定时将 FSImage 和 EditLog 备份到 SecondaryNameNode 。当 NameNode 出错，就可以根据 SecondaryNameNode 中的数据进行恢复。\nDataNode 出错 当 DataNode 发生网络问题或机器故障时，这些 DataNode 会被标记为 “宕机”，节点上的数据均被标记为 “不可读”， NameNode 不会再对它发送任何数据请求。这时，由于部分 DataNode 不可用，会导致一些数据块的副本数量小于冗余因子。在这种情况下，NameNode 会启动冗余复制，为数据块生成新的副本。\n数据出错 当文件被创建时，客户端都会对每个文件块进行信息摘要，并将其存储在同路径的隐藏文件里。客户端在读取数据时，会首先获取信息摘要，并对数据块进行 MD5 和 SHA1 校验。如果数据错误，则会向 NameNode 报告错误，NameNode 定时检查并重新复制该数据块。\nHDFS 数据读写过程 写数据过程 具体过程如下：\n Client 调用 DistributedFileSystem 对象的 create 方法，创建一个文件输出流（FSDataOutputStream）对象； 通过 DistributedFileSystem 对象与集群的 NameNode 进行一次 RPC 远程调用，在 HDFS 的 Namespace 中创建一个文件条目（Entry），此时该条目没有任何的 Block，NameNode 会返回该数据每个块需要拷贝的 DataNode 地址信息； 通过 FSDataOutputStream 对象，开始向 DataNode 写入数据，数据首先被写入 FSDataOutputStream 对象内部的数据队列中，数据队列由 DataStreamer 使用，它通过选择合适的 DataNode 列表来存储副本，从而要求 NameNode 分配新的 block； DataStreamer 将数据包以流式传输的方式传输到分配的第一个 DataNode 中，该数据流将数据包存储到第一个 DataNode 中并将其转发到第二个 DataNode 中，接着第二个 DataNode 节点会将数据包转发到第三个 DataNode 节点； DataNode 确认数据传输完成，最后由第一个 DataNode 通知 client 数据写入成功； 完成向文件写入数据，Client 在文件输出流（FSDataOutputStream）对象上调用 close 方法，完成文件写入； 调用 DistributedFileSystem 对象的 complete 方法，通知 NameNode 文件写入成功，NameNode 会将相关结果记录到 editlog 中。   注意：client运行 write 操作后，写完的 block 才是可见的，正在写的 block 对 client 是不可见的，仅仅有调用 sync 方法。client才确保该文件的写操作已经全部完毕。当 client 调用 close 方法时，会默认调用 sync 方法。是否须要手动调用取决你依据程序须要在数据健壮性和吞吐率之间的权衡。\n 读数据过程  Client 通过 DistributedFileSystem 对象与集群的 NameNode 进行一次 RPC 远程调用，获取文件 block 位置信息； NameNode 返回存储的每个块的 DataNode 列表； Client 将连接到列表中最近的 DataNode； Client 开始从 DataNode 并行读取数据； 一旦 Client 获得了所有必须的 block，它就会将这些 block 组合起来形成一个文件。  参考  HDFS机架感知功能原理 - rack awareness HDFS数据存储与读写过程 HDFS 架构学习总结 Hadoop NameNode 高可用 (High Availability) 实现解析  "});index.add({'id':24,'href':'/interview/docs/java/','title':"Java",'content':"Java "});index.add({'id':25,'href':'/interview/docs/java/nio/','title':"NIO",'content':"Channel Java NIO的通道类似流，但又有些不同：\n 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。 通道可以异步地读写。 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。  Selector Selector（选择器）是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。 Channel 可以向 Selector 注册监听四种不同类型的事件：\n Connect Accept Read Write  一旦向 Selector 注册了一或多个通道，就可以调用几个重载的 select() 方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣， select() 方法会返回读事件已经就绪的那些通道。\nselect 方法空转 若 Selector 的轮询结果为空，也没有 wakeup 或新消息处理，则发生空轮询，CPU使用率 100%，Netty的解决办法：对 Selector 的 select 操作周期进行统计，每完成一次空的 select 操作进行一次计数。若在某个周期内连续发生N次空轮询，则触发了 epoll 死循环 bug 。重建 Selector 判断是否是其他线程发起的重建请求，若不是则将原 SocketChannel 从旧的 Selector 上去除注册，重新注册到新的 Selector 上，并将原来的 Selector 关闭。\nSelectionKey 当向 Selector 注册 Channel 时，Channel.register() 方法会返回一个 SelectionKey 对象，这个对象代表了注册到该 Selector 和 Channel 的关联关系，并提供了一组方法来操作。当 Channel 注册的事件来到时，这个对象会在 Selector.selectedKeys() 中返回，直到 Channel 或者 Selector 被关闭。\n isAcceptable isReadable channel selector  Set\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if(key.isAcceptable()) { // a connection was accepted by a ServerSocketChannel.  } else if (key.isConnectable()) { // a connection was established with a remote server.  } else if (key.isReadable()) { // a channel is ready for reading  } else if (key.isWritable()) { // a channel is ready for writing  } keyIterator.remove(); } 注意每次迭代末尾的 keyIterator.remove() 调用。Selector 不会自己从已选择键集中移除 SelectionKey 实例。必须在处理完通道时自己移除。下次该通道变成就绪时， Selector 会再次将其放入已选择键集中。\nBuffer 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成 NIO Buffer 对象，并提供了一组方法，用来方便的访问该块内存。为了理解Buffer的工作原理，需要熟悉它的三个属性： capacity 、 position 、 limit。\nposition 和 limit 的含义取决于 Buffer 处在读模式还是写模式。不管 Buffer 处在什么模式， capacity 的含义总是一样的。\ncapacity：作为一个内存块，Buffer有一个固定的大小值。你只能往里写 capacity 个byte、long，char等类型。一旦 Buffer 满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。\n flip()：方法将 Buffer 从写模式切换到读模式。调用 flip() 方法会将 position 设回 0 ，并将 limit 设置成之前 position 的值。 clear()： position 将被设回0， limit 被设置成 capacity 的值 compact()：将所有未读的数据拷贝到 Buffer 起始处。然后将 position 设到最后一个未读元素正后面。 limit 属性依然像 clear() 方法一样，设置成 capacity 。 rewind()：将 position 设回0，所以你可以重读 Buffer 中的所有数据，limit保持不变。  堆内内存（HeapByteBuffer） HeapByteBuffer 是在 Java Heap 上分配的，但是Java NIO在读写到相应的 Channel 的时候，会先将 Java Heap 的 buffer 内容拷贝至直接内存 —— Direct Memory。这样的话，无疑 DirectByteBuffer 的 IO 性能肯定强于使用 HeapByteBuffer ，它省去了临时 buffer 的拷贝开销。\n堆外内存（DirectByteBuffer） DirectByteBuffer 底层的数据其实是维护在 JVM 堆外的用户空间中， DirectByteBuffer 里维护了一个引用 address 指向了数据，从而操作数据。虽然 GC 仍然管理着 DirectBuffer 的回收，但它是使用 PhantomReference 来达到的，在平常的 Young GC 或者 mark and compact 的时候却不会在内存里搬动。如果IO的数量比较大，比如在网络发送很大的文件，那么 GC 的压力下降就会很明显。只有在 Full GC 以及调用 System.gc 的时候才会进行回收。\nDirectByteBuffer Java 堆内只会占用一个对象的指针引用的大小，堆外的的空间只有当 java 对象被回收时，才会被回收，这里会发现一个明显的不对称现象，就是堆外可能占用了很多，而堆内没占用多少，导致还没触发 GC ，那就很容易出现 Direct Memory 造成物理内存耗光。\nEchoNIOServer @Slf4j public class NIOServer { private static final ByteBuffer buffer = ByteBuffer.allocate(32); public static void main(String[] args) throws Exception { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(8080)); serverSocketChannel.configureBlocking(false); Selector selector = Selector.open(); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { if (selector.select() == 0) { log.warn(\u0026#34;selector.select() == 0\u0026#34;); TimeUnit.MILLISECONDS.sleep(100); continue; } Iterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator(); while (iterator.hasNext()) { SelectionKey selectedKey = iterator.next(); if (selectedKey.isAcceptable()) { handleAccept(selectedKey); } else if (selectedKey.isReadable()) { handleRead(selectedKey); } else { log.warn(\u0026#34;{}\u0026#34;, selectedKey); } iterator.remove(); } } } private static void handleRead(SelectionKey selectedKey) throws Exception { SocketChannel channel = (SocketChannel) selectedKey.channel(); int readSize = channel.read(buffer); if (readSize == -1) { channel.close(); return; } buffer.flip(); byte[] readed = Arrays.copyOf(buffer.array(), readSize); log.info(\u0026#34;from:{} read data:{}\u0026#34;, channel, new String(readed)); buffer.clear(); buffer.put(\u0026#34;echo:\u0026#34;.getBytes()); buffer.put(readed); buffer.flip(); channel.write(buffer); buffer.compact(); } private static void handleAccept(SelectionKey selectionKey) throws Exception { ServerSocketChannel serverSocketChannel = (ServerSocketChannel) selectionKey.channel(); SocketChannel socketChannel = serverSocketChannel.accept(); socketChannel.configureBlocking(false); socketChannel.register(selectionKey.selector(), SelectionKey.OP_READ); log.info(\u0026#34;handleAccept from:{}\u0026#34;, socketChannel); } "});index.add({'id':26,'href':'/interview/docs/architecture/','title':"Architecture",'content':""});index.add({'id':27,'href':'/interview/docs/architecture/design/','title':"Design",'content':""});index.add({'id':28,'href':'/interview/docs/fromwork/','title':"Fromwork",'content':""});index.add({'id':29,'href':'/interview/docs/fromwork/mybatis/','title':"Mybatis",'content':""});index.add({'id':30,'href':'/interview/docs/leetcode/','title':"Leetcode",'content':"LeetCode 包含头条常见的面试题\n"});index.add({'id':31,'href':'/interview/docs/offer/','title':"Offer",'content':"剑指Offer 包含 剑指Offer 一直 60 道算法题目\n常用技巧  异或运算 删除链表节点时，可通过复制下一个节点的方式减少遍历 保存计算结果来减少重复计算，优化时间效率 分治的思想 滑动窗口 数学建模  "});index.add({'id':32,'href':'/interview/docs/fromwork/spring/aop/','title':"AOP",'content':"AOP AOP 的存在价值 在传统 OOP 编程里以对象为核心，整个软件系统由系列相互依赖的对象所组成，而这些对象将被抽象成一个一个的类，并允许使用类继承来管理类与类之间一般到特殊的关系。随着软件规模的增大，应用的逐渐升级，慢慢出现了一些 OOP 很难解决的问题。\n我们可以通过分析、抽象出一系列具有一定属性与行为的对象，并通过这些对象之间的协作来形成一个完整的软件功能。由于对象可以继承，因此我们可以把具有相同功能或相同特性的属性抽象到一个层次分明的类结构体系中。随着软件规范的不断扩大，专业化分工越来越系列，以及 OOP 应用实践的不断增多，随之也暴露出了一些 OOP 无法很好解决的问题。\n现在假设系统中有 3 段完全相似的代码，这些代码通常会采用“复制”、“粘贴”方式来完成，通过这种“复制”、“粘贴”方式开发出来的软件如图 1 所示。\n看到如上图所示的示意图，可能有的读者已经发现了这种做法的不足之处：如果有一天，上图中的深色代码段需要修改，那是不是要打开 3 个地方的代码进行修改？如果不是 3 个地方包含这段代码，而是 100 个地方，甚至是 1000 个地方包含这段代码段，那会是什么后果？\n为了解决这个问题，我们通常会采用将如上图所示的深色代码部分定义成一个方法，然后在 3 个代码段中分别调用该方法即可。在这种方式下，软件系统的结构如下图所示。\n"});index.add({'id':33,'href':'/interview/docs/java/concurrent/AQS/','title':"AQS",'content':"AQS AQS 提供一个框架，用于实现依赖于先进先出（FIFO）等待队列 的阻塞锁和相关同步器（信号量，事件等）。对于大多数依赖单个原子 int 值表示状态的同步器，该类可以作为十分有用的基类。子类必须定义所有的protected方法（包括tryAcquire、tryRelease），来改变这个状态，并且定义哪些状态代表来对象被使用和被释放。鉴于这些，该类中其他的方法用来实现队列和阻塞的机制。子类可以维护其他状态字段，但是只有使用 getState 、setState以及 compareAndSetState 来原子的操作状态值。\n子类需要定义非 public 的内部工具类用于实现其内部类的同步属性。AbstractQueuedSynchronizer 类不实现任何同步接口，相反，它定义了诸如acquireInterruptibly之类的方法，可以被具体的锁和相关的同步器适当地调用，以实现它们的公共方法。\n该类支持默认的独占模式和共享模式。当一个线程处在独占模式下，其他试图 acquire 的线程都无法成功。共享模式可以同时被多个线程 acquire成功。在具体的应用场景中该类无法理解这些区别，当共享模式 acquire 成功之后，下一个线程（如果有一个存在）必须判定是否能够acquire。线程等待在不同的模式里但是会共享同一个FIFO队列。通常来说，子类只需要支持其中一种模式，但是如果都支持，可以参照ReadWriteLock。子类不需要定义不支持模式的方法。\n该类定义AbstractQueuedSynchronizer.ConditionObject内部类，可以被子类使用的 Condition 实现，来支持独占模式 isHeldExclusively 判定当前线程的同步是否是独占模式，可用通过release方法与 getState 方法来完全释放当前对象，在将保存的状态值调用acquire，最终将此对象恢复到其先前获取的状态。AbstractQueuedSynchronizer没有方法来创建 Condition，所以如果无法满足这个约束，则不要使用它。AbstractQueuedSynchronizer.ConditionObject 的行为与具体的同步器实现有关。\n该类为内部队列提供检查，检测和监视方法，以及 在condition objects上的类似方法。 这些方法可以根据需要使用 AbstractQueuedSynchronizer 用于它们的同步机制。该类的序列化仅存储 atomic int 的状态值，因此反序列化对象的线程队列为空。\n使用 为了使用该类去创建一个同步器，需要重新定义以下方法，并使用 getState, setState, compareAndSetState 方法来改变同步状态。\n tryAcquire tryRelease tryAcquireShared tryReleaseShared isHeldExclusively  上述所有方法默认实现都会抛出 UnsupportedOperationException。这个方法的具体实现必须保证内部的线程安全，并且应该快速并且不会阻塞。所有其他方法均为 final，因为他们不能独立变化。\n也许你发现一些继承自 AbstractOwnableSynchronizer 的方法非常有助于线程保持拥有其独占同步器。同时我们也鼓励使用他们，有助于监控和诊断工具判定哪些线程持有来锁。\nReentrantLock  公平锁相比与非公平锁在 tryAcquire中会多判定一个 hasQueuedPredecessors，如果为 false（队列头为当前线程\u0026ndash;已获取锁 or 队列为空）并且成功修改状态值，则可以认为获取锁成功，这样才是重入，不然加到队尾就会有麻烦。\n ReentrantLock 中通过两个子类 FairSync 和 NoFairSync 继承 AQS 来实现锁。在Lock方法中，直接调用 AQS 的 acquire，acquire会调用 NoFairSync 中的tryAcquire来尝试让当前线程直接获取锁。如果失败则会创建链表节点，将当前线程加入队列，并park。当release方法被调用后，会寻找队列下一个节点进行 unpark，这样他就有机会在acquireQueued中获取锁。\n 公平和非公平就体现在 tryAcquire 方法中，FairSync会判定当前线程是否已获取锁 or 队列为空，在这样的情况下才会尝试获取锁。而NoFairSync会直接来获取锁。\n Condition Condition 因子将 Object monitor 方法（wait, notify and notifyAll）拆分为不同的对象，通过将它们与 Lock 相结合来实现每个对象具有多个等待集的效果。任何 Lock 可以替代 synchronized 关键字的地方，都可以用Condition 来替换Object monitor 方法。\nConditions（也称为 条件队列 或者 条件变量）提供了一种方法 \u0026ndash; 让线程暂停执行，直到其他线程基于某种条件唤醒。在多个线程中访问一些共享的状态信息，是需要进行保护的，所以 Lock 与 Condition 有某种形式的关联。Condition提供的关键属性是它以原子方式释放关联的锁并挂起当前线程，就像Object.wait一样。\nCondition 本质上是绑定到 Lock。可以通过 Lock.newCondition() 来获取一个 Condition 实例。\nCondition 的实现可以提供相比于 Object monitor方法不一样的行为和语义，比如：被通知调起的顺序、在通知时不需要持有锁。如果实现类提供了不一样的语义，必须在文档中进行说明。\nCondition 实例只是普通的对象，可以用在同步语句中，并且有他们自己的 Object monitor的wait和 notification 方法。获取 Condition 对象的 Object monitor 或者使用其 monitor 方法，与Lock 中使用 Condition 的 wait 或者 signal 方法没有任何关系。为了避免混淆，不建议使用 Condition 的 Object monitor 方法，除非在它自己的实现里。\n实现类需要注意  虚假唤醒（spurious wakeup）：开发者最好将条件 wait 方法放在循环中 Condition 有3中 wait 形式（interruptible, non-interruptible, and timed），在不同平台的底层实现可能不同。因此，不需要对三种 wait 定义一致的语义，也不需要支持中断形式的线程暂停。  AbstractQueuedSynchronizer.ConditionObject /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; 在 ConditionObject 的内部维护了一个队列：条件队列，与 AbstractQueuedSynchronizer 里的 等待队列 不同。\n基本上，把这张图看懂，你也就知道 condition 的处理流程了。\n 条件队列和等待队列的节点，都是 Node 的实例，因为条件队列的节点是需要转移到等待队列中去的； 我们知道一个 ReentrantLock 实例可以通过多次调用 newCondition() 来产生多个 Condition 实例，这里对应 condition1 和 condition2。注意，ConditionObject 只有两个属性 firstWaiter 和 lastWaiter； 每个 condition 有一个关联的条件队列，如线程 1 调用 condition1.await() 方法即可将当前线程 1 包装成 Node 后加入到条件队列中，然后阻塞在这里，不继续往下执行，条件队列是一个单向链表； 调用condition1.signal() 触发一次唤醒，此时唤醒的是队头，会将condition1 对应的条件队列的 firstWaiter（队头） 移到等待队列的队尾，等待获取锁，获取锁后 await 方法才能返回，继续往下执行。  上面的 2-\u0026gt;3-\u0026gt;4 描述了一个最简单的流程，没有考虑中断、signalAll、还有带有超时参数的 await 方法等，不过把这里弄懂是这节的主要目的。\n"});index.add({'id':34,'href':'/interview/docs/java/collection/BlockQueue/','title':"BlockingQueue",'content':"BlockingQueue BlockingQueue 支持当获取队列元素但是队列为空时，会阻塞等待队列中有元素再返回；也支持添加元素时，如果队列已满，那么等到队列可以放入新元素时再放入。\n其提供了4种类型的方法：\n    Throws exception Special value Blocks Times out     Insert add(e) offer(e) put(e) offer(e, time, unit)   Remove remove() poll() take() poll(time, unit)   Examine element() peek() not applicable not applicable    BlockingQueue不接受 null 元素。所有实现应当抛出 NullPointerException 在所有的 add,put以及offer方法上。null被用来标记poll失败。\n在任意时刻，当有界BlockingQueue 队列元素放满之后，所有的元素都将在放入的时候阻塞。无界BlockingQueue 没有任何容量限制，容量大小始终是Integer.MAX_VALUE。\nBlockingQueue的实现是用于 生产者-消费者 的队列，同时也支持 Collection 接口。所以可通过remove(x)来移除队列里的一个元素。通常情况下，这样的操作效率不是很好，只在诸如队列消息被取消的情况下才会偶尔使用。\nBlockingQueue 的实现都是线程安全的。所有 queue 的方法都需要通过内部锁机制或者其他形式来进行并发控制来实现其原子操作。然而，Collection 接口的方法，比如：addAll, containsAll, retainAll 以及 removeAll 都没有必要进行原子操作，除非实现类有特别说明。所以对于addAll(c)有可能在添加部分c元素后抛出异常。\nBlockingQueue 本质上不支持任何的 close 或者 shutdown 操作，来表明不会有新的元素添加。如果需要这些特性，得实现类来支持。\nArrayBlockingQueue ArrayBlockingQueue 是底层由数组存储的有界队列。遵循FIFO，所以在队首的元素是在队列中等待时间最长的，而在队尾的则是最短时间的元素。新元素被插入到队尾，队列的取出 操作队首元素。\n这是一个经典的有界缓存，由一个长度确定的数组持有所有由生产者插入、由消费者取出的元素。一旦创建，整个队列的容量将不会改变。尝试向一个已满的队列 put 将会导致调用被阻塞，同样的向一个空队列 take 也会阻塞。\n该队列支持队等待的生产者和消费者实施可选的公平策略。默认情况下，是非公平策略。可以通过构造函数来指定是否进行公平策略。一般情况下公平策略会减小吞吐量，但是也会降低可变性以及防止饥饿效应。\n实现 ArrayBlockingQueue 内部使用了 ReentrantLock 以及两个 Condition 来实现。\n/** Main lock guarding all access */ final ReentrantLock lock; /** Condition for waiting takes */ private final Condition notEmpty; /** Condition for waiting puts */ private final Condition notFull; PUT 方法也很简单，就是 Condition 的应用。\npublic void put(E e) throws InterruptedException { checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { //队列已满，wait 在 condition 上 while (count == items.length) notFull.await(); enqueue(e); } finally { lock.unlock(); } } take 方法也同样的。\npublic E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { //队列为空，wait 在 condition 上 while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } "});index.add({'id':35,'href':'/interview/docs/java/collection/Concurrenthashmap/','title':"ConcurrentHashmap",'content':"ConcurrentHashmap JDK1.7 ConcurrentHashMap的锁分段技术：假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。\n ConcurrentHashMap不允许Key或者Value的值为NULL。ConcurrentMaps中不允许空值的主要原因是，在非并发映射中几乎不能容忍的模糊性是无法容纳的。主要的一点是如果map.get（key）返回null，则无法检测 key 是否显式映射为 null 或者 key 未映射。 在非并发映射中，您可以通过 map.contains（key） 进行检查，但在并发映射中，映射可能在调用之间发生了变化。\n Segment类 Put 将一个HashEntry放入到该Segment中，使用自旋机制，减少了加锁的可能性。\nfinal V put(K key, int hash, V value, boolean onlyIfAbsent) { HashEntry\u0026lt;K,V\u0026gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); //如果加锁失败，则调用该方法 V oldValue; try { HashEntry\u0026lt;K,V\u0026gt;[] tab = table; int index = (tab.length - 1) \u0026amp; hash; //同hashMap相同的哈希定位方式 HashEntry\u0026lt;K,V\u0026gt; first = entryAt(tab, index); for (HashEntry\u0026lt;K,V\u0026gt; e = first;;) { if (e != null) { //若不为null，则持续查找，知道找到key和hash值相同的节点，将其value更新 K k; if ((k = e.key) == key || (e.hash == hash \u0026amp;\u0026amp; key.equals(k))) { oldValue = e.value; if (!onlyIfAbsent) { e.value = value; ++modCount; } break; } e = e.next; } else { //若头结点为null if (node != null) //在遍历key对应节点链时没有找到相应的节点 node.setNext(first); //当前修改并不需要让其他线程知道，在锁退出时修改自然会 //更新到内存中,可提升性能 else node = new HashEntry\u0026lt;K,V\u0026gt;(hash, key, value, first); int c = count + 1; if (c \u0026gt; threshold \u0026amp;\u0026amp; tab.length \u0026lt; MAXIMUM_CAPACITY) rehash(node); //如果超过阈值，则进行rehash操作 else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; } } } finally { unlock(); } return oldValue; } scanAndLockForPut 该操作持续查找key对应的节点链中是否已存在该节点，如果没有找到已存在的节点，则预创建一个新节点，并且尝试n次，直到尝试次数超出限制，才真正进入等待状态，即所谓的 自旋等待。\nprivate HashEntry\u0026lt;K,V\u0026gt; scanAndLockForPut(K key, int hash, V value) { //根据hash值找到segment中的HashEntry节点 HashEntry\u0026lt;K,V\u0026gt; first = entryForHash(this, hash); //首先获取头结点 HashEntry\u0026lt;K,V\u0026gt; e = first; HashEntry\u0026lt;K,V\u0026gt; node = null; int retries = -1; // negative while locating node while (!tryLock()) { //持续遍历该哈希链 HashEntry\u0026lt;K,V\u0026gt; f; // to recheck first below if (retries \u0026lt; 0) { if (e == null) { if (node == null) //若不存在要插入的节点，则创建一个新的节点 node = new HashEntry\u0026lt;K,V\u0026gt;(hash, key, value, null); retries = 0; } else if (key.equals(e.key)) retries = 0; else e = e.next; } else if (++retries \u0026gt; MAX_SCAN_RETRIES) { //尝试次数超出限制，则进行自旋等待 lock(); break; } /*当在自旋过程中发现节点链的链头发生了变化，则更新节点链的链头， 并重置retries值为－1，重新为尝试获取锁而自旋遍历*/ else if ((retries \u0026amp; 1) == 0 \u0026amp;\u0026amp; (f = entryForHash(this, hash)) != first) { e = first = f; // re-traverse if entry changed retries = -1; } } return node; } remove 用于移除某个节点，返回移除的节点值。\nfinal V remove(Object key, int hash, Object value) { if (!tryLock()) scanAndLock(key, hash); V oldValue = null; try { HashEntry\u0026lt;K,V\u0026gt;[] tab = table; int index = (tab.length - 1) \u0026amp; hash; //根据这种哈希定位方式来定位对应的HashEntry HashEntry\u0026lt;K,V\u0026gt; e = entryAt(tab, index); HashEntry\u0026lt;K,V\u0026gt; pred = null; while (e != null) { K k; HashEntry\u0026lt;K,V\u0026gt; next = e.next; if ((k = e.key) == key || (e.hash == hash \u0026amp;\u0026amp; key.equals(k))) { V v = e.value; if (value == null || value == v || value.equals(v)) { if (pred == null) setEntryAt(tab, index, next); else pred.setNext(next); ++modCount; --count; oldValue = v; } break; } pred = e; e = next; } } finally { unlock(); } return oldValue; } Clear 要首先对整个segment加锁，然后将每一个HashEntry都设置为null。\nfinal void clear() { lock(); try { HashEntry\u0026lt;K,V\u0026gt;[] tab = table; for (int i = 0; i \u0026lt; tab.length ; i++) setEntryAt(tab, i, null); ++modCount; count = 0; } finally { unlock(); } } Put public V put(K key, V value) { Segment\u0026lt;K,V\u0026gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); //求出key的hash值 int j = (hash \u0026gt;\u0026gt;\u0026gt; segmentShift) \u0026amp; segmentMask; //求出key在segments数组中的哪一个segment中 if ((s = (Segment\u0026lt;K,V\u0026gt;)UNSAFE.getObject (segments, (j \u0026lt;\u0026lt; SSHIFT) + SBASE)) == null) s = ensureSegment(j); //使用unsafe操作取出该segment return s.put(key, hash, value, false); //向segment中put元素 } Get public V get(Object key) { Segment\u0026lt;K,V\u0026gt; s; HashEntry\u0026lt;K,V\u0026gt;[] tab; int h = hash(key); //找出对应的segment的位置 long u = (((h \u0026gt;\u0026gt;\u0026gt; segmentShift) \u0026amp; segmentMask) \u0026lt;\u0026lt; SSHIFT) + SBASE; if ((s = (Segment\u0026lt;K,V\u0026gt;)UNSAFE.getObjectVolatile(segments, u)) != null \u0026amp;\u0026amp; (tab = s.table) != null) { //使用Unsafe获取对应的Segmen for (HashEntry\u0026lt;K,V\u0026gt; e = (HashEntry\u0026lt;K,V\u0026gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) \u0026amp; h)) \u0026lt;\u0026lt; TSHIFT) + TBASE); e != null; e = e.next) { //找出对应的HashEntry，从头开始遍历 K k; if ((k = e.key) == key || (e.hash == h \u0026amp;\u0026amp; key.equals(k))) return e.value; } } return null; } Size 求出所有的HashEntry的数目，先尝试的遍历查找、计算2遍，如果两遍遍历过程中整个Map没有发生修改（即两次所有Segment实例中modCount值的和一致），则可以认为整个查找、计算过程中Map没有发生改变。否则,需要对所有segment实例进行加锁、计算、解锁，然后返回。\npublic int size() { final Segment\u0026lt;K,V\u0026gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try { for (;;) { if (retries++ == RETRIES_BEFORE_LOCK) { for (int j = 0; j \u0026lt; segments.length; ++j) ensureSegment(j).lock(); // force creation } sum = 0L; size = 0; overflow = false; for (int j = 0; j \u0026lt; segments.length; ++j) { Segment\u0026lt;K,V\u0026gt; seg = segmentAt(segments, j); if (seg != null) { sum += seg.modCount; int c = seg.count; if (c \u0026lt; 0 || (size += c) \u0026lt; 0) overflow = true; } } if (sum == last) break; last = sum; } } finally { if (retries \u0026gt; RETRIES_BEFORE_LOCK) { for (int j = 0; j \u0026lt; segments.length; ++j) segmentAt(segments, j).unlock(); } } return overflow ? Integer.MAX_VALUE : size; } JDK1.8 在JDK1.8中对ConcurrentHashmap做了两个改进：\n  取消segments字段，直接采用transient volatile HashEntry\u0026lt;K,V\u0026gt;[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。\n  将原先 table数组＋单向链表 的数据结构，变更为 table数组＋单向链表＋红黑树 的结构。对于 hash 表来说，最核心的能力在于将 key hash 之后能均匀的分布在数组中。如果 hash 之后散列的很均匀，那么 table 数组中的每个队列长度主要为 0 或者 1 。但实际情况并非总是如此理想，虽然 ConcurrentHashMap 类默认的加载因子为 0.75，但是在数据量过大或者运气不佳的情况下，还是会存在一些队列长度过长的情况，如果还是采用单向列表方式，那么查询某个节点的时间复杂度为   \\(O(n)\\)  ；因此，对于个数超过 8 (默认值)的链表，jdk1.8 中采用了红黑树的结构，那么查询的时间复杂度可以降低到 \\(O(logN)\\)  ，可以改进性能。\n  Put final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); // 得到 hash 值 int hash = spread(key.hashCode()); // 用于记录相应链表的长度 int binCount = 0; for (Node\u0026lt;K,V\u0026gt;[] tab = table;;) { Node\u0026lt;K,V\u0026gt; f; int n, i, fh; // 如果数组\u0026quot;空\u0026quot;，进行数组初始化 if (tab == null || (n = tab.length) == 0) // 初始化数组，后面会详细介绍 tab = initTable(); // 找该 hash 值对应的数组下标，得到第一个节点 f else if ((f = tabAt(tab, i = (n - 1) \u0026amp; hash)) == null) { // 如果数组该位置为空， // 用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了 // 如果 CAS 失败，那就是有并发操作，进到下一个循环就好了 if (casTabAt(tab, i, null, new Node\u0026lt;K,V\u0026gt;(hash, key, value, null))) break; // no lock when adding to empty bin } // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容 else if ((fh = f.hash) == MOVED) // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了 tab = helpTransfer(tab, f); else { // 到这里就是说，f 是该位置的头结点，而且不为空 V oldVal = null; // 获取数组该位置的头结点的监视器锁 synchronized (f) { if (tabAt(tab, i) == f) { if (fh \u0026gt;= 0) { // 头结点的 hash 值大于 0，说明是链表 // 用于累加，记录链表的长度 binCount = 1; // 遍历链表 for (Node\u0026lt;K,V\u0026gt; e = f;; ++binCount) { K ek; // 如果发现了\u0026quot;相等\u0026quot;的 key，判断是否要进行值覆盖，然后也就可以 break 了 if (e.hash == hash \u0026amp;\u0026amp; ((ek = e.key) == key || (ek != null \u0026amp;\u0026amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } // 到了链表的最末端，将这个新值放到链表的最后面 Node\u0026lt;K,V\u0026gt; pred = e; if ((e = e.next) == null) { pred.next = new Node\u0026lt;K,V\u0026gt;(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { // 红黑树 Node\u0026lt;K,V\u0026gt; p; binCount = 2; // 调用红黑树的插值方法插入新节点 if ((p = ((TreeBin\u0026lt;K,V\u0026gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8 if (binCount \u0026gt;= TREEIFY_THRESHOLD) // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换， // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树 // 具体源码我们就不看了，扩容部分后面说 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } // addCount(1L, binCount); return null; } Get  计算 hash 值 根据 hash 值找到数组对应位置: (n - 1) \u0026amp; h 根据该位置处结点性质进行相应查找  如果该位置为 null ，那么直接返回 null 就可以了 如果该位置处的节点刚好就是我们需要的，返回该节点的值即可 如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，后面我们再介绍 find 方法 如果以上 3 条都不满足，那就是链表，进行遍历比对即可    "});index.add({'id':36,'href':'/interview/docs/java/concurrent/count-down-latch/','title':"CountDownLatch",'content':"CountDownLatch CountDownLatch 是可以使一个或者多个线程等待其他线程完成某些操作的同步器。CountDownLatch 通过一个给定的数字 count 进行初始化。调用 await 方法的线程会一直阻塞到其他线程调用 countDown 将 count 变为0，这时所有的线程都将释放，并且后续的 await 方法调用都会立即返回。count 值不能重置。如果你需要重置 count 请考虑使用 CyclicBarrier。\nCountDownLatch 是一个能力很强的同步工具，可以用在多种途径。CountDownLatch 最重要的属性是其不要求 调用 countDown 的线程等待到 count 为0，只是要求所有 await 调用线程等待。\nCountDownLatch 内部使用的是 AQS，AQS 里面的 state 是一个整数值，这边用一个 int count 参数其实初始化就是设置了这个值，所有调用了 await 方法的等待线程会挂起，然后有其他一些线程会做 state = state - 1 操作，当 state 减到 0 的同时，那个将 state 减为 0 的线程会负责唤醒 所有调用了 await 方法的线程。\n countDown() 方法每次调用都会将 state 减 1，直到 state 的值为 0；而 await 是一个阻塞方法，当 state 减为 0 的时候，await 方法才会返回。await 可以被多个线程调用，读者这个时候脑子里要有个图：所有调用了 await 方法的线程阻塞在 AQS 的阻塞队列中，等待条件满足（state == 0），将线程从队列中一个个唤醒过来。 await() 方法，它代表线程阻塞，等待 state 的值减为 0。  "});index.add({'id':37,'href':'/interview/docs/architecture/distributed/dubbo/','title':"Dubbo",'content':"Dubbo 领域模型 在 Dubbo 的核心领域模型中：\n Protocol 是服务域，它是 Invoker 暴露和引用的主功能入口，它负责 Invoker 的生命周期管理。 Invoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。 Invocation 是会话域，它持有调用过程中的变量，比如方法名，参数等。  基本设计原则  采用 Microkernel + Plugin 模式，Microkernel 只负责组装 Plugin，Dubbo 自身的功能也是通过扩展点实现的，也就是 Dubbo 的所有功能点都可被用户自定义扩展所替换。 采用 URL 作为配置信息的统一格式，所有扩展点都通过传递 URL 携带配置信息。  Dubbo 服务暴露过程 官方文档\u0026ndash;服务导出\nDubbo 结构  第一层：service 层，接口层，给服务提供者和消费者来实现的 第二层：config 层，配置层，主要是对 dubbo 进行各种配置的 第三层：proxy 层，服务代理层，无论是 consumer 还是 provider，dubbo 都会给你生成代理，代理之间进行网络通信 第四层：registry 层，服务注册层，负责服务的注册与发现 第五层：cluster 层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务 第六层：monitor 层，监控层，对 rpc 接口的调用次数和调用时间进行监控 第七层：protocal 层，远程调用层，封装 rpc 调用 第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步 第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口 第十层：serialize 层，数据序列化层  工作流程  第一步：provider 向注册中心去注册 第二步：consumer 从注册中心订阅服务，注册中心会通知 consumer 注册好的服务 第三步：consumer 调用 provider 第四步：consumer 和 provider 都异步通知监控中心  注册中心挂了可以继续通信吗？ 可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到 本地缓存，所以注册中心挂了可以继续通信。\nDubbo 支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？ Dubbo 支持不同的通信协议  dubbo 协议：默认就是走 dubbo 协议，单一长连接，进行的是 NIO 异步通信，基于 hessian 作为序列化协议。使用的场景是：传输数据量小（每次请求在 100kb 以内），但是并发量很高。 rmi 协议：走 Java 二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。 hessian 协议：走 hessian 序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件的传输，一般较少用。 http 协议：走 json 序列化 webservice：走 SOAP 文本序列化  Dubbo 支持的序列化协议 dubbo 支持 hession 、 Java 二进制序列化、json、SOAP 文本序列化多种序列化协议。但是 hessian 是其默认的序列化协议。\n为什么 PB 的效率是最高的？ 其实 PB 之所以性能如此好，主要得益于两个：\n 它使用 proto 编译器，自动进行序列化和反序列化，速度非常快，应该比 XML 和 JSON 快上了 20~100 倍； 它的数据压缩效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。  dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？ dubbo 负载均衡策略 random loadbalance 默认情况下，dubbo 是 random load balance ，即 随机 调用实现负载均衡，可以对 provider 不同实例 设置不同的权重，会按照权重来负载均衡，权重越大分配流量越高，一般就用这个默认的就可以了。\nroundrobin loadbalance 这个的话默认就是均匀地将流量打到各个机器上去，但是如果各个机器的性能不一样，容易导致性能差的机器负载过高。所以此时需要调整权重，让性能差的机器承载权重小一些，流量少一些。\nleastactive loadbalance 这个就是自动感知一下，如果某个机器性能越差，那么接收的请求越少，越不活跃，此时就会给 不活跃的性能差的机器更少的请求。\nconsistanthash loadbalance 一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去， provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。如果你需要的不是随机负载均衡，是要一类请求都到一个节点，那就走这个一致性 Hash 策略。\ndubbo 集群容错策略 failover cluster 模式 失败自动切换，自动重试其他机器，默认就是这个，常见于读操作。（失败重试其它机器）\nfailfast cluster模式 一次调用失败就立即失败，常见于写操作。（调用失败就立即失败）\nfailsafe cluster 模式 出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。\nfailback cluster 模式 失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。\nforking cluster 模式 并行调用 多个 provider ，只要一个成功就立即返回。\nbroadcacst cluster 逐个调用所有的 provider。\ndubbo动态代理策略 默认使用 javassist 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。\ndubbo 的 spi 思想是什么？ spi ，简单来说，就是 service provider interface，说白了是什么意思呢，比如你有个接口，现在这个接口有 3 个实现类，那么在系统运行的时候对这个接口到底选择哪个实现类呢？这就需要 spi 了，需要根据指定的配置或者是默认的配置，去找到对应的实现类加载进来，然后用这个实现类的实例对象。\ndubbo 也用了 spi 思想，不过没有用 jdk 的 spi 机制，是自己实现的一套 spi 机制。\nProtocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); Protocol 接口，在系统运行的时候， dubbo 会判断一下应该选用这个 Protocol 接口的哪个实现类来实例化对象来使用。\n它会去找一个你配置的 Protocol ，将你配置的 Protocol 实现类，加载到 jvm 中来，然后实例化对象，就用你的那个 Protocol 实现类就可以了。\n与 Java SPI 对比  JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。 增加了对扩展点 IoC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。 如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK 标准的 ScriptEngine，通过 getName() 获取脚本类型的名称，但如果 RubyScriptEngine 因为所依赖的 jruby.jar 不存在，导致 RubyScriptEngine 类加载失败，这个失败原因被吃掉了，和 ruby 对应不起来，当用户执行 ruby 脚本时，会报不支持 ruby，而不是真正失败的原因。  如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？ 服务治理 1. 调用链路自动生成 一个大型的分布式系统，或者说是用现在流行的微服务架构来说吧，分布式系统由大量的服务组成。那么这些服务之间互相是如何调用的？调用链路是啥？说实话，几乎到后面没人搞的清楚了，因为服务实在太多了，可能几百个甚至几千个服务。\n那就需要基于 dubbo 做的分布式系统中，对各个服务之间的调用自动记录下来，然后自动将 各个服务之间的依赖关系和调用链路生成出来，做成一张图，显示出来，大家才可以看到对吧。\n2. 服务访问压力以及时长统计 需要自动统计 各个接口和服务之间的调用次数以及访问延时，而且要分成两个级别。\n 一个级别是接口粒度，就是每个服务的每个接口每天被调用多少次，TP50/TP90/TP99，三个档次的请求延时分别是多少； 第二个级别是从源头入口开始，一个完整的请求链路经过几十个服务之后，完成一次请求，每天全链路走多少次，全链路请求延时的 TP50/TP90/TP99，分别是多少。  这些东西都搞定了之后，后面才可以来看当前系统的压力主要在哪里，如何来扩容和优化啊。\n3. 其它  服务分层（避免循环依赖） 调用链路失败监控和报警 服务鉴权 每个服务的可用性的监控（接口调用成功率？几个 9？99.99%，99.9%，99%）  服务降级 比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。\n举个栗子，我们有接口 HelloService。HelloServiceImpl 有该接口的具体实现。\npublic interface HelloService { void sayHello(); } public class HelloServiceImpl implements HelloService { public void sayHello() { System.out.println(\u0026quot;hello world......\u0026quot;); } } \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:dubbo=\u0026#34;http://code.alibabatech.com/schema/dubbo\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\u0026#34;\u0026gt; \u0026lt;dubbo:application name=\u0026#34;dubbo-provider\u0026#34; /\u0026gt; \u0026lt;dubbo:registry address=\u0026#34;zookeeper://127.0.0.1:2181\u0026#34; /\u0026gt; \u0026lt;dubbo:protocol name=\u0026#34;dubbo\u0026#34; port=\u0026#34;20880\u0026#34; /\u0026gt; \u0026lt;dubbo:service interface=\u0026#34;com.zhss.service.HelloService\u0026#34; ref=\u0026#34;helloServiceImpl\u0026#34; timeout=\u0026#34;10000\u0026#34; /\u0026gt; \u0026lt;bean id=\u0026#34;helloServiceImpl\u0026#34; class=\u0026#34;com.zhss.service.HelloServiceImpl\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:dubbo=\u0026#34;http://code.alibabatech.com/schema/dubbo\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\u0026#34;\u0026gt; \u0026lt;dubbo:application name=\u0026#34;dubbo-consumer\u0026#34; /\u0026gt; \u0026lt;dubbo:registry address=\u0026#34;zookeeper://127.0.0.1:2181\u0026#34; /\u0026gt; \u0026lt;dubbo:reference id=\u0026#34;fooService\u0026#34; interface=\u0026#34;com.test.service.FooService\u0026#34; timeout=\u0026#34;10000\u0026#34; check=\u0026#34;false\u0026#34; mock=\u0026#34;return null\u0026#34;\u0026gt; \u0026lt;/dubbo:reference\u0026gt; \u0026lt;/beans\u0026gt; 我们调用接口失败的时候，可以通过 mock 统一返回 null 。\nmock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口名称+Mock” 后缀。然后在 Mock 类里实现自己的降级逻辑。\npublic class HelloServiceMock implements HelloService { public void sayHello() { // 降级逻辑 } } 失败重试和超时重试 所谓失败重试，就是 consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。配置如下：\n\u0026lt;dubbo:reference id=\u0026#34;xxxx\u0026#34; interface=\u0026#34;xx\u0026#34; check=\u0026#34;true\u0026#34; async=\u0026#34;false\u0026#34; retries=\u0026#34;3\u0026#34; timeout=\u0026#34;2000\u0026#34;/\u0026gt; 参考链接 advanced-java\n"});index.add({'id':38,'href':'/interview/docs/java/collection/HashMap/','title':"HashMap",'content':"HashMap 在get和put的过程中，计算下标时，先对hashCode进行hash操作，然后再通过hash值进一步计算下标，如下图所示：\n在对hashCode()计算hash时具体实现是这样的：\nstatic final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); }  可以看到这个函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或。\n 在设计hash函数时，因为目前的table长度n为2的幂，而计算下标的时候，是这样实现的(使用\u0026amp;位操作，而非%求余)。设计者认为这方法很容易发生碰撞。为什么这么说呢？不妨思考一下，在n - 1为15(0x1111)时，其实散列真正生效的只是低4bit的有效位，当然容易碰撞了。\n因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高16bit和低16bit异或了一下。设计者还解释到因为现在大多数的 hashCode 的分布已经很不错了，就算是发生了碰撞也用O(logn)的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。\n如果还是产生了频繁的碰撞，会发生什么问题呢？作者注释说，他们使用树来处理频繁的碰撞(we use trees to handle large sets of collisions in bins)，在JEP-180中，描述了这个问题：\n Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class.\n 之前已经提过，在获取HashMap的元素时，基本分两步：\n 首先根据 hashCode() 做 hash ，然后确定 bucket 的 index ； 如果 bucket 的节点的 key 不是我们需要的，则通过 keys.equals() 在链中找。  在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行 get 时，两步的时间复杂度是   \\(O(1)+O(n)\\)  。因此，当碰撞很厉害的时候n很大， \\(O(n)\\)  的速度显然是影响速度的。因此在Java 8中，如果一个 bucket 中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，这样复杂度就变成了 \\(O(1)+O(logn)\\)  了，这样在 n 很大的时候，能够比较理想的解决这个问题。\nResize 当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。resize的注释是这样描述的：\n Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table.\n 大致意思就是说，当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。例如我们从16扩展为32时，具体的变化如下所示：\n因此元素在重新计算 hash 之后，因为n变为2倍，那么 n-1 的 mask 范围在高位多1bit(红色)，因此新的index就会发生这样的变化：\n因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。可以看看下图为16扩充为32的resize示意图：\n这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。\n并发问题 疫苗：JAVA HASHMAP的死循环\n在 HashMap 并发进行 Resize 的过程中会出现环形链表，导致 get() 操作死循环。\n"});index.add({'id':39,'href':'/interview/docs/basic/net/http/','title':"HTTP",'content':"HTTP  HTTP构建于TCP/IP协议之上，默认端口号是80。 HTTP是 无连接无状态 的。  无连接的含义是 限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。后来使用了Keep-Alive技术。\n无状态是指 协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。\nHTTP 协议这种特性有优点也有缺点，优点在于解放了服务器，每一次请求“点到为止”不会造成不必要连接占用，缺点在于每次请求会传输大量重复的内容信息。\n为了解决HTTP无状态的缺点，两种用于保持 HTTP 连接状态的技术就应运而生了，一个是 Cookie，而另一个则是 Session。Cookie在客户端记录状态，比如登录状态。Session在服务器记录状态。\nHttp的报文结构 HTTP 请求报文头部  User-Agent：产生请求的浏览器类型。 Accept：客户端可识别的响应内容类型列表; Accept-Language：客户端可接受的自然语言; Accept-Encoding：客户端可接受的编码压缩格式; Accept-Charset：可接受的应答的字符集; Host：请求的主机名，允许多个域名同处一个IP 地址，即虚拟主机;（必选） Connection：连接方式(close 或 keep-alive); Cookie：存储于客户端扩展字段，向同一域名的服务端发送属于该域的cookie; 请求包体：在POST方法中使用。 Referer：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。 If-Modified-Since：文档的最后改动时间  HTTP 响应头  Allow\t服务器支持哪些请求方法（如GET、POST等）。 Content-Encoding\t文档的编码（Encode）方法。 Content-Length\t表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。 Content-Type\t表示后面的文档属于什么MIME类型。 Date\t当前的GMT时间。你可以用setDateHeader来设置这个头以避免转换时间格式的麻烦。 Expires\t应该在什么时候认为文档已经过期，从而不再缓存它。 Last-Modified\t文档的最后改动时间。 Refresh\t表示浏览器应该在多少时间之后刷新文档，以秒计。 Server\t服务器名字。 Set-Cookie\t设置和页面关联的Cookie。 ETag：被请求变量的实体值。ETag是一个可以与Web资源关联的记号（MD5值）。 Cache-Control：这个字段用于指定所有缓存机制在整个请求/响应链中必须服从的指令。   max-age：表示当访问此网页后的 x 秒内再次访问不会去服务器；no-cache，实际上Cache-Control: no-cache是会被缓存的，只不过每次在向客户端（浏览器）提供响应数据时，缓存都要向服务器评估缓存响应的有效性；no-store，这个才是响应不被缓存的意思；\n  Last-Modified与If-Modified-Since都是用来记录页面的最后修改时间。当客户端访问页面时，服务器会将页面最后修改时间通过 Last-Modified 标识由服务器发往客户端，客户端记录修改时间，再次请求本地存在的cache页面时，客户端会通过 If-Modified-Since 头将先前服务器端发过来的最后修改时间戳发送回去，服务器端通过这个时间戳判断客户端的页面是否是最新的，如果不是最新的，则返回新的内容，如果是最新的，则返回 304。\n Http的状态码含义。  1**\t信息，服务器收到请求，需要请求者继续执行操作 2**\t成功，操作被成功接收并处理 3**\t重定向，需要进一步的操作以完成请求  301 Moved Permanently。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Moved Temporarily。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 304 Not Modified。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源。   4**\t客户端错误，请求包含语法错误或无法完成请求  400 Bad Request 由于客户端请求有语法错误，不能被服务器所理解。 401 Unauthorized 请求未经授权。这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden 服务器收到请求，但是拒绝提供服务。服务器通常会在响应正文中给出不提供服务的原因 404 Not Found 请求的资源不存在，例如，输入了错误的URL   5**\t服务器错误，服务器在处理请求的过程中发生了错误  500 Internal Server Error 服务器发生不可预期的错误，导致无法完成客户端的请求。 503 Service Unavailable 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。    Http request的几种类型。  GET\t请求指定的页面信息，并返回实体主体。 POST\t向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 PUT\t从客户端向服务器传送的数据取代指定的文档的内容。 DELETE\t请求服务器删除指定的页面。   GET可提交的数据量受到URL长度的限制，HTTP协议规范没有对URL长度进行限制。这个限制是特定的浏览器及服务器对它的限制\n  理论上讲，POST是没有大小限制的，HTTP协议规范也没有进行大小限制，出于安全考虑，服务器软件在实现时会做一定限制\n 条件 GET HTTP条件GET 是 HTTP 协议为了减少不必要的带宽浪费，提出的一种方案。实际上就是利用If-Modified-Since做浏览器缓存。\n持久连接 我们知道 HTTP 协议采用请求-应答模式，当使用普通模式，即非 Keep-Alive 模式时，每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接（HTTP协议为无连接的协议）；当使用 Keep-Alive 模式（又称持久连接、连接重用）时，Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接。\n在 HTTP 1.0 中, 没有官方的 keep alive 的操作。通常是在现有协议上添加一个指数。如果浏览器支持 keep-alive，它会在请求的包头中添加：\nConnection: Keep-Alive 然后当服务器收到请求，作出回应的时候，它也添加一个头在响应中：\nConnection: Keep-Alive 这样做，连接就不会中断（超过 Keep-Alive 规定的时间\u0026ndash;服务器设置，意外断电等情况除外），而是保持连接。当客户端发送另一个请求时，它会使用同一个连接。这一直继续到客户端或服务器端认为会话已经结束，其中一方中断连接。\n在 HTTP 1.1 版本中，默认情况下所有连接都被保持，如果加入 \u0026ldquo;Connection: close\u0026rdquo; 才关闭。\n HTTP Keep-Alive 简单说就是保持当前的TCP连接，避免了重新建立连接。\n  HTTP 长连接不可能一直保持，例如 Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开。\n  HTTP是一个无状态协议，这意味着每个请求都是独立的，Keep-Alive没能改变这个结果。另外，Keep-Alive也不能保证客户端和服务器之间的连接一定是活跃的，在HTTP1.1版本中也如此。唯一能保证的就是当连接被关闭时你能得到一个通知，所以不应该让程序依赖于Keep-Alive的保持连接特性，否则会有意想不到的后果。\n  使用长连接之后，客户端、服务端怎么知道本次传输结束呢？两部分：1. 判断传输数据是否达到了Content-Length 指示的大小；2. 动态生成的文件没有 Content-Length ，它是分块传输（chunked），这时候就要根据 chunked 编码来判断，chunked 编码的数据在最后有一个空 chunked 块，表明本次传输数据结束。\n 跨站攻击 CSRF（Cross-site request forgery，跨站请求伪造）伪造请求，冒充用户在站内的正常操作，比如爬虫。\n防范的方法  关键操作只接受POST请求 验证码 检测 Referer Token  Token 要足够随机——只有这样才算不可预测 Token 是一次性的，即每次请求成功后要更新Token——这样可以增加攻击难度，增加预测难度 Token 要注意保密性——敏感操作使用 post，防止 Token 出现在 URL 中    断点续传 要实现断点续传的功能，通常都需要客户端记录下当前的下载进度，并在需要续传的时候通知服务端本次需要下载的内容片段。\nHTTP1.1协议中定义了断点续传相关的HTTP头 Range 和 Content-Range 字段，一个最简单的断点续传实现大概如下：\n 客户端下载一个1024K的文件，已经下载了其中512K 网络中断，客户端请求续传，因此需要在HTTP头中申明本次需要续传的片段：Range:bytes=512000-，这个头通知服务端从文件的512K位置开始传输文件。 服务端收到断点续传请求，从文件的512K位置开始传输，并且在HTTP头中增加：Content-Range:bytes 512000-/1024000，并且此时服务端返回的HTTP状态码应该是206，而不是200。  但是在实际场景中，会出现一种情况，即在终端发起续传请求时，URL对应的文件内容在服务端已经发生变化，此时续传的数据肯定是错误的。如何解决这个问题了？显然此时我们需要有一个标识文件唯一性的方法。在RFC2616中也有相应的定义，比如 实现Last-Modified来标识文件的最后修改时间，这样即可判断出续传文件时是否已经发生过改动。同时RFC2616中还定义有一个ETag的头，可以使用ETag头来放置文件的唯一标识，比如文件的MD5值。\n客户端在发起续传请求时应该在HTTP头中申明If-Match 或者 If-Modified-Since 字段，帮助服务端判别文件变化。\n一次HTTP请求  域名解析 1. 浏览器缓存 2. 系统缓存 3. hosts 4. ISP DNS 缓存 5. DNS 服务器搜索 浏览器发送 HTTP 请求到目标服务器 服务器永久重定向 浏览器跟踪重定向地址 服务器“处理”请求 服务器发回一个HTML响应 浏览器开始显示HTML 浏览器请求获取嵌入在 HTML 中的对象（图片\u0026amp;脚本等） 浏览器发送异步（AJAX）请求  "});index.add({'id':40,'href':'/interview/docs/basic/net/https/','title':"HTTPS",'content':"HTTPS HTTPS 是一种通过计算机网络进行安全通信的传输协议。HTTPS经由HTTP进行通信，但利用 SSL/TLS 来加密数据包。 HTTPS 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。\nHTTPS 的主要思想是在不安全的网络上创建一安全信道，并可在使用适当的加密包和服务器证书可被验证且可被信任时，对窃听和中间人攻击提供合理的防护。HTTPS的信任继承基于预先安装在浏览器中的证书颁发机构（如Symantec、Comodo、GoDaddy和GlobalSign等）（意即“我信任证书颁发机构告诉我应该信任的”）\nHTTP 为什么不安全 http 协议属于 明文传输协议 ，交互过程以及数据传输都没有进行加密，通信双方也没有进行任何认证，通信过程非常容易遭遇劫持、监听、篡改，严重情况下，会造成恶意的流量劫持等问题，甚至造成个人隐私泄露（比如银行卡卡号和密码泄露）等严重的安全问题。\n比如常见的，在 http 通信过程中，“中间人”将广告链接嵌入到服务器发给用户的 http 报文里，导致用户界面出现很多不良链接； 或者是修改用户的请求头 URL ，导致用户的请求被劫持到另外一个网站，用户的请求永远到不了真正的服务器。这些都会导致用户得不到正确的服务，甚至是损失惨重。\nHTTPS 如何保证安全 数字证书 TLS 握手的作用之一是 身份认证（authentication） ，被验证的一方需要提供一个身份证明，在 HTTPS 的世界里，这个身份证明就是 TLS 证书 ，或者称为 HTTPS 证书。\n世界上的 CA 机构会遵守 X.509 规范来签发公钥证书（Public Key Certificate），证书内容的语法格式遵守 ASN.1，证书大致包含如下内容：\nCertificate: Data: Version: 3 (0x2) //版本号 Serial Number: //证书序列号 0e:3c:c1:49:94:b3:e1:74:a6:34:54:d9:90:64:66:d7 Signature Algorithm: sha256WithRSAEncryption //签名算法 Issuer: C=US, O=DigiCert Inc, OU=www.digicert.com, CN=GeoTrust RSA CA 2018 //签发机构 Validity //有效期 Not Before: Dec 25 00:00:00 2017 GMT Not After : Dec 24 12:00:00 2020 GMT Subject: C=CN, L=北京市, O=智者四海（北京）技术有限公司, OU=IT, CN=*.zhihu.com //证书主体 Subject Public Key Info: Public Key Algorithm: rsaEncryption //公钥算法 Public-Key: (2048 bit) Modulus: 00:a0:a8:71:... //公钥 Exponent: 65537 (0x10001) X509v3 extensions: //扩展信息 X509v3 Authority Key Identifier: keyid:90:58:FF:B0:9C:75:A8:51:54:77:B1:ED:F2:A3:43:16:38:9E:6C:C5 //授权密钥标识 X509v3 Subject Key Identifier: 31:63:1F:A1:0B:43:D7:A5:8C:3D:F6:2E:85:69:D4:E1:E3:56:91:46 //主体密钥标识 X509v3 Subject Alternative Name: DNS:*.zhihu.com, DNS:zhihu.com X509v3 Key Usage: critical Digital Signature, Key Encipherment X509v3 Extended Key Usage: TLS Web Server Authentication, TLS Web Client Authentication X509v3 CRL Distribution Points: Full Name: URI:http://cdp.geotrust.com/GeoTrustRSACA2018.crl X509v3 Certificate Policies: Policy: 2.16.840.1.114412.1.1 CPS: https://www.digicert.com/CPS Policy: 2.23.140.1.2.2 Authority Information Access: OCSP - URI:http://status.geotrust.com CA Issuers - URI:http://cacerts.geotrust.com/GeoTrustRSACA2018.crt X509v3 Basic Constraints: CA:FALSE Signature Algorithm: sha256WithRSAEncryption //签名算法 54:73:e6:02:... //数字签名 同一个CA颁发的证书序列号都必须是唯一的。\n证书链 证书链是从终端用户证书后跟着一系列的 CA 证书，例如：CA_ZHIHU -\u0026gt; CA_GEO -\u0026gt; CA_ROOT，而通常 最后一个是自签名证书（根证书），并且有如下关系：\n A -\u0026gt; B 表示 \u0026ldquo;A是由B签发的\u0026rdquo; （更确切地说，A是由B中所载公钥对应的私钥签署的）\n  在证书链上除根证书外，证书颁发者等于其后一个证书的主题。即：CA_ZHIHU.Authority Key Identifier=CA_GEO.Subject Key Identifier 除了最后一个证书，每个证书都是由其后的一个证书签名的。即：CA_ZHIHU 由 CA_GEO 签名，CA_GEO 由 CA_ROOT 签名 最后的证书是信任主题，由于是通过可信过程得到的，你可以信任它，一般为系统内置。  证书链用于检查目标证书（证书链里的第一个证书）里的公钥及其它数据是否属于其主题。检查是这么做的，用证书链中的下一个证书的公钥来验证它的签名，一直检查到证书链的尾端，如果所有验证都成功通过，那个这个证书就是可信的。\n证书认证 数字签名其实就是把 散列值 经过非对称加密算法加密得到的一个 加密的散列值 。数字签名一般用于身份认证和防止抵赖。\n根认证机构的构建  根认证机构 CA 生成公钥 ca_KeyPub 和私钥 ca_KeyPri ，以及基本信息表 ca_Info （CSR）。ca_Info 中一般包含了 CA 的名称、证书的有效期等信息。 根认证机构 CA 对 ca_KeyPub + ca_Info 进行散列运算，得到散列值 ca_Hash 。 根认证机构 CA 使用其私钥 ca_KeyPri 对 ca_Hash 进行非对称加密，得到加密的散列值 enc_ca_Hash 。 根认证机构 CA 将 ca_KeyPub + ca_Info + enc_ca_Hash 组合生成自签名的数字证书 ca_Cert 。这张证书称之为根证书。  ca_Cert 可用于签署下一级的证书。\n二级（或以上）认证机构的构建  二级认证机构 CA2 生成公钥 ca2_KeyPub 和私钥 ca2_KeyPri ，以及基本信息表 ca2_Info 。 ca2_Info 中一般包含了 CA2 的名称、证书要求的有效期等信息。 二级认证机构 CA2 将 ca2_KeyPub 、ca2_Info 送给根认证机构 CA 。 根认证机构 CA 通过某种方式验证 CA2 的身份之后，再加上根认证机构自己的一些信息 ca_Info ，然后对它们 ca2_KeyPub + ca2_Info + ca_Info 进行散列运算，得到散列值 ca2_Hash 。 根认证机构 CA 使用其私钥 ca_KeyPri 对 ca2_Hash 进行非对称加密，得到加密的散列值 enc_ca2_Hash 。 根认证机构 CA 将 ca2_KeyPub + ca2_Info + ca_Info + enc_ca2_Hash 组合签署成数字证书 ca2_Cert 并回送给 CA2 。  ca2_Cert 可用于签署下一级的证书。\n二级（或以上）认证机构的证书签署  服务器 S2 生成公钥 s2_KeyPub 和私钥 s2_KeyPri ，以及基本信息表 s2_Info 。 s2_Info 中一般包含了 S2 的名称、证书要求的有效期等信息。 服务器 S2 将 s2_KeyPub 、 s2_Info 送给二级认证机构 CA2。 二级认证机构 CA2 通过某种方式验证 S2 的身份之后，再加上根认证机构自己的一些信息 ca2_Info ，然后对它们 s2_KeyPub + s2_Info + ca2_Info 进行散列运算，得到散列值 s2_Hash 。 二级认证机构 CA2 使用其私钥 ca2_KeyPri 对 s2_Hash 进行非对称加密，得到加密的散列值 enc_s2_Hash 。 二级认证机构 CA2 将 s2_KeyPub + s2_Info + ca2_Info + enc_s2_Hash 组合签署成数字证书 s2_Cert 并回送给 S2 。  s2_Cert 不可用于签署下一级的证书。\n openssl ca 的 -extensions 参数控制，生成 s2_Cert 时是使用参数 server_cert 生成，所以不具备签署的能力\n 从上面可以看出，证书签署的流程是： ca_Cert -\u0026gt; ca2_Cert -\u0026gt; s2_Cert 。它是一条完整的链条，我们把它称之为 证书链 。\n二级（或以上）认证机构的验证  服务器 S2 下发证书 s2_Cert 、 ca2_Cert （证书链）给客户端 C 。 客户端 C 检查到 s2_Cert 中的 ca2_Info ，发现它是由 CA2 签署的。 客户端 C 取出 ca2_Cert 中的 ca2_KeyPub ，对 s2_Cert 中的 enc_s2_Hash 进行解密得到 s2_Hash 。 客户端 C 对 s2_Cert 中的 s2_KeyPub + s2_Info + ca2_Info 进行散列运算，得到散列值 s2_Hash_tmp。 客户端 C 判断 s2_Hash 和 s2_Hash_tmp 是否相等。如果两者相等，则证明 s2_Cert 是由 ca2_Cert 签署的。 客户端 C 检查到 ca2_Cert 中的 ca_Info ，发现它是由 CA 签署的。 客户端 C 取出 ca_Cert 中的 ca_KeyPub ，对 ca2_Cert 中的 enc_ca2_Hash 进行解密得到 ca2_Hash 。 客户端 C 对 ca2_Cert 中的 ca2_KeyPub + ca2_Info + ca_Info 进行散列运算，得到散列值 ca2_Hash_tmp 。 客户端 C 判断 ca2_Hash 和 ca2_Hash_tmp 是否相等。如果两者相等，证明 ca2_Cert 是由 ca_Cert 签署的。 客户端 C 检查 ca_Cert ，发现该证书是根证书，且已经被系统信任，身份验证通过。  无 SNI 支持问题 很多公司由于业务众多，域名也是相当多的，为了方便运维，会让很多域名指向同样的 ip，然后统一将流量/请求分发到后端，此时就会面临一个问题：由于 TLS/SSL 在 HTTP 层之下，客户端和服务器握手的时候还拿不到 origin 字段，所以服务器不知道这个请求是从哪个域名过来的，而服务器这边每个域名都对应着一个证书，服务器就不知道该返回哪个证书啦。这个问题有两个通用解决方案：\n 使用 VIP 服务器，每个域名对应一个 VIP，然后 VIP 与统一接入服务对接，通过 ip 来分发证书，不过运维成本很高，可能也需要大量的 VIP 服务器 采用 多泛域名，将多个泛域名证书打包进一个证书。它的缺点是每次添加域名都需要更新证书。  证书选择 证书有多张加密方式，不同的加密方式对 CPU 计算的损耗不同，安全级别也不同。TLS 在进行第一次握手的时候，客户端会向服务器端 say hello，这个时候会告诉服务器，它支持哪些算法，此时 服务器可以将最适合的证书发给客户端。\n证书的吊销 CA 证书的吊销存在两种机制，一种是 在线检查（OCSP），客户端向 CA 机构发送请求检查公钥的靠谱性；第二种是客户端储存一份 CA 提供的 证书吊销列表（CRL），定期更新。前者要求查询服务器具备良好性能，后者要求每次更新提供下次更新的时间，一般时差在几天。安全性要求高的网站建议采用第一种方案。\n大部分 CA 并不会提供吊销机制（CRL/OCSP），靠谱的方案是 为根证书提供中间证书，一旦中间证书的私钥泄漏或者证书过期，可以直接吊销中间证书并给用户颁发新的证书。中间证书还可以产生下一级中间证书，多级证书可以减少根证书的管理负担。\nSSL/TLS协议 不使用SSL/TLS的HTTP通信，就是不加密的通信。所有信息明文传播，带来了三大风险。\n 窃听风险（eavesdropping）：第三方可以获知通信内容。 篡改风险（tampering）：第三方可以修改通信内容。 冒充风险（pretending）：第三方可以冒充他人身份参与通信。  SSL/TLS协议是为了解决这三大风险而设计的，希望达到：\n 所有信息都是加密传播，第三方无法窃听。 具有校验机制，一旦被篡改，通信双方会立刻发现。 配备身份证书，防止身份被冒充。  目前，应用最广泛的是 TLS 1.0，接下来是SSL 3.0。但是，主流浏览器都已经实现了 TLS 1.2 的支持。TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3。\nTLS 运行过程 SSL/TLS协议的基本思路是采用 公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。因此，SSL/TLS协议的基本过程是这样的：\n 客户端向服务器端索要并验证公钥。 双方协商生成\u0026quot;对话密钥\u0026rdquo;。 双方采用\u0026quot;对话密钥\u0026quot;进行加密通信。  \u0026ldquo;握手阶段\u0026quot;涉及四次通信，我们一个个来看。需要注意的是，\u0026ldquo;握手阶段\u0026quot;的所有通信都是明文的。\n客户端发出请求（ClientHello） 首先，客户端（通常是浏览器）先向服务器发出加密通信的请求，这被叫做 ClientHello 请求。\n在这一步，客户端主要向服务器提供以下信息。\n 支持的协议版本，比如TLS 1.0版。 一个客户端生成的随机数，稍后用于生成对话密钥。 支持的加密方法，比如RSA公钥加密。 支持的压缩方法。  这里需要注意的是，客户端发送的信息之中不包括服务器的域名。也就是说，理论上服务器只能包含一个网站，否则会分不清应该向客户端提供哪一个网站的数字证书。这就是为什么通常一台服务器只能有一张数字证书的原因。\n对于虚拟主机的用户来说，这当然很不方便。2006年，TLS协议加入了一个 Server Name Indication 扩展，允许客户端向服务器提供它所请求的域名。\n服务器回应（SeverHello） 服务器收到客户端请求后，向客户端发出回应，这叫做 SeverHello 。服务器的回应包含以下内容。\n 确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的随机数，稍后用于生成对话密钥。 确认使用的加密方法，比如 RSA 公钥加密。 服务器证书。  除了上面这些信息，如果服务器需要确认客户端的身份，就会再包含一项请求，要求客户端提供 \u0026ldquo;客户端证书\u0026rdquo;。比如，金融机构往往只允许认证客户连入自己的网络，就会向正式客户提供 USB 密钥，里面就包含了一张客户端证书。\n客户端回应 客户端收到服务器回应以后，首先验证服务器证书。如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。\n如果证书没有问题，客户端就会从证书中取出服务器的公钥。然后，向服务器发送加密信息，包含下面三项信息。\n 一个随机数。该随机数用服务器公钥加密，防止被窃听。 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。  上面第一项的随机数，是整个握手阶段出现的第三个随机数，又称 pre-master key 。有了它以后，客户端和服务器就同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的同一把\u0026quot;会话密钥\u0026rdquo;。\n至于 为什么一定要用三个随机数，来生成\u0026quot;会话密钥\u0026rdquo;：\n 不管是客户端还是服务器，都需要随机数，这样生成的密钥才不会每次都一样。由于SSL协议中证书是静态的，因此十分有必要引入一种随机因素来保证协商出来的密钥的随机性。\n对于 RSA 密钥交换算法来说，pre-master-key本身就是一个随机数，再加上 hello 消息中的随机，三个随机数通过一个密钥导出器最终导出一个对称密钥。\npre master 的存在在于 SSL 协议不信任每个主机都能产生完全随机的随机数，如果随机数不随机，那么 pre master secret（对称密钥） 就有可能被猜出来，那么仅适用 pre master secret 作为密钥就不合适了，因此必须引入新的随机因素，那么客户端和服务器三个随机数一同生成的密钥就不容易被猜出了，一个伪随机可能完全不随机，可是是三个伪随机就十分接近随机了，每增加一个自由度，随机性增加的可不是一个量级。\n 此外，如果前一步，服务器要求客户端证书，客户端会在这一步发送证书及相关信息。\n服务器的最后回应 服务器收到客户端的第三个随机数 pre-master key 之后，计算生成本次会话所用的\u0026quot;会话密钥\u0026rdquo;。然后，向客户端最后发送下面信息。\n 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供客户端校验。  至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过用\u0026quot;会话密钥\u0026quot;加密内容。\nHTTPS 的七个误解  HTTPS无法缓存？：许多人以为，出于安全考虑，浏览器不会在本地保存HTTPS缓存。实际上，只要在HTTP头中使用特定命令，HTTPS是可以缓存的。 SSL证书很贵？：如果你在网上搜一下，就会发现很多便宜的SSL证书，大概10美元一年，这和一个 .com 域名的年费差不多。而且事实上，还能找到免费的 SSL 证书。 HTTPS站点必须有独享的IP地址？使用子域名通配符SSL证书（wildcard SSL certificate，价格大约是每年125美元），就能在一个IP地址上部署多个HTTPS子域名。 转移服务器时要购买新证书？ HTTPS太慢？：使用HTTPS不会使你的网站变得更快（实际上有可能，请看下文），但是有一些技巧可以大大减少额外开销。 有了HTTPS，Cookie和查询字符串就安全了？：虽然无法直接从HTTPS数据中读取Cookie和查询字符串，但是你仍然需要使它们的值变得难以预测。 只有注册登录页，才需要HTTPS？：这种想法很普遍。人们觉得，HTTPS可以保护用户的密码，此外就不需要了。Firefox浏览器新插件Firesheep，证明了这种想法是错的。我们可以看到，在Twitter和Facebook上，劫持其他人的session是非常容易的。  中间人攻击（MITM） TLS对中间人攻击的抵御 当然正常情况下，我们的网络安全肯定不会这么脆弱。得利于TLS证书体系，虽然我们能发起中间人攻击，不过浏览器察觉到了证书的异常。这是因为我们冒充了目标网站，但是并没有目标网站的证书，这样浏览器在校验证书时很容易发现证书错误。\n无法抵御中间人攻击的实例 部分开发者忽视证书校验，或对证书异常处理不当，导致本来十分有效LTS失去原本的防御能力。有许多APP存在类似的问题，包括个别金融类应用，还有部分APP部分模块的流量存在被劫持的风险。\n参考链接  HTTPS 精读之 TLS 证书校验 细说 CA 和证书 HTTPS中间人攻击实践（原理·实践）  "});index.add({'id':41,'href':'/interview/docs/basic/os/io/','title':"I/O",'content':"I/O 基本概念 文件描述符fd 文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。\n文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于 UNIX、Linux 这样的操作系统。\n缓存 I/O 缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。\n缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。\nIO模式 刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：\n 等待数据准备 将数据从内核拷贝到进程中  正式因为这两个阶段，Linux系统产生了下面五种网络模式的方案。\n 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO）   由于signal driven IO在实际中并不常用，所以这里只提及剩下的四种 IO Model。\n 阻塞IO 在 Linux 中，默认情况下所有的 socket 都是 blocking ，一个典型的读操作流程大概是这样：\n当用户进程调用了 recvfrom 这个系统调用， kernel 就开始了 IO 的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的 UDP 包。这个时候 kernel 就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当 kernel 一直等到数据准备好了，它就会将数据从 kernel 中拷贝到用户内存，然后 kernel 返回结果，用户进程才解除 block 的状态，重新运行起来。\n blocking IO的特点就是在IO执行的两个阶段都被block了\n 非阻塞 I/O Linux 下，可以通过设置 socket 使其变为 non-blocking 。当对一个 non-blocking socket 执行读操作时，流程是这个样子：\n当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error 。从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call ，那么它马上就将数据拷贝到了用户内存，然后返回。\n nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有\n IO多路复用 IO多路复用就是我们说的 select，poll，epoll ，有些地方也称这种IO方式为 event driven IO 。select/epoll 的好处就在于单个 process 就可以同时处理多个网络连接的 IO 。它的基本原理就是 select，poll，epoll 这个 function 会不断的轮询所负责的所有 socket ，当某个 socket 有数据到达了，就通知用户进程。\n当用户进程调用了 select，那么整个进程会被 block，而同时， kernel 会监视所有 select 负责的 socket ，当任何一个 socket 中的数据准备好了， select 就会返回。这个时候用户进程再调用 read 操作，将数据从 kernel 拷贝到用户进程。\n I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select() 函数就可以返回。\n 这个图和 blocking IO 的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个 system call (select 和 recvfrom)，而 blocking IO 只调用了一个 system call (recvfrom)。但是，用 select 的优势在于它可以同时处理多个 connection 。\n所以，如果处理的连接数不是很高的话，使用 select/epoll 的 web server 不一定比使用 multi-threading + blocking IO 的 web server 性能更好，可能延迟还更大。select/epoll 的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。\n在IO多路复用实际使用中，对于每一个socket，一般都设置成为 non-blocking ，但是，如上图所示，整个用户的 process 其实是一直被block的。只不过 process 是被 select 这个函数 block ，而不是被 socket IO 给 block 。\n基本概念 在 I/O 编程过程中,当需要同时处理多个客户端接入请求时，可以利用多线程或者 I/O 多路复用 技术进行处理。I/O多路复用 技术通过把多个I/O的阻塞复用到同一个selct的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。与传统的 多线程/多进程 模型比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源，I/O多路复用的主要应用场景如下。\n 服务器需要同时处理多个处于监听状态或者多个连接状态的套接字 服务器需要同时处理多种网络协议的套接字  目前支持I/O多路复用的系统调用有 select、pselect、poll、epoll，在Linux网络编程; 过程中，很长一段时间都使用 select 做轮询和网络事件通知，然而 select 的一些固有缺陷导致了它的应用受到了很大的限制。最终 Linux 不得不在新的内核版本中寻找 select 的替代方案，最终选择了 epoll。 epoll 与 select 的原理比较类似，为了克服 select 的缺点， epoll 作了很多重大改进，现总结如下。\n支持一个进程打开的 socket 描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数）。 select 最大的缺陷就是单个进程所打开的 FD 是有一定限制的，它由 FD_SETSIZE 设置，默认值是 1024 。对于那些需要支持上万个 TCP 连接的大型服务器来说显然太少了。可以选择修改这个宏然后重新编译内核，不过这会带来网络效率的下降。我们也可以通过选择多进程的方案（传统的 Apache 方案）解决这个问题，不过虽然在 Linux上创建进程的代价比较小，但仍旧是不可忽视的，另外，进程间的数据交换非常麻烦，对于 Java 由于没有共享内存，需要通过 Socket 通信或者其他方式进行数据同步，这带来了额外的性能损耗，增加了程序复杂度，所以也不是一种完美的解决方案。值得庆幸的是， epoll 并没有这个限制，它所支持的 FD 上限是操作系统的 最大文件句柄数，这个数字远远大于 1024 。例如，在 1 GB 内存的机器上大约是 10万个句柄左右，具体的值可以通过cat /proc/sys/fs/file- max 察看，通常情况下这个值跟系统的内存关系比较大。\nI/O效率不会随着FD数目的增加而线性下降。 传统的 select/poll 另-个致命弱点就是当你拥有一个很大的 socket 集合，由于网络延时或者链路空闲，任一时刻只有少部分的 socket 是“活跃”的，但是 select/poll 每次调用都会线性扫描全部的集合，导致效率呈现线性下降。 epoll 不存在这个问题，它只会对“活跃”的 socket 进行操作，这是因为在内核实现中 epoll 是根据每个 fd 上面的 callback 函数实现的，那么，只有“活跃”的 socket 才会主动的去调用 callback 函数，其他 idle 状态 socket 则不会。在这点上， epoll 实现了一个伪 AIO。针对 epoll 和 select 性能对比的 benchmark 测试表明：如果所有的 socket 都处于活跃态，例如一个高速 LAN 环境， epoll 并不比 select/poll 效率高太多；相反，如果过多使用 epoll_ ctl , 效率相比还有稍微的下降。但是一旦使用 idleconnections 模拟 WAN 环境，epoll 的效率就远在 select/poll 之上了。\n使用 mmap 加速内核与用户空间的消息传递 无论是 select，poll 还是 epoll 都需要内核把 FD 消息通知给用户空间，如何避免不必要的内存复制（Zero Copy）就显得非常重要， epoll 是通过内核和用户空间 mmap 共享同一块内存来实现。\nEpoll 的 API 更加简单 包括创建一个 epoll 描述符、添加监听事件、阻塞等待所监听的事件发生，关闭 epoll 描述符等。\n值得说明的是，用来克服 select/poll 缺点的方法不只有 epoll , epoll 只是一种 Linux 的 实现方案。在 freeBSD 下有 kqueue\nEpoll 边缘触发\u0026amp;水平触发 epoll 对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是 默认模式 ，LT模式与ET模式的区别如下：\n LT模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。 ET模式：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。   ET模式 在很大程度上减少了 epoll 事件被重复触发的次数，因此 效率要比LT模式高。epoll 工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n 异步 I/O 用户进程发起 read 操作之后，立刻就可以开始去做其它的事。而另一方面，从 kernel 的角度，当它受到一个 asynchronous read 之后，首先它会立刻返回，所以不会对用户进程产生任何 block 。然后，kernel 会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel 会给用户进程发送一个 signal ，告诉它 read 操作完成了。\nblocking vs non-blocking 调用 blocking IO 会一直 block 住对应的进程直到操作完成，而 non-blocking IO 在 kernel 还准备数据的情况下会立刻返回。\nsynchronous IO vs asynchronous IO 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。 POSIX 的定义是这样子的：\n A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked;  两者的区别就在于 synchronous IO 做 IO operation 的时候会将 process 阻塞。按照这个定义，之前所述的 blocking IO，non-blocking IO，IO multiplexing 都属于 synchronous IO。\n有人会说，non-blocking IO 并没有被 block 啊。这里有个非常 狡猾 的地方，定义中所指的 IO operation 是指真实的 IO 操作，就是例子中的 recvfrom 这个 system call 。non-blocking IO 在执行 recvfrom 这个 system call 的时候，如果 kernel 的数据没有准备好，这时候不会 block 进程。但是，当 kernel 中数据准备好的时候，recvfrom 会将数据从 kernel 拷贝到用户内存中，这个时候进程是被 block 了，在这段时间内，进程是被 block 的。\n而 asynchronous IO 则不一样，当进程发起 IO 操作之后，就直接返回再也不理睬了，直到 kernel 发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被 block 。\n参考  Linux IO模式及 select、poll、epoll详解  "});index.add({'id':42,'href':'/interview/docs/fromwork/spring/ioc/','title':"IOC",'content':"IOC Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想。在Java 开发中，Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。如何理解好Ioc呢？理解好Ioc的关键是要明确“谁控制谁，控制什么，为何是反转（有反转就应该有正转了），哪些方面反转了”，那我们来深入分析一下：\n　- 谁控制谁，控制什么：传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对 象的创建；谁控制谁？当然是IoC 容器控制了对象；控制什么？那就是主要控制了外部资源获取（不只是对象包括比如文件等）。 - 为何是反转，哪些方面反转了：有反转就有正转，传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。\nIoC能做什么 　IoC 不是一种技术，只是一种思想，一个重要的面向对象编程的法则，它能指导我们如何设计出松耦合、更优良的程序。传统应用程序都是由我们在类内部主动创建依赖对象，从而导致类与类之间高耦合，难于测试；有了IoC容器后，把创建和查找依赖对象的控制权交给了容器，由容器进行注入组合对象，所以对象与对象之间是 松散耦合，这样也方便测试，利于功能复用，更重要的是使得程序的整个体系结构变得非常灵活。\nIoC和DI DI—Dependency Injection，即“依赖注入”：组件之间依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。\n理解DI的关键是：“谁依赖谁，为什么需要依赖，谁注入谁，注入了什么”，那我们来深入分析一下：\n 谁依赖于谁：当然是应用程序依赖于IoC容器； 为什么需要依赖：应用程序需要IoC容器来提供对象需要的外部资源； 谁注入谁：很明显是IoC容器注入应用程序某个对象，应用程序依赖的对象； 注入了什么：就是注入某个对象所需要的外部资源（包括对象、资源、常量数据）。  IoC和DI由什么关系呢？其实它们是同一个概念的不同角度描述，由于控制反转概念比较含糊（可能只是理解为容器控制对象这一个层面，很难让人想到谁来维护对象关系），所以2004年大师级人物Martin Fowler又给出了一个新的名字：“依赖注入”，相对IoC 而言，“依赖注入”明确描述了“被注入对象依赖IoC容器配置依赖对象”。\nIOC vs Factory 简单来说，IOC 与 工厂模式 分别代表了 push 与 pull 的机制：\n Pull 机制：类间接依赖于 Factory Method ，而 Factory Method 又依赖于具体类。 Push 机制：容器可以在一个位置配置所有相关组件，从而促进高维护和松耦合。  使用 工厂模式 的责任仍然在于类（尽管间接地）来创建新对象，而 依赖注入 将责任外包。\n循环依赖 Spring 为了解决单例的循环依赖问题，使用了 三级缓存 ，递归调用时发现 Bean 还在创建中即为循环依赖\n/** 一级缓存：用于存放完全初始化好的 bean **/ private final Map\u0026lt;String, Object\u0026gt; singletonObjects = new ConcurrentHashMap\u0026lt;String, Object\u0026gt;(256); /** 二级缓存：存放原始的 bean 对象（尚未填充属性），用于解决循环依赖 */ private final Map\u0026lt;String, Object\u0026gt; earlySingletonObjects = new HashMap\u0026lt;String, Object\u0026gt;(16); /** 三级级缓存：存放 bean 工厂对象，用于解决循环依赖 */ private final Map\u0026lt;String, ObjectFactory\u0026lt;?\u0026gt;\u0026gt; singletonFactories = new HashMap\u0026lt;String, ObjectFactory\u0026lt;?\u0026gt;\u0026gt;(16); /** bean 的获取过程：先从一级获取，失败再从二级、三级里面获取 创建中状态：是指对象已经 new 出来了但是所有的属性均为 null 等待被 init */  A 创建过程中需要 B，于是 A 将自己放到三级缓里面 ，去实例化 B B 实例化的时候发现需要 A，于是 B 先查一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，找到了！  然后把三级缓存里面的这个 A 放到二级缓存里面，并删除三级缓存里面的 A B 顺利初始化完毕，将自己放到一级缓存里面（此时B里面的A依然是创建中状态）   然后回来接着创建 A，此时 B 已经创建结束，直接从一级缓存里面拿到 B ，然后完成创建，并将自己放到一级缓存里面 如此一来便解决了循环依赖的问题  "});index.add({'id':43,'href':'/interview/docs/basic/net/ip/','title':"IP",'content':"IP 地址分类  A类：8位网络号，0_ _ _ _ _ _ _，1.0.0.0 ~ 126.0.0.0 B类：16位网络号，10 _ _ ...，128.0.0.0 ~ 191.255.255.255 C类：24位网络号，110_ _ _...，192.0.0.0 ~ 223.255.255.255 D类：多播地址，1110_ _ _... E类：保留地址，1111_ _ _ ...  私有地址  A类:10.0.0.0 ~ 10.255.255.255(长度相当于1个A类IP地址) B类:172.16.0.0 ~ 172.31.255.255(长度相当于16个连续的B类IP地址) C类:192.168.0.0 ~ 192.168.255.255(长度相当于256个连续的C类IP地址)  特殊的IP地址   0.0.0.0：已经不是一个真正意义上的IP地址。它表示的是这样一个集合：所有不清楚的主机和目的网络。这里的“不清楚”是指在本机的路由表里没有特定条目指明如何到达。如果在网络设置中设置了缺省网关,那么系统会自动产生一个目的地址为0.0.0.0的缺省路由.对本机来说,它就是一个“收容所”,所有不认识的“三无”人员,一 律送进去。\n  255.255.255.255： 限制广播地址，对本机来说,这个地址指本网段内(同一广播域)的所有主机。这个地址不能被路由器转发。\n  127.0.0.1：本机地址主要用于测试。这样一个地址,是不能把它发到网络接口的。\n  "});index.add({'id':44,'href':'/interview/docs/java/proxy/','title':"Java 代理",'content':"代理 Java 代理 我们常说的代理分为静态代理和动态代理。\n 静态代理：代码中显式指定代理 动态代理：类比静态代理，可以发现，代理类不需要实现原接口了，而是实现InvocationHandler。  静态代理 因为需要对一些函数进行二次处理，或是某些函数不让外界知道时，可以使用代理模式，通过访问第三方，间接访问原函数的方式，达到以上目的。\n弊端 如果要想为多个类进行代理，则需要建立多个代理类，维护难度加大。\n仔细想想，为什么静态代理会有这些问题，是因为代理在编译期就已经决定，如果代理发生在运行期，这些问题解决起来就比较简单，所以动态代理的存在就很有必要了。\n动态代理 当动态生成的代理类调用方法时，会触发 invoke 方法，在 invoke 方法中可以对被代理类的方法进行增强。\n// 1. 首先实现一个InvocationHandler，方法调用会被转发到该类的invoke()方法。 class LogInvocationHandler implements InvocationHandler{ ... private Hello hello; public LogInvocationHandler(Hello hello) { this.hello = hello; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { if(\u0026quot;sayHello\u0026quot;.equals(method.getName())) { logger.info(\u0026quot;You said: \u0026quot; + Arrays.toString(args)); } return method.invoke(hello, args); } } // 2. 然后在需要使用Hello的时候，通过JDK动态代理获取Hello的代理对象。 Hello hello = (Hello)Proxy.newProxyInstance( getClass().getClassLoader(), // 1. 类加载器 new Class\u0026lt;?\u0026gt;[] {Hello.class}, // 2. 代理需要实现的接口，可以有多个 new LogInvocationHandler(new HelloImp()));// 3. 方法调用的实际处理者 System.out.println(hello.sayHello(\u0026quot;I love you!\u0026quot;)); 通过动态代理可以很明显的看到它的好处，在使用静态代理时，如果不同接口的某些类想使用代理模式来实现相同的功能，将要实现多个代理类，但在动态代理中，只需要一个代理类就好了。\n除了省去了编写代理类的工作量，动态代理实现了可以在原始类和接口还未知的时候，就确定代理类的代理行为，当代理类与原始类脱离直接联系后，就可以很灵活地重用于不同的应用场景中。\n 继承了Proxy类，实现了代理的接口，由于java不能多继承，这里已经继承了Proxy类了，不能再继承其他的类，所以JDK的动态代理不支持对实现类的代理，只支持接口的代理。 提供了一个使用InvocationHandler作为参数的构造方法。 生成静态代码块来初始化接口中方法的Method对象，以及Object类的equals、hashCode、toString方法  弊端 代理类和委托类需要都实现同一个接口。也就是说只有实现了某个接口的类可以使用Java动态代理机制。但是，事实上使用中并不是遇到的所有类都会给你实现一个接口。因此，对于没有实现接口的类，就不能使用该机制。\n动态代理与静态代理的区别  Proxy类的代码被固定下来，不会因为业务的逐渐庞大而庞大； 代理对象是在程序运行时产生的，而不是编译期； 可以实现AOP编程，这是静态代理无法实现的； 解耦，如果用在web业务下，可以实现数据层和业务层的分离。 动态代理的优势就是实现无侵入式的代码扩展。 静态代理这个模式本身有个大问题，如果类方法数量越来越多的时候，代理类的代码量是十分庞大的。所以引入动态代理来解决此类问题  CGLib cglib 是针对类来实现代理的，他的 原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对 final 修饰的类进行代理。同样的，final 方法是不能重载的，所以也不能通过CGLIB代理，遇到这种情况不会抛异常，而是会跳过 final 方法只代理其他方法。\nCGLIB 代理主要通过对字节码的操作，为对象引入间接级别，以控制对象的访问。 CGLIB 底层使用了ASM（一个短小精悍的字节码操作框架）来操作字节码生成新的类。\nCGLIB和Java动态代理的区别   Java 动态代理只能够对接口进行代理，不能对普通的类进行代理（因为所有生成的代理类的父类为 Proxy，Java 类继承机制不允许多重继承）；CGLIB能够代理普通类；\n  Java 动态代理使用 Java 原生的反射 API 进行操作，在生成类上比较高效；CGLIB 使用 ASM 框架直接对字节码进行操作，在类的执行过程中比较高效\n  "});index.add({'id':45,'href':'/interview/docs/java/jvm/dispatcher/','title':"Java 分派机制",'content':"Java分派机制 在Java中，符合“编译时可知，运行时不可变”这个要求的方法主要是静态方法和私有方法。这两种方法都不能通过继承或别的方法重写，因此它们适合在类加载时进行解析。\nJava虚拟机中有四种方法调用指令：\n invokestatic：调用静态方法。 invokespecial：调用实例构造器方法，私有方法和super。 invokeinterface：调用接口方法。 invokevirtual：调用以上指令不能调用的方法（虚方法）。  只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段确定唯一的调用版本，符合这个条件的有：静态方法、私有方法、实例构造器、父类方法，他们在类加载的时候就会把符号引用解析为改方法的直接引用。这些方法被称为非虚方法，反之其他方法称为虚方法（final方法除外）。\n 虽然final方法是使用invokevirtual 指令来调用的，但是由于它无法被覆盖，多态的选择是唯一的，所以是一种非虚方法。\n 静态分派  对于类字段的访问也是采用静态分派\n People man = new Man()\n静态分派主要针对重载，方法调用时如何选择。在上面的代码中，People被称为变量的引用类型，Man被称为变量的实际类型。静态类型是在编译时可知的，而动态类型是在运行时可知的，编译器不能知道一个变量的实际类型是什么。\n编译器在重载时候通过参数的静态类型而不是实际类型作为判断依据。并且静态类型在编译时是可知的，所以编译器根据重载的参数的静态类型进行方法选择。\n 在某些情况下有多个重载，那编译器如何选择呢？ 编译器会选择\u0026quot;最合适\u0026quot;的函数版本，那么怎么判断\u0026quot;最合适“呢？越接近传入参数的类型，越容易被调用。\n 动态分派 动态分派主要针对重写，使用invokevirtual指令调用。invokevirtual指令多态查找过程：\n 找到操作数栈顶的第一个元素所指向的对象的实际类型，记为C。 如果在类型C中找到与常量中的描述符合简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；如果权限校验不通过，返回java.lang.IllegalAccessError异常。 否则，按照继承关系从下往上一次对C的各个父类进行第2步的搜索和验证过程。 如果始终没有找到合适的方法，则抛出 java.lang.AbstractMethodError异常。  虚拟机动态分派的实现 由于动态分派是非常繁琐的动作，而且动态分派的方法版本选择需要考虑运行时在类的方法元数据中搜索合适的目标方法，因此在虚拟机的实现中基于性能的考虑，在方法区中建立一个虚方法表（invokeinterface 有接口方法表），来提高性能。\n虚方法表中存放各个方法的实际入口地址。如果某个方法在子类没有重写，那么子类的虚方法表里的入口和父类入口一致，如果子类重写了这个方法，那么子类方法表中的地址会被替换为子类实现版本的入口地址。\n"});index.add({'id':46,'href':'/interview/docs/java/exception/','title':"Java 异常",'content':"Java异常 Java中有Error和Exception，它们都是继承自Throwable类。\n二者的不同之处 Exception：\n  可以是可被控制(checked) 或不可控制的(unchecked)。\n  表示一个由程序员导致的错误。\n  应该在应用程序级被处理。\n  Error：\n  总是不可控制的(unchecked)。\n  经常用来用于表示系统错误或低层资源的错误。\n  如何可能的话，应该在系统级被捕捉。\n  异常的分类   Checked exception: 这类异常都是Exception的子类。异常的向上抛出机制进行处理，假如子类可能产生A异常，那么在父类中也必须throws A异常。可能导致的问题：代码效率低，耦合度过高。\n  Unchecked exception: 这类异常都是RuntimeException的子类，虽然RuntimeException同样也是Exception的子类，但是它们是非凡的，它们不能通过client code来试图解决，所以称为Unchecked exception 。\n  "});index.add({'id':47,'href':'/interview/docs/java/generics/','title':"Java 泛型",'content':"Java泛型 开发人员在使用泛型的时候，很容易根据自己的直觉而犯一些错误。比如一个方法如果接收List\u0026lt;Object\u0026gt;作为形式参数，那么如果尝试将一个List\u0026lt;String\u0026gt;的对象作为实际参数传进去，却发现无法通过编译。虽然从直觉上来说，Object是String的父类，这种类型转换应该是合理的。但是实际上这会产生隐含的类型转换问题，因此编译器直接就禁止这样的行为。\n类型擦除 Java中的泛型基本上都是在编译器这个层次来实现的，在生成的Java字节代码中是不包含泛型中的类型信息的。使用泛型的时候加上的类型参数，会被编译器在编译的时候去掉，这个过程就称为类型擦除。如在代码中定义的List\u0026lt;Object\u0026gt;和List\u0026lt;String\u0026gt;等类型，在编译之后都会变成List。JVM看到的只是List，而由泛型附加的类型信息对JVM来说是不可见的。Java编译器会在编译时尽可能的发现可能出错的地方，但是仍然无法避免在运行时刻出现类型转换异常的情况。\n很多泛型的奇怪特性都与这个类型擦除的存在有关，包括：\n  泛型类并没有自己独有的Class类对象。比如并不存在List\u0026lt;String\u0026gt;.class或是List\u0026lt;Integer\u0026gt;.class，而只有List.class。\n  静态变量是被泛型类的所有实例所共享的。对于声明为MyClass\u0026lt;T\u0026gt;的类，访问其中的静态变量的方法仍然是 MyClass.myStaticVar。不管是通过new MyClass\u0026lt;String\u0026gt;还是new MyClass\u0026lt;Integer\u0026gt;创建的对象，都是共享一个静态变量。\n  泛型的类型参数不能用在Java异常处理的catch语句中。因为异常处理是由JVM在运行时刻来进行的。由于类型信息被擦除，JVM是无法区分两个异常类型MyException\u0026lt;String\u0026gt;和MyException\u0026lt;Integer\u0026gt;的。对于JVM来说，它们都是 MyException类型的。也就无法执行与异常对应的catch语句。\n  类型擦除的基本过程也比较简单，首先是找到用来替换类型参数的具体类。这个具体类一般是Object。如果指定了类型参数的上界的话，则使用这个上界。把代码中的类型参数都替换成具体的类。同时去掉出现的类型声明，即去掉\u0026lt;\u0026gt;的内容。比如T get()方法声明就变成了Object get()；List\u0026lt;String\u0026gt;就变成了List。接下来就可能需要生成一些桥接方法（bridge method）。这是由于擦除了类型之后的类可能缺少某些必须的方法。比如考虑下面的代码：\nclass MyString implements Comparable\u0026lt;String\u0026gt; { public int compareTo(String str) { return 0; } } 当类型信息被擦除之后，上述类的声明变成了class MyString implements Comparable。但是这样的话，类MyString就会有编译错误，因为没有实现接口Comparable声明的int compareTo(Object)方法。这个时候就由编译器来动态生成这个方法。\n通配符 在使用泛型类的时候，既可以指定一个具体的类型，如List\u0026lt;String\u0026gt;就声明了具体的类型是String；也可以用通配符?来表示未知类型，如List\u0026lt;?\u0026gt;就声明了List中包含的元素类型是未知的。 通配符所代表的其实是一组类型，但具体的类型是未知的。List\u0026lt;?\u0026gt;所声明的就是所有类型都是可以的。但是List\u0026lt;?\u0026gt;并不等同于List\u0026lt;Object\u0026gt;。List\u0026lt;Object\u0026gt;实际上确定了List中包含的是Object及其子类，在使用的时候都可以通过Object来进行引用。而List\u0026lt;?\u0026gt;则其中所包含的元素类型是不确定。其中可能包含的是String，也可能是 Integer。如果它包含了String的话，往里面添加Integer类型的元素就是错误的。正因为类型未知，就不能通过new ArrayList中的元素确总是可以用Object来引用的，因为虽然类型未知，但肯定是Object及其子类。考虑下面的代码：\npublic void wildcard(List\u0026lt;?\u0026gt; list) { list.add(1);//编译错误 }  如上所示，试图对一个带通配符的泛型类进行操作的时候，总是会出现编译错误。其原因在于通配符所表示的类型是未知的。\n 因为对于List\u0026lt;?\u0026gt;中的元素只能用Object来引用，在有些情况下不是很方便。在这些情况下，可以使用上下界来限制未知类型的范围。 如 List\u0026lt;? extends Number\u0026gt;说明List中可能包含的元素类型是Number及其子类。而List\u0026lt;? super Number\u0026gt;则说明List中包含的是Number及其父类。当引入了上界之后，在使用类型的时候就可以使用上界类中定义的方法。\n类型系统 在Java中，大家比较熟悉的是通过继承机制而产生的类型体系结构。比如String继承自Object。根据Liskov替换原则，子类是可以替换父类的。当需要Object类的引用的时候，如果传入一个String对象是没有任何问题的。但是反过来的话，即用父类的引用替换子类引用的时候，就需要进行强制类型转换。编译器并不能保证运行时刻这种转换一定是合法的。这种自动的子类替换父类的类型转换机制，对于数组也是适用的。 String[]可以替换Object[]。但是泛型的引入，对于这个类型系统产生了一定的影响。正如前面提到的List是不能替换掉List的。\n引入泛型之后的类型系统增加了两个维度：一个是类型参数自身的继承体系结构，另外一个是泛型类或接口自身的继承体系结构。第一个指的是对于 List\u0026lt;String\u0026gt;和List\u0026lt;Object\u0026gt;这样的情况，类型参数String是继承自Object的。而第二种指的是 List接口继承自Collection接口。对于这个类型系统，有如下的一些规则：\n  相同类型参数的泛型类的关系取决于泛型类自身的继承体系结构。即List\u0026lt;String\u0026gt;是Collection\u0026lt;String\u0026gt; 的子类型，List\u0026lt;String\u0026gt;可以替换Collection\u0026lt;String\u0026gt;。这种情况也适用于带有上下界的类型声明。\n  当泛型类的类型声明中使用了通配符的时候，其子类型可以在两个维度上分别展开。如对Collection\u0026lt;? extends Number\u0026gt;来说，其子类型可以在Collection这个维度上展开，即List\u0026lt;? extends Number\u0026gt;和Set\u0026lt;? extends Number\u0026gt;等；也可以在Number这个层次上展开，即Collection\u0026lt;Double\u0026gt;和Collection\u0026lt;Integer\u0026gt;等。如此循环下去，ArrayList\u0026lt;Long\u0026gt;和 HashSet\u0026lt;Double\u0026gt;等也都算是Collection\u0026lt;? extends Number\u0026gt;的子类型。\n  如果泛型类中包含多个类型参数，则对于每个类型参数分别应用上面的规则。\n  "});index.add({'id':48,'href':'/interview/docs/java/concurrent/thread/','title':"Java线程",'content':"Java线程 线程定义 线程（英语：thread）是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。在Unix System V及SunOS中也被称为轻量进程（lightweight processes），但轻量进程更多指内核线程（kernel thread），而把用户线程（user thread）称为线程。\n线程是独立调度和分派的基本单位。线程可以操作系统内核调度的内核线程，如Win32线程；由用户进程自行调度的用户线程，如Linux平台的POSIX Thread；或者由内核与用户进程，如Windows 7的线程，进行混合调度。\n同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈（call stack），自己的寄存器环境（register context），自己的线程本地存储（thread-local storage）。\n线程实现 Java中的线程都是调用的原生系统的本地函数，Java线程模型是基于操作系统原生线程模型实现的，实现线程有三种方式：内核线程实现、用户线程实现、混合线程实现。\n内核线程实现 直接由操作系统内核支持的线程，通过内核来完成进程切换。每个内核线程就是一个内核的分身，这样操作系统就可以同时处理多件事情，支持多线程的内核被称为多线程内核。\n程序一般不直接使用内核线程，而是使用一种高级接口——轻量级进程，轻量级进程就是我们通常意义上的线程，可以获得内核线程的支持，与内核线程构成1:1的线程模型。\n由于得到内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即时有一个轻量级进程在系统调用中阻塞，也不会影响整个进程，但也有其局限性：由于是基于内核线程实现的，各种操作，如创建、销毁及同步，都需要进行系统调用。而系统调用代价较高，需要在内核态和用户态来回切换。\n用户线程实现 从广义上说，一个线程不是内核线程，就是用户线程，所以轻量级进程也属于用户线程。狭义的用户线程是指完全建立在用户空间上的，系统内核不能感知到其存在。\n用户线程的创建、同步、销毁和调度都是在用户空间实现的，因此相对较快，代价相对较低。这种用户线程和进程是N:1的线程模型。\n由于用户线程没有内核的支持，线程的创建、切换和调度是需要自己实现的，而且由于操作系统只把CPU资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何将线程映射到其他处理器”这类问题解决起来异常复杂。\n混合实现 这种实现模式将内核线程与用户线程一起使用，在这种方式下既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间，因此用户线程的创建、切换等操作依旧低廉。而操作系统提供的轻量级进程则作为用户线程和内核线程的桥梁，这样就可以使用内核提供的线程调度及处理器映射。这种实现下，用户线程和轻量级进程是M:N的模式。\nJava线程调度 线程调度分为协同式和抢占式。\n 协同式调度：线程的执行时间由线程自己控制，这种的实现很简单，但是很可能造成很严重的后果。 抢占式调度：由操作系统分配线程执行的时间，线程切换的决定权在操作系统。  有时候我们需要为某些线程多分配时间，这时我们就需要用到线程优先级的方法，Java提供了10种优先级。Java优先级是在操作系统的原生线程优先级上实现的，所以对于同一个优先级，不同的操作系统可能有不同的表现，也就是说 Java线程优先级不是可靠的。\nJava线程状态切换 Java线程模型定义了 6 种状态，在任意一个时间点，一个线程有且只有其中一个状态：\n 新建（New）：新建的Thread，尚未开始。 运行（Runable）：包含操作系统线程状态中的Running、Ready，也就是处于正在执行或正在等待CPU分配时间的状态。 无限期等待（Waiting）：处于这种状态的线程不会被分配CPU时间，等待其他线程唤醒。 限期等待（Timed Waiting）：处于这种状态的线程不会被分配CPU时间，在一定时间后会由系统自动唤醒。 阻塞（Blocked）：在等待获得排他锁。 结束（Terminated）：已终止的线程。  线程安全 多线程访问同一代码，不会产生不确定的结果。\nJava 线程池 "});index.add({'id':49,'href':'/interview/docs/architecture/distributed/kafka/','title':"Kafka",'content':"Kafka 术语  Broker：Kafka 集群包含一个或多个服务器，这种服务器被称为 broker 。 Topic：每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）。 Partition： Partition 是物理上的概念，每个 Topic 包含一个或多个 Partition 。 Producer：负责发布消息到 Kafka broker。 Consumer：消息消费者，向 Kafka broker 读取消息的客户端。 Consumer Group：每个 Consumer 属于一个特定的 Consumer Group（可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group）。  拓扑结构 如上图所示，一个典型的 Kafka 集群中包含若干 Producer （可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干 broker （Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干 Consumer Group ，以及一个 Zookeeper 集群。 Kafka 通过 Zookeeper 管理集群配置，选举 leader ，以及在 Consumer Group 发生变化时进行 rebalance。 Producer 使用 push 模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。\nTopic \u0026amp; Partition Topic 在逻辑上可以被认为是一个 queue ，每条消费都必须指定它的 Topic ，可以简单理解为必须指明把这条消息放进哪个 queue 里。为了使得 Kafka 的吞吐率可以线性提高，物理上把 Topic 分成一个或多个 Partition ，每个 Partition 在物理上对应一个文件夹，该文件夹下存储这个 Partition 的所有消息和索引文件。若创建 topic1 和 topic2 两个 topic ，且分别有 13 个和 19 个分区，则整个集群上会相应会生成共 32 个文件夹（本文所用集群共8个节点，此处 topic1 和 topic2 replication-factor 均为1）。\n Partition 都是通过 顺序读写，所以效率很高\n  replication-factor 配置 partition 副本数。配置副本之后,每个 partition 都有一个唯一的 leader ，有 0 个或多个 follower 。所有的读写操作都在 leader 上完成，followers 从 leader 消费消息来复制 message，就跟普通的 consumer 消费消息一样。一般情况下 partition 的数量大于等于 broker 的数量，并且所有 partition 的 leader 均匀分布在 broker 上。\n 对于传统的 MQ 而言，一般会删除已经被消费的消息，而 Kafka 集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此 Kafka 提供两种策略删除旧数据。一是基于时间，二是基于 Partition 文件大小。\nProducer 消息路由 Producer 发送消息到 broker 时，会根据 Paritition 机制选择将其存储到哪一个 Partition 。如果 Partition 机制设置合理，所有消息可以均匀分布到不同的 Partition 里，这样就实现了负载均衡。如果一个 Topic 对应一个文件，那这个文件所在的机器I/O将会成为这个 Topic 的性能瓶颈，而有了 Partition 后，不同的消息可以并行写入不同 broker 的不同 Partition 里，极大的提高了吞吐率。\n可以在 $KAFKA_HOME/config/server.properties 中通过配置项 num.partitions 来指定新建 Topic 的默认 Partition 数量，也可在创建 Topic 时通过参数指定，同时也可以在 Topic 创建之后通过 Kafka 提供的工具修改。\n 指定了 patition，则直接使用 未指定 patition 但指定 key，通过对 key 进行 hash 选出一个 patition patition 和 key 都未指定，使用轮询选出一个 patition  Consumer Group 这是 Kafka 用来实现一个 Topic 消息的广播（发给所有的 Consumer ）和单播（发给某一个 Consumer ）的手段。一个 Topic 可以对应多个 Consumer Group 。如果需要实现广播，只要每个 Consumer 有一个独立的 Group 就可以了。要实现单播只要所有的 Consumer 在同一个 Group 里。用 Consumer Group 还可以将 Consumer 进行自由的分组而不需要多次发送消息到不同的 Topic 。\nConsumer 个数与 Parition 数有什么关系？ topic 下的一个分区只能被同一个 consumer group 下的一个 consumer 线程来消费，但反之并不成立，即一个 consumer 线程可以消费多个分区的数据。比如 Kafka 提供的 ConsoleConsumer ，默认就只是一个线程来消费所有分区的数据。\n 即分区数决定了同组消费者个数的上限\n 所以，如果你的分区数是 N ，那么最好线程数也保持为 N ，这样通常能够达到最大的吞吐量。超过 N 的配置只是浪费系统资源，因为多出的线程不会被分配到任何分区。\n 如果消费线程大于 patition 数量，则有些线程将收不到消息 如果 patition 数量大于消费线程数，则有些线程多收到多个 patition 的消息 如果一个线程消费多个 patition，则无法保证你收到的消息的顺序，而一个 patition 内的消息是有序的  Push vs. Pull　 作为一个消息系统，Kafka 遵循了传统的方式，选择由 Producer 向 broker push 消息并由 Consumer 从 broker pull 消息。事实上，push 模式和 pull 模式各有优劣。\n Push模式 很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成 Consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。 Pull模式 可以根据Consumer的消费能力以适当的速率消费消息。  对于 Kafka 而言，Pull模式 更合适。Pull模式 可简化 broker 的设计，Consumer 可自主控制消费消息的速率，同时 Consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。\n高可用性 Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。\n比如说，我们假设创建了一个 topic ，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。\nKafka 0.8 以后，提供了 HA 机制，就是 replica 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower 。写的时候， leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。 Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。\n这么搞，就有所谓的高可用性了，因为如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的，如果这上面有某个 partition 的 leader ，那么此时会从 follower 中 重新选举 一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。\n 写数据 的时候，生产者就写 leader ，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader ， leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为） 消费 的时候，只会从 leader 去读，但是 只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。  消息幂等性 Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset ，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。\n但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 kill 进程了，再重启。这会导致 consumer 有些消息处理了，但是没来得及提交 offset ，尴尬了。重启之后，少数消息会再次消费一次。\n幂等性，通俗点说，一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性？其实还是得 结合业务来思考，这里给几个思路：\n 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。 比如你是写 Redis ，那没问题了，反正每次都是 set，天然幂等性。 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。  消息丢失 消费端弄丢了数据 唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边 自动提交了 offset ，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。\nKafka 会自动提交 offset ，那么只要 关闭自动提交 offset，在处理完之后自己手动提交 offset ，就可以保证数据不会丢。但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 offset ，结果自己挂了，此时肯定会重复消费一次，自己 保证幂等性 就好了。\nKafka 弄丢了数据 这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader 。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。\n此时一般是要求起码设置如下 4 个参数：\n 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有 至少 2 个副本。 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是 要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求 一旦写入失败，就无限重试，卡在这里了。  这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。\n生产者会不会弄丢数据？ 如果按照上述的思路设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者可以自动不断的重试，重试无限次。\n消息的顺序性 比如说我们建了一个 topic ，有三个 partition 。生产者在写的时候，其实可以指定一个 key ，比如说我们指定了某个订单 id 作为 key ，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。\n消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞 多个线程来并发处理消息。而多个线程并发跑的话，顺序可能就乱掉了。\n解决方案：\n 一个 topic ，一个 partition ，一个 consumer ，内部单线程消费，单线程吞吐量太低，一般不会用这个。 写 N 个内存 queue ，具有相同 key 的数据都到同一个内存 queue ；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。  Kafka 如何进行扩容的？ 假如集群有 3 个 broker，一共有 4 个 TP，每个 3 副本，均匀分布。现在要扩容一台机器，新 broker 加入集群后需要通过工具进行 TP 的迁移。一共迁移 3 个 TP 的副本到新 broker 上。等迁移结束之后，会重新进行 Leader balance。\n从微观的角度看，TP 从一台 broker 迁移到另一个 broker 的流程是怎么样的呢？咱们来看下 TP3 第三个副本，从 broker1 迁移到 broker4 的过程，如下图所示，broker4 作为 TP3 的 follower，从 broker1 上最早的 offset 进行获取数据，直到赶上最新的 offset 为止，新副本被放入 ISR 中，并移除 broker1 上的副本，迁移过程完毕。\n但在现有的扩容流程中存有如下问题：数据迁移从 TP3 的最初的 offset 开始拷贝数据，这会导致大量读磁盘，消耗大量的 I/O 资源，导致磁盘繁忙，从而造成 produce 操作延迟增长，产生抖动。所以整体迁移流程不够平滑。我们看下实际的监控到的数据。从中可以看到数据迁移中， broker1 上磁盘读量增大，磁盘 util 持续打满，produce 极其不稳定。\n针对这个问题，我们回到 Kafka 迁移的流程上看，理论上 Kafka 是一个缓存系统，不需要永久存储数据，很有可能费了很多工作迁移过来的数据根本就不会被使用，甚至马上就会被删除了。从这个角度上看，那么迁移数据时，为什么一定要从 partition 最初 offset 开始迁移数据呢？细想想，好像不需要这样。\n所以，解决这个问题的思路就比较简单了，在迁移 TP 时，直接从 partition 最新的 offset 开始数据迁移，但是要同步保持一段时间，主要是确保所有 consumer 都已经跟得上了。\nLeader 选举过程 控制器的选举 在Kafka集群中会有一个或多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态等工作。比如当某个分区的 Leader 副本出现故障时，由控制器负责为该分区选举新的 Leader 副本。再比如当检测到某个分区的 ISR(In-Sync Replicas) 集合发生变化时，由控制器负责通知所有 broker 更新其元数据信息。\nKafka Controller 的选举是依赖 Zookeeper 来实现的，在 Kafka 集群中哪个 broker 能够成功创建 /controller 这个临时（EPHEMERAL）节点他就可以成为 Kafka Controller。Kafka Controller 的出现是处于性能考虑，当 Kafka 集群规模很大，partition 达到成千上万时，当 broker 宕机时，造成集群内大量的调整，会造成大量 Watch 事件被触发，Zookeeper负载会过重。\nController 脑裂 kafka 中只有一个控制器 controller 负责分区的 leader 选举，同步 broker 的新增或删除消息，但有时由于网络问题，可能同时有两个 broker 认为自己是 controller ，这时候其他的 broker 就会发生脑裂。\n解决方案：每当新的 controller 产生的时候就会在 ZK 中生成一个全新的、数值更大的 controller epoch 的标识，并同步给其他的 broker 进行保存，这样当第二个 controller 发送指令时，其他的 broker 就会自动忽略。\n分区 Leader 的选举 分区 Leader 副本的选举由 Kafka Controller 负责具体实施。当创建分区（创建主题或增加分区都有创建分区的动作）或分区上线（比如分区中原先的 Leader 副本下线，此时分区需要选举一个新的 Leader 上线来对外提供服务）的时候都需要执行 Leader 的选举动作。\n消费者相关的选举 组协调器 GroupCoordinator 需要为消费组内的消费者选举出一个消费组的 Leader，这个选举的算法也很简单，分两种情况分析。如果消费组内还没有 Leader，那么第一个加入消费组的消费者即为消费组的 Leader。如果某一时刻 Leader 消费者由于某些原因退出了消费组，那么会重新选举一个新的 Leader。\n负载均衡 Producers 负载均衡 对于同一个 topic 的不同 partition，Kafka 会尽力将这些 partition 分布到不同的 broker 服务器上，这种均衡策略实际上是基于 ZooKeeper 实现的。在一个 broker 启动时，会首先完成 broker 的注册过程，并注册一些诸如 “有哪些可订阅的 topic” 之类的元数据信息。producers 启动后也要到 ZooKeeper 下注册，创建一个临时节点来监听 broker 服务器列表的变化。由于在 ZooKeeper 下 broker 创建的也是临时节点，当 brokers 发生变化时，producers 可以得到相关的通知，从改变自己的 broker list。其它的诸如 topic 的变化以及 broker 和 topic 的关系变化，也是通过 ZooKeeper 的这种 Watcher 监听实现的。\n在生产中，必须指定 topic；但是对于 partition，有两种指定方式：\n 明确指定 partition(0-N)，则数据被发送到指定 partition； 设置为 RD_KAFKA_PARTITION_UA ，则 Kafka 会回调 partitioner 进行均衡选取， partitioner 方法需要自己实现。可以轮询或者传入 key 进行 hash。未实现则采用默认的随机方法 rd_kafka_msg_partitioner_random 随机选择。  Consumer 负载均衡 Kafka 保证同一 consumer group 中只有一个 consumer 可消费某条消息，实际上，Kafka 保证的是稳定状态下每一个 consumer 实例只会消费某一个或多个特定的数据，而某个 partition 的数据只会被某一个特定的 consumer 实例所消费。这样设计的劣势是无法让同一个 consumer group 里的 consumer 均匀消费数据，优势是每个 consumer 不用都跟大量的 broker 通信，减少通信开销，同时也降低了分配难度，实现也更简单。另外，因为同一个 partition 里的数据是有序的，这种设计可以保证每个 partition 里的数据也是有序被消费。\nconsumer 数量不等于 partition 数量 如果某 consumer group 中 consumer 数量少于 partition 数量，则至少有一个 consumer 会消费多个 partition 的数据；如果 consumer 的数量与 partition 数量相同，则正好一个 consumer 消费一个 partition 的数据，而如果 consumer 的数量多于 partition 的数量时，会有部分 consumer 无法消费该 topic 下任何一条消息。\n借助 ZooKeeper 实现负载均衡 关于负载均衡，对于某些低级别的 API，consumer 消费时必须指定 topic 和 partition，这显然不是一种友好的均衡策略。基于高级别的 API，consumer 消费时只需制定 topic，借助 ZooKeeper 可以根据 partition 的数量和 consumer 的数量做到均衡的动态配置。\nconsumers 在启动时会到 ZooKeeper 下以自己的 conusmer-id 创建临时节点 /consumer/[group-id]/ids/[conusmer-id]，并对 /consumer/[group-id]/ids 注册监听事件，当消费者发生变化时，同一 group 的其余消费者会得到通知。当然，消费者还要监听 broker 列表的变化。kafka 通常会将 partition 进行排序后，根据消费者列表，进行轮流的分配。\n参考  Kafka设计解析 Kafka的高可用 Kafka幂等性 Kafka消息丢失 快手万亿级别 Kafka 集群应用实践与技术演进之路 kafka的leader选举过程  "});index.add({'id':50,'href':'/interview/docs/basic/algo/kmp/','title':"KMP",'content':"KMP算法 KMP算法解决的问题是字符匹配，这个算法把字符匹配的时间复杂度缩小到O(m+n),而空间复杂度也只有O(m),n是target的长度，m是pattern的长度。\n  部分匹配表（Next数组）：表的作用是 让算法无需多次匹配S中的任何字符。能够实现线性时间搜索的关键是 在不错过任何潜在匹配的情况下，我们\u0026quot;预搜索\u0026quot;这个模式串本身并将其译成一个包含所有可能失配的位置对应可以绕过最多无效字符的列表。\n  Next数组（前缀和前缀的比较）：t为模式串，j为下标\n Next[0] = -1 Next[j] = MAX{ k | 0 \u0026lt; k \u0026lt; j | \u0026quot; t0 t1 ... tk \u0026quot; = \u0026quot;t ( j-k ) t ( j-k+1 ) ... t( j-1 )\u0026quot; }    |i|\t0|\t1|\t2|\t3|\t4|\t5\t|6| |\u0026ndash;| | t[i]|\tA|\tB|\tC|\tD|\tA|\tB|\tD| |next[i]|\t-1|\t0\t|0\t|0\t|0\t|1\t|2|\n NextVal数组：是一种优化后的Next数组，是为了解决类似aaaab这种模式串的匹配，减少重复的比较。 如果t[next[j]]=t[j]：nextval[j]=nextval[next[j]]，否则nextval[j]=next[j]。  |i|\t0|\t1|\t2|\t3|\t4|\t5\t|6| |\u0026ndash;| | t |\ta|\tb| c|\ta| b| a |a| |next[j] |\t-1|\t0\t|0\t|0\t|1\t|2\t|1| |nextval[j] |\t-1|\t0\t|0\t|-1\t|0\t|2\t|1|\n在上面的表格中，t[next[4]]=t[4]=b，所以nextval[4]=nextval[next[4]]=0\n"});index.add({'id':51,'href':'/interview/docs/architecture/distributed/mq/','title':"MQ",'content':"MQ 消息队列技术(Message Queue) 是分布式应用间交换信息的一种技术。消息队列可驻留在内存或磁盘上, 队列存储消息直到它们被应用程序读走。通过消息队列，应用程序可独立地执行 ———— 它们不需要知道彼此的位置、或在继续执行前不需要等待接收程序接收此消息。在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。\nMQ使用场景   异步通信：有些业务不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。\n  解耦：降低工程间的强依赖程度，针对异构系统进行适配。在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。通过消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口，当应用发生变化时，可以独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束\n  冗余：有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的\u0026quot;插入-获取-删除\u0026quot;范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。\n  扩展性：因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。便于分布式扩容\n  过载保护：在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量无法提取预知；如果以为了能处理这类瞬间峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃\n  可恢复性：系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。   顺序保证：在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。   缓冲：在任何重要的系统中，都会有需要不同的处理时间的元素。消息队列通过一个缓冲层来帮助任务最高效率的执行，该缓冲有助于控制和优化数据流经过系统的速度。以调节系统响应时间。\n  数据流处理：分布式系统产生的海量数据流，如：业务日志、监控数据、用户行为等，针对这些数据流进行实时或批量采集汇总，然后进行大数据分析是当前互联网的必备技术，通过消息队列完成此类数据收集是最好的选择\n  MQ缺点   系统可用性降低：系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了， ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用。\n  系统复杂度提高：硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。\n  一致性问题： A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里， BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。\n  MQ常用协议   AMQP协议 AMQP即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。\n 优点：可靠、通用\n   MQTT协议 MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和致动器（比如通过Twitter让房屋联网）的通信协议。  优点：格式简洁、占用带宽小、移动端通信、PUSH、嵌入式系统\n   STOMP协议 STOMP（Streaming Text Orientated Message Protocol）是流文本定向消息协议，是一种为MOM(Message Oriented Middleware，面向消息的中间件)设计的简单文本协议。STOMP提供一个可互操作的连接格式，允许客户端与任意STOMP消息代理（Broker）进行交互。  优点：命令模式（非topic/queue模式）\n   XMPP协议 XMPP（可扩展消息处理现场协议，Extensible Messaging and Presence Protocol）是基于可扩展标记语言（XML）的协议，多用于即时消息（IM）以及在线现场探测。适用于服务器之间的准即时操作。核心是基于XML流传输，这个协议可能最终允许因特网用户向因特网上的其他任何人发送即时消息，即使其操作系统和浏览器不同。\n 优点：通用公开、兼容性强、可扩展、安全性高，但XML编码格式占用带宽大\n   其他基于TCP/IP自定义的协议：有些特殊框架（如：redis、kafka、zeroMq等）根据自身需要未严格遵循MQ规范，而是基于TCP\\IP自行封装了一套协议，通过网络socket接口进行传输，实现了MQ的功能。\n  MQ的通讯模式   点对点通讯：点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。\n  多点广播：MQ适用于不同类型的应用。其中重要的，也是正在发展中的是\u0026quot;多点广播\u0026quot;应用，即能够将消息发送到多个目标站点(Destination List)。可以使用一条MQ指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ将消息的一个复制版本和该系统上接收者的名单发送到目标MQ系统。目标MQ系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。\n  发布/订阅(Publish/Subscribe)模式：发布/订阅功能使消息的分发可以突破目的队列地理指向的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅功能使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。在MQ家族产品中，MQ Event Broker是专门用于使用发布/订阅技术进行数据通讯的产品，它支持基于队列和直接基于TCP/IP两种方式的发布和订阅。\n  集群(Cluster)：为了简化点对点通讯模式中的系统配置，MQ提供 Cluster 的解决方案。集群类似于一个 域(Domain) ，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用 Cluster 通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性\n  消息投递保证  At most once：消息可能会丢，但绝不会重复投递 At least one：消息绝不会丢，但可能会重复投递 Exactly once：每条消息肯定会被投递一次且仅投递一次，很多时候这是用户所想要的。  参考链接 消息队列面试场景\n"});index.add({'id':52,'href':'/interview/docs/fromwork/mybatis/proxy/','title':"Mybatis 动态代理",'content':"Mybatis 动态代理 获取代理类流程 获取Mapper代理类的时序图如下：\n重点说下MapperProxy类，声明如下：\npublic class MapperProxy\u0026lt;T\u0026gt; implements InvocationHandler, Serializable 获取到 MapperProxy 之后，根据调用不同的方法，会将最终的参数传递给 SqlSession。\n"});index.add({'id':53,'href':'/interview/docs/fromwork/mybatis/cache/','title':"Mybatis 缓存机制",'content':"Mybatis 缓存机制 Mybatis 的缓存均缓存查询操作结果。按照作用域范围，可以分为：\n- **一级缓存**： `SqlSession` 级别的缓存 - **二级缓存**： `namespace` 级别的缓存  一级缓存 Mybatis 默认开启了一级缓存， 一级缓存有两个级别可以设置：分别是 SESSION 或者 STATEMENT 默认是 SESSION 级别，即在一个 MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是 STATEMENT 级别，可以理解为缓存只对当前执行的这一个 Statement 有效。\n STATEMENT 级别相当于关闭一级缓存\n \u0026lt;setting name=\u0026quot;localCacheScope\u0026quot; value=\u0026quot;SESSION\u0026quot;/\u0026gt; 基本原理 在一级缓存中，当 sqlSession 执行写操作（执行插入、更新、删除），清空 SqlSession 中的一级缓存。\n总结  MyBatis 一级缓存的生命周期和SqlSession一致。 MyBatis 一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。 MyBatis 的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。  二级缓存 如果多个 SqlSession 之间需要共享缓存，则需要使用到二级缓存。开启二级缓存后，会使用 CachingExecutor 装饰 Executor ，进入一级缓存的查询流程前，先在C achingExecutor 进行二级缓存的查询，具体的工作流程如下所示。\n二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。当开启缓存后，数据的查询执行的流程就是 二级缓存 -\u0026gt; 一级缓存 -\u0026gt; 数据库。\n\u0026lt;setting name=\u0026quot;cacheEnabled\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; 总结  MyBatis 的二级缓存相对于一级缓存来说，实现了 SqlSession 之间缓存数据的共享，同时粒度更加的细，能够到 namespace 级别，通过 Cache 接口实现类不同的组合，对Cache的可控性也更强。 MyBatis 在多表查询时，极大可能会出现脏数据，有设计上的缺陷，安全使用二级缓存的条件比较苛刻。 在分布式环境下，由于默认的 MyBatis Cache 实现都是基于本地的，分布式环境下必然会出现读取到脏数据，需要使用集中式缓存将 MyBatis 的 Cache 接口实现，有一定的开发成本，直接使用 Redis、Memcached 等分布式缓存可能成本更低，安全性也更高。  "});index.add({'id':54,'href':'/interview/docs/fromwork/netty/','title':"Netty",'content':"Netty Netty 是一个 异步 事件驱动 的网络应用框架，用于快速开发高性能、可扩展协议的服务器和客户端\nReactor 无论是 C++ 还是 Java 编写的网络框架，大多数都是基于 Reactor 模式进行设计和开发，Reactor 模式基于事件驱动，特别适合处理海量的 I/O 事件。\n反应器设计模式-维基百科 \u0026ndash; 反应器设计模式(Reactor pattern)是一种为处理服务请求并发 提交到一个或者多个服务处理程序的事件设计模式。当请求抵达后，服务处理程序使用解多路分配策略，然后同步地派发这些请求至相关的请求处理程序。\n单线程模型 Reactor 单线程模型，指的是所有的 IO 操作都在同一个 NIO 线程上面完成，NIO 线程的职责如下：\n 作为 NIO 服务端，接收客户端的 TCP 连接； 作为 NIO 客户端，向服务端发起 TCP 连接； 读取通信对端的请求或者应答消息； 向通信对端发送消息请求或者应答消息。  由于 Reactor 模式使用的是异步非阻塞 IO，所有的 IO 操作都不会导致阻塞，理论上一个线程可以独立处理所有 IO 相关的操作。从架构层面看，一个 NIO 线程确实可以完成其承担的职责。例如，通过 Acceptor 类接收客户端的 TCP 连接请求消息，链路建立成功之后，通过 Dispatch 将对应的 ByteBuffer 派发到指定的 Handler 上进行消息解码。用户线程可以通过消息编码通过 NIO 线程将消息发送给客户端。\n对于一些小容量应用场景，可以使用单线程模型。但是 对于高负载、大并发的应用场景却不合适。\n多线程模型 Rector 多线程模型与单线程模型最大的区别就是有一组 NIO 线程处理 IO 操作，它的原理图如下：\nReactor 多线程模型的特点：\n 有专门一个 NIO 线程 Acceptor 线程用于监听服务端，接收客户端的 TCP 连接请求； 网络 IO 操作 - 读、写等由一个 NIO 线程池负责，线程池可以采用标准的 JDK 线程池实现，它包含一个任务队列和 N 个可用的线程，由这些 NIO 线程负责消息的读取、解码、编码和发送； 1 个 NIO 线程可以同时处理 N 条链路，但是 1 个链路只对应 1 个 NIO 线程，防止发生并发操作问题。  主从多线程模型 主从 Reactor 线程模型的特点是：服务端用于接收客户端连接的不再是个 1 个单独的 NIO 线程，而是一个独立的 NIO 线程池。 Acceptor 接收到客户端 TCP 连接请求处理完成后（可能包含接入认证等），将新创建的 SocketChannel 注册到 IO 线程池（sub reactor 线程池）的某个 IO 线程上，由它负责 SocketChannel 的读写和编解码工作。 Acceptor 线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端 subReactor 线程池的 IO 线程上，由 IO 线程负责后续的 IO 操作。\n它的工作流程总结如下：\n 从主线程池中随机选择一个 Reactor 线程作为 Acceptor 线程，用于绑定监听端口，接收客户端连接； Acceptor 线程接收客户端连接请求之后创建新的 SocketChannel ，将其注册到主线程池的其它 Reactor 线程上，由其负责接入认证、IP 黑白名单过滤、握手等操作； 步骤 2 完成之后，业务层的链路正式建立，将 SocketChannel 从主线程池的 Reactor 线程的多路复用器上摘除，重新注册到 Sub 线程池的线程上，用于处理 I/O 的读写操作。  Netty 的优势  多路复用，并在 NIO 的基础上进行更高层次的抽象 事件机制 功能强大，预置了多种编解码功能，支持多种主流协议 定制能力强，可以通过ChannelHandler对通信框架进行灵活的扩展  Netty 为什么性能好？  纯异步：Reactor 线程模型 IO 多路复用 GC 优化：更少的分配内存、池化（Pooling）、复用、选择性的使用 sun.misc.Unsafe 更多的硬件相关优化（mechanical sympathy） 内存泄漏检测 \u0026ldquo;Zero Copy\u0026rdquo;  Zero Copy Netty 的 Zero-copy 体现在如下几个个方面:\n Netty 提供了 CompositeByteBuf 类, 它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf , 避免了各个 ByteBuf 之间的拷贝. 通过 wrap 操作, 我们可以将 byte[] 数组、ByteBuf 、 ByteBuffer 等包装成一个 Netty ByteBuf 对象, 进而避免了拷贝操作. ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf, 避免了内存的拷贝. 通过 FileRegion 包装的 FileChannel.tranferTo 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel , 避免了传统通过循环 write 方式导致的内存拷贝问题.  垃圾回收 Netty 里 HeapByteBuffer 底下的 byte[] 能够依赖JVM GC自然回收；而 DirectByteBuffer 底下是 Java 堆外内存，除了等JVM GC，最好也能主动进行回收；所以，Netty ByteBuf需要在 JVM 的 GC 机制之外，有自己的引用计数器和回收过程。\n 原生的 JVM GC 很难回收掉 DirectByteBuffer 所占用的 Native Memory\n Netty 中采用引用计数对 DirectByteBuffer 进行对象可达性检测，当 DirectByteBuffer 上的引用计数为 0 时将对象释放。\n@Override public boolean release() { for (;;) { int refCnt = this.refCnt; if (refCnt == 0) { throw new IllegalReferenceCountException(0, -1); } if (refCntUpdater.compareAndSet(this, refCnt, refCnt - 1)) { if (refCnt == 1) { deallocate(); return true; } return false; } } } Netty 内存泄漏，主要是针对池化的 ByteBuf 。 ByteBuf 对象被 JVM GC 掉之前，没有调用 release() 把底下的 DirectByteBuffer 或byte[] 归还，会导致池越来越大。而非池化的 ByteBuf ，即使像 DirectByteBuf 那样可能会用到 System.gc() ，但终归会被 release 掉的，不会出大事。因此 Netty 默认会从分配的 ByteBuf 里抽样出大约 1% 的来进行跟踪。\n源码 ByteBuf  ByteBuf 扩容采用先倍增后步进的方式  DirectBuffer vs HeapBuffer 在执行网络IO或者文件IO时，如果是使用 DirectBuffer 就会少一次内存拷贝。如果是非 DirectBuffer ，JDK 会先创建一个 DirectBuffer ，再去执行真正的写操作。这是因为，当我们把一个地址通过 JNI 传递给底层的C库的时候，有一个基本的要求，就是这个地址上的内容不能失效。然而，在 GC 管理下的对象是会在 Java 堆中移动的。也就是说，有可能我把一个地址传给底层的 write ，但是这段内存却因为 GC 整理内存而失效了。所以我必须要把待发送的数据放到一个 GC 管不着的地方。这就是调用 native 方法之前，数据一定要在堆外内存的原因。\nNetty 启动以及链接建立过程 Epoll 触发 有两种模式，一是水平触发（LT），二是边缘触发（ET）。\n在LT模式下，只要某个fd还有数据没读完，那么下次轮询还会被选出。而在ET模式下，只有fd状态发生改变后，该fd才会被再次选出。ET模式的特殊性，使在ET模式下的一次轮询必须处理完本次轮询出的fd的所有数据，否则该fd将不会在下次轮询中被选出。\n NioChannel：是水平触发 EpollChannel：是边缘触发，Netty 为保证数据完整会在特定条件下自己触发 Epoll Event，来读取数据  JDK NIO BUG  正常情况下，selector.select() 操作是阻塞的，只有被监听的 fd 有读写操作时，才被唤醒 但是，在这个 bug 中，没有任何 fd 有读写请求，但是 select() 操作依旧被唤醒 很显然，这种情况下，selectedKeys() 返回的是个空数组 然后按照逻辑执行到 while(true) 处，循环执行，导致死循环。  Netty 解决方案：\nlong currentTimeNanos = System.nanoTime(); for (;;) { // 1.定时任务截止事时间快到了，中断本次轮询  //...  // 2.轮询过程中发现有任务加入，中断本次轮询  //...  // 3.阻塞式select操作  selector.select(timeoutMillis); // 4.解决jdk的nio bug  long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) \u0026gt;= currentTimeNanos) { selectCnt = 1; } else if (SELECTOR_AUTO_REBUILD_THRESHOLD \u0026gt; 0 \u0026amp;\u0026amp; selectCnt \u0026gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) { rebuildSelector(); selector = this.selector; selector.selectNow(); selectCnt = 1; break; } currentTimeNanos = time; //...  } netty 会在每次进行 selector.select(timeoutMillis) 之前记录一下开始时间 currentTimeNanos ，在 select 之后记录一下结束时间，判断 select 操作是否至少持续了 timeoutMillis 秒。如果持续的时间大于等于 timeoutMillis ，说明就是一次有效的轮询，重置 selectCnt 标志，否则，表明该阻塞方法并没有阻塞这么长时间，可能触发了 jdk 的空轮询 bug ，当空轮询的次数超过一个阀值的时候，默认是 512 ，就开始重建 selector\n"});index.add({'id':55,'href':'/interview/docs/java/object/','title':"Object",'content':"Object getClass 返回该对象运行时的 class 对象，返回的 Class 对象是由所表示的类的静态同步方法锁定的对象。\nhashCode 返回该对象的 hashcode，该方法对hash表提供支持，例如 HashMap。 对于该方法有几点需要注意：\n 在运行中的Java应用，如果用在 equals 中进行比较的信息没有改变，那么不论何时调用都需要返回一致的int值。这个hash值在应用的两次执行中不需要保持一致。 如果两个对象根据 equals 方法认为是相等的，那么这两个对象也应该返回相等的 hashcode。 不要求两个不相等的对象，在调用 hashCode 方法返回的结果是必须是不同的。然而，程序员应该了解不同的对象产生不同的 hashcode 能够提升哈希表的效率。 Object的hashcode对不同的对象，尽可能返回不同的 hashcode 。这通常通过将对象的内部地址转换为整数来实现，但Java编程语言不需要此实现技术。  Arrays.hashCode Arrays.hashCode 是一个数组的浅哈希码实现，深哈希可以使用 deepHashCode。并且当数组长度为1时，Arrays.hashCode(object) = object.hashCode 不一定成立\n31 不论是String、Arrays在计算多个元素的哈希值的时候，都会有31这个数字。主要有以下两个原因：\n  31是一个不大不小的质数，是作为 hashCode 乘子的优选质数之一。\n 另外一些相近的质数，比如37、41、43等等，也都是不错的选择。那么为啥偏偏选中了31呢？请看第二个原因。\n   31可以被 JVM 优化，   \\(31 * i = (i 。\n  上面两个原因中，第一个需要解释一下，第二个比较简单，就不说了。一般在设计哈希算法时，会选择一个特殊的质数。至于为啥选择质数，我想应该是可以降低哈希算法的冲突率。\n在 Effective Java 中有一段相关的解释：\n 选择数字31是因为它是一个奇质数，如果选择一个偶数会在乘法运算中产生溢出，导致数值信息丢失，因为乘二相当于移位运算。选择质数的优势并不是特别的明显，但这是一个传统。同时，数字31有一个很好的特性，即乘法运算可以被移位和减法运算取代，来获取更好的性能： \\(31 * i == (i ，现代的 Java 虚拟机可以自动的完成这个优化。\n equals 判定两个对象是否相等。equals和hashCode需要同时被overwrite\nclone 创建一个该对象的副本，并且对于对象 x 应当满足以下表达式：\nx.clone() != x x.clone().getClass() == x.getClass() x.clone().equals(x) toString wait 当前线程等待知道其他线程调用该对象的 notify 或者 notifyAll方法。当前线程必须拥有该对象的 monitor。线程释放该对象monitor的拥有权，并且等待到别的线程通知等待在该对象monitor上的线程苏醒。然后线程重新拥有monitor并继续执行。在某些jdk版本中，中断和虚假唤醒是存在的，所以wait方法需要放在循环中。\nsynchronized (obj) { while (\u0026lt;condition does not hold\u0026gt;) obj.wait(); ... // Perform action appropriate to condition } 该方法只能被拥有该对象monitor的线程调用。\n虚假唤醒（spurious wakeup） 虚假唤醒就是一些obj.wait()会在除了obj.notify()和obj.notifyAll()的其他情况被唤醒，而此时是不应该唤醒的。\n 注意 Lock 的 Conditon.await 也有虚假唤醒的问题\n 解决的办法是基于while来反复判断进入正常操作的临界条件是否满足\n 同时也可以使用同步数据结构：BlokingQueue\n 解释 虚假唤醒（spurious wakeup）是一个表象，即在多处理器的系统下发出 wait 的程序有可能在没有 notify 唤醒的情形下苏醒继续执行。\n以运行在 Linux 的 hotspot 虚拟机上的 java 程序为例， wait 方法在 jvm 执行时实质是调用了底层 pthread_cond_wait/pthread_cond_timedwait 函数，挂起等待条件变量来达到线程间同步通信的效果，而底层 wait 函数在设计之初为了不减慢条件变量操作的效率并没有去保证每次唤醒都是由 notify 触发，而是把这个任务交由上层应用去实现，即使用者需要定义一个循环去判断是否条件真能满足程序继续运行的需求，当然这样的实现也可以避免因为设计缺陷导致程序异常唤醒的问题。\nnotify 唤醒一个等待在该对象monitor上的线程。如果有多个线程等待，则会随机选择一个线程唤醒。线程等待是通过调用wait方法。\n唤醒的线程不会立即执行，直到当前线程放弃对象上的锁。唤醒的线程也会以通常的方式和竞争该对象锁的线程进行竞争。也就是说，唤醒的线程在对该对象的加锁中没有任何优先级。\n该方法只能被拥有该对象monitor的线程调用。线程拥有monitor有下面三种方式：\n 执行该对象的 synchronized 方法 执行以该对象作为同步语句的synchronized方法体 对于class对象，可以执行该对象的static synchronized方法  在同一时间只能有一个线程能够拥有该对象monitor\nfinalize 当 GC 认为该对象已经没有任何引用的时候，该方法被GC收集器调用。子类可以 overwrite 该方法来关闭系统资源或者其他清理任务。\nfinalize 的一般契约是，如果 Java 虚拟机确定不再有任何方法可以通过任何尚未死亡的线程访问此对象，除非由于某个操作，它将被调用通过最终确定准备完成的其他一些对象或类来完成。 finalize 方法可以采取任何操作，包括使该对象再次可用于其他线程；但是，finalize 的通常目的是在对象被不可撤销地丢弃之前执行清理操作。例如，表示输入/输出连接的对象的 finalize 方法可能会执行显式 I/O 事务，以在永久丢弃对象之前断开连接。\n类 Object 的 finalize 方法不执行任何特殊操作;它只是正常返回。 Object 的子类可以覆盖此定义。\nJava 编程语言不保证哪个线程将为任何给定对象调用 finalize 方法。但是，可以保证，调用 finalize 时，调用 finalize 的线程不会持有任何用户可见的同步锁。如果 finalize 方法抛出未捕获的异常，则忽略该异常并终止该对象的终止。在为对象调用 finalize 方法之后，在 Java 虚拟机再次确定不再有任何方法可以通过任何尚未死亡的线程访问此对象之前，不会采取进一步操作，包括可能的操作通过准备完成的其他对象或类，此时可以丢弃该对象。\n对于任何给定对象，Java 虚拟机永远不会多次调用 finalize 方法。 finalize 方法抛出的任何异常都会导致暂停此对象的终结，但会被忽略。\n缺陷  一些与 finalize 相关的方法，由于一些致命的缺陷，已经被废弃了，如 System.runFinalizersOnExit() 方法、Runtime.runFinalizersOnExit()方法。 System.gc() 与 System.runFinalization() 方法增加了finalize方法执行的机会，但不可盲目依赖它们。 Java 语言规范并不保证 finalize 方法会被及时地执行、而且根本不会保证它们会被执行。 finalize 方法可能会带来性能问题。因为JVM通常在单独的低优先级线程中完成finalize的执行。 对象再生问题： finalize 方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的。 finalize 方法至多由GC执行一次(用户当然可以手动调用对象的 finalize 方法，但并不影响GC对 finalize 的行为)。  "});index.add({'id':56,'href':'/interview/docs/basic/database/redis/','title':"Redis",'content':"Redis 线程模型 Redis 在处理网络请求是使用单线程模型，并通过 IO 多路复用来提高并发。但是在其他模块，比如：持久化，会使用多个线程。\nRedis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket ，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。\n文件事件处理器的结构包含 4 个部分：\n 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）  多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket ，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket ，根据 socket 的事件类型交给对应的事件处理器进行处理。\n客户端与 Redis 的一次通信过程：\n为啥 Redis 单线程模型也能效率这么高？  纯内存操作 核心是基于非阻塞的 IO 多路复用机制 单线程反而避免了多线程的频繁上下文切换问题  持久化 RDB RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化。\n RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，非常适合做冷备 RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。 一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟的数据。 RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。  AOF AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集\n AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 fsync 操作，最多丢失 1 秒钟的数据。 AOF 日志文件以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。 AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。 AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常 适合做灾难性的误删除的紧急恢复。比如某人不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。 对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。 AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低） 以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。  RDB 和 AOF 到底该如何选择  不要仅仅使用 RDB，因为那样会导致你丢失很多数据； 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug； Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。  一致性哈希算法 一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n 个关键字重新映射，其中 K 是关键字的数量，n 是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。\n 一致哈希也可用于实现健壮缓存来减少大型 Web 应用中系统部分失效带来的负面影响\n 需求 在使用 n 台缓存服务器时，一种常用的负载均衡方式是，对资源 o 的请求使用 hash(o)= o mod n 来映射到某一台缓存服务器。当增加或减少一台缓存服务器时这种方式可能会改变所有资源对应的 hash 值，也就是所有的缓存都失效了，这会使得缓存服务器大量集中地向原始内容服务器更新缓存。\n因此需要一致哈希算法来避免这样的问题。 一致哈希尽可能使同一个资源映射到同一台缓存服务器。这种方式要求增加一台缓存服务器时，新的服务器尽量分担存储其他所有服务器的缓存资源。减少一台缓存服务器时，其他所有服务器也可以尽量分担存储它的缓存资源。\n一致哈希算法的主要思想是将每个缓存服务器与一个或多个哈希值域区间关联起来，其中区间边界通过计算缓存服务器对应的哈希值来决定。如果一个缓存服务器被移除，则它所对应的区间会被并入到邻近的区间，其他的缓存服务器不需要任何改变。\n实现 一致哈希将每个对象映射到圆环边上的一个点，系统再将可用的节点机器映射到圆环的不同位置。查找某个对象对应的机器时，需要用一致哈希算法计算得到对象对应圆环边上位置，沿着圆环边上查找直到遇到某个节点机器，这台机器即为对象应该保存的位置。\n当删除一台节点机器时，这台机器上保存的所有对象都要移动到下一台机器。添加一台机器到圆环边上某个点时，这个点的下一台机器需要将这个节点前对应的对象移动到新机器上。更改对象在节点机器上的分布可以通过调整节点机器的位置来实现。\n实践  假设有1000w个数据项，100个存储节点，请设计一种算法合理地将他们存储在这些节点上。\n 看一看普通Hash算法的原理：\nfor item in range(ITEMS): k = md5(str(item)).digest() h = unpack_from(\u0026quot;\u0026gt;I\u0026quot;, k)[0] # 通过取余的方式进行映射 n = h % NODES node_stat[n] += 1 普通的Hash算法均匀地将这些数据项打散到了这些节点上，并且分布最少和最多的存储节点数据项数目小于 1%。之所以分布均匀，主要是依赖 Hash 算法（实现使用的MD5算法）能够比较随机的分布。\n然而，我们看看存在一个问题，由于 该算法使用节点数取余的方法，强依赖 node 的数目，因此，当是 node 数发生变化的时候，item 所对应的 node 发生剧烈变化，而发生变化的成本就是我们需要在 node 数发生变化的时候，数据需要迁移，这对存储产品来说显然是不能忍的。\n一致性哈希 普通 Hash 算法的劣势，即当 node 数发生变化（增加、移除）后，数据项会被重新“打散”，导致大部分数据项不能落到原来的节点上，从而导致大量数据需要迁移。\n那么，一个亟待解决的问题就变成了：当 node 数发生变化时，如何保证尽量少引起迁移呢？即当增加或者删除节点时，对于大多数 item ，保证原来分配到的某个 node ，现在仍然应该分配到那个 node ，将数据迁移量的降到最低。\nfor n in range(NODES): h = _hash(n) ring.append(h) ring.sort() hash2node[h] = n for item in range(ITEMS): h = _hash(item) n = bisect_left(ring, h) % NODES node_stat[hash2node[ring[n]]] += 1 虽然一致性Hash算法解决了节点变化导致的数据迁移问题，但是，数据项分布的均匀性很差。\n主要是因为这 100 个节点 Hash 后，在环上分布不均匀，导致了每个节点实际占据环上的区间大小不一造成的。\n改进 \u0026ndash; 虚节点 当我们将 node 进行哈希后，这些值并没有均匀地落在环上，因此，最终会导致，这些节点所管辖的范围并不均匀，最终导致了数据分布的不均匀。\nfor n in range(NODES): for v in range(VNODES): h = _hash(str(n) + str(v)) # 构造ring ring.append(h) # 记录hash所对应节点 hash2node[h] = n ring.sort() for item in range(ITEMS): h = _hash(str(item)) # 搜索ring上最近的hash n = bisect_left(ring, h) % (NODES*VNODES) node_stat[hash2node[ring[n]]] += 1 通过增加虚节点的方法，使得每个节点在环上所“管辖”更加均匀。这样就既保证了在节点变化时，尽可能小的影响数据分布的变化，而同时又保证了数据分布的均匀。也就是靠增加“节点数量”加强管辖区间的均匀。\n集群 主从复制 单机的 Redis ，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成 主从(Master-Slave)架构 ，一主多从，主负责写，并且将数据复制到其它的 Slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。\nRedis 默认采用异步方式复制数据到 Slave Node，同时 Slave Node 会周期性地确认自己每次复制的数据量：\n 当 Master 和 Slave 网络连接顺畅时，Master 会持续向 Slave 推送命令，以保持在 Master 数据集合上执行的：客户端写、Key 过期、Key 淘汰等均在 Slave 数据集合上执行。 当 Master 和 Slave 网络连接由于网络问题、超时等中断时， Slave 会尝试重连并进行连接断开期间的命令 部分同步（partial resynchronization）。 当部分同步不可用时，Slave 会请求全量同步。在这个过程中，Master 会创建当前所有数据的镜像，发送给 Slave 并继续推送命令。  Redis 主从复制包含以下几个要点：\n 一个 Master 可以有多个 Slave Slave 支持级联结构，即 Slave 可以连接到其他 Slave 上 Redis 在复制过程中，不阻塞 Master ，不论是全量同步还是部分同步 在大部分时间里，复制也不会阻塞 Slave 。当 Slave 在进行初始化同步时，Slave 会先使用旧的数据集提供服务。但当初始化同步完成时，会删除旧数据集，这时 Slave 会拒绝服务。 Redis 主从复制可以用来做水平扩容，以提供读写分离，或作为数据备份和高可用 在主从复制的情况下，可以通过配置避免数据持久化，将 Slave 作为数据的备份或开启 Slave 的 AOF。但是这种情况下也会有风险：当 Master 重启后数据集将清空，这时如果 Slave 同步 Master 就会导致数据也被清空  当 Master 不进行持久化如何保证数据安全 在生产环境中，强烈建议开启 Redis 持久化，不论是在 Master 还是在 Slave。如果由于磁盘速度等问题，不能开启持久化，那么需要 避免 Redis 进程的自动重启。\n哨兵 Sentinel 是 Redis 官方推荐的 高可用性( HA )解决方案，当用 Redis 做主从复制的高可用方案时，假如 Master 宕机了， Redis 本身都没有实现自动进行主备切换，而哨兵本身也是一个独立运行的进程，它能监控多个节点，发现 Master 宕机后能进行自动切换。\n它的主要功能有以下几点\n 集群监控：负责监控 Redis Master 和 Slave 进程是否正常工作。 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果 Master node 挂掉了，会自动转移到 Slave node 上。 配置中心：如果故障转移发生了，通知 client 客户端新的 Master 地址。  哨兵的核心知识  哨兵至少需要 3 个实例，来保证自己的健壮性。 哨兵 + Redis 主从的部署架构，是 不保证数据零丢失 的，只能保证 Redis 集群的高可用性。 对于哨兵 + Redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。 哨兵的个数与集群节点个数无关，每个哨兵都会 Check 所有节点 当启用哨兵后，客户端的连接是通过哨兵连接到 Node 的  哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，Quorum = 1。\n+----+ +----+ | M1 |---------| R1 | | S1 | | S2 | +----+ +----+ 如果 Master 宕机， S1 和 S2 中只要有 1 个哨兵认为 Master 宕机了，就可以进行切换，同时 S1 和 S2 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 Majority ，也就是超过半数的哨兵都是运行的。\n如果此时仅仅是 M1 进程宕机了，哨兵 s1 正常运行，那么故障转移是 OK 的。但是如果是整个 M1 和 S1 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 Majority 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。\n经典的 3 节点哨兵集群是这样的：\n+----+ | M1 | | S1 | +----+ | +----+ | +----+ | R2 |----+----| R3 | | S2 | | S3 | +----+ +----+ 配置 Quorum=2，如果 M1 所在机器宕机了，那么三个哨兵还剩下 2 个， S2 和 S3 可以一致认为 Master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 Majority 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。\nSlave 选主算法 如果一个 Master 被认为宕机，而且 Majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 Slave 来，会考虑 Slave 的一些信息：\n 跟 Master 断开连接的时长 Slave 优先级 复制 offset run id  接下来会对 Slave 进行排序：\n 按照 Slave 优先级进行排序，Slave Priority 越低，优先级就越高。 如果 Slave Priority 相同，那么看 Replica Offset，哪个 Slave 复制了越多的数据，Offset 越靠后，优先级就越高。 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 Slave。  Redis Cluster Redis Cluster 是一种服务器 Sharding 技术，提供内置的高可用支持，部分 master 不可用时，还可以继续工作。Redis Cluster 功能强大，直接集成了 主从复制 和 哨兵 的功能。\n在 Cluster 架构下，每个 Redis 都需要开启额外的端口来进行节点间通信，这种机制被称之为 Cluster Bus。\n内部节点通信 Redis 维护集群元数据采用 gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。\ngossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。\n寻址算法  Hash 算法（大量缓存重建） 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡） Redis Cluster 的 Hash Slot 算法  Redis Cluster 有固定的 16384 个 Hash Slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 Hash Slot。\nRedis Cluster 中每个 Master 都会持有部分 Slot，比如有 3 个 Master，那么可能每个 Master 持有 5000 多个 Hash Slot。Hash Slot 让 node 的增加和移除很简单，增加一个 Master，就将其他 Master 的 Hash Slot 移动部分过去，减少一个 Master，就将它的 Hash Slot 移动到其他 master 上去。移动 Hash Slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 Hash Slot，通过 hash tag 来实现。\n任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 Hash Slot，不是机器。\n数据结构 Redis的外围由一个键、值映射的字典构成。与其他非关系型数据库主要不同在于：Redis中值的类型不仅限于 字符串，还支持如下抽象数据类型：\n List：字符串列表 Set：无序不重复的字符串集合 Soret Set：有序不重复的字符串集合 HashTable：键、值都为字符串的哈希表  值的类型决定了值本身支持的操作。Redis支持不同无序、有序的列表，无序、有序的集合间的交集、并集等高级服务器端原子操作。\nstring Redis 没有直接使用 C 语言传统的字符串表示（以空字符结尾的字符数组，以下简称 C 字符串）， 而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象类型， 并将 SDS 用作 Redis 的默认字符串表示。\n在 Redis 里面， C 字符串只会作为字符串字面量（string literal）， 用在一些无须对字符串值进行修改的地方， 比如打印日志。\n当 Redis 需要的不仅仅是一个字符串字面量， 而是一个可以被修改的字符串值时， Redis 就会使用 SDS 来表示字符串值： 比如在 Redis 的数据库里面， 包含字符串值的键值对在底层都是由 SDS 实现的。\n   C字符串 SDS     获取字符串长度的复杂度为 O(N) 。 获取字符串长度的复杂度为 O(1) 。   API 是不安全的，可能会造成缓冲区溢出。 API 是安全的，不会造成缓冲区溢出。   修改字符串长度 N 次必然需要执行 N 次内存重分配。 修改字符串长度 N 次最多需要执行 N 次内存重分配。   只能保存文本数据。 可以保存文本或者二进制数据。   可以使用所有 \u0026lt;string.h\u0026gt; 库中的函数。 可以使用一部分 \u0026lt;string.h\u0026gt; 库中的函数。    缓冲区溢出 因为 C 字符串不记录自身的长度， 所以 strcat 假定用户在执行这个函数时， 已经为 dest 分配了足够多的内存， 可以容纳 src 字符串中的所有内容， 而一旦这个假定不成立时， 就会产生缓冲区溢出。\n举个例子， 假设程序里有两个在内存中紧邻着的 C 字符串 s1 和 s2 ， 其中 s1 保存了字符串 \u0026quot;Redis\u0026quot; ， 而 s2 则保存了字符串 \u0026quot;MongoDB\u0026quot; ， 如图所示。\n如果一个程序员决定通过执行：\nstrcat(s1, \u0026quot; Cluster\u0026quot;); 将 s1 的内容修改为 \u0026quot;Redis Cluster\u0026quot; ， 但粗心的他却忘了在执行 strcat 之前为 s1 分配足够的空间， 那么在 strcat 函数执行之后， s1 的数据将溢出到 s2 所在的空间中， 导致 s2 保存的内容被意外地修改， 如图所示。\n与 C 字符串不同， SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性： 当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求， 如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小， 然后才执行实际的修改操作， 所以使用 SDS 既不需要手动修改 SDS 的空间大小， 也不会出现前面所说的缓冲区溢出问题。\n减少修改字符串时带来的内存重分配次数  空间预分配：解决 append 问题 惰性空间释放：解决 strim 问题  二进制安全 C 字符串中的字符必须符合某种编码（比如 ASCII）， 并且 除了字符串的末尾之外， 字符串里面不能包含空字符， 否则最先被程序读入的空字符将被误认为是字符串结尾 —— 这些限制使得 C 字符串只能保存文本数据， 而不能保存像图片、音频、视频、压缩文件这样的二进制数据。\nzset底层实现 跳跃表（skiplist） 是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的。\nRedis 使用跳跃表作为有序集合键的底层实现之一：\n 如果一个有序集合包含的元素数量比较多， 有序集合中元素的成员（member）是比较长的字符串时  Redis 就会使用跳跃表来作为有序集合键的底层实现。\n和链表、字典等数据结构被广泛地应用在 Redis 内部不同， Redis 只在两个地方用到了跳跃表， 一个是实现有序集合键， 另一个是在集群节点中用作内部数据结构， 除此之外， 跳跃表在 Redis 里面没有其他用途。\nBitMap 实现 Bitmaps 并不是实际的数据类型，而是定义在 String 类型上的一个面向字节操作的集合。因为字符串是二进制安全的，最大长度是 512M ，所以最长拥有   \\(2^32\\)  个不同字节。\nRedis 提供以下 BitMap 操作接口：setBit、getBit、bitCount、bitop、bitpos。其中 setBit、getBit都是 \\(O(1)\\)  复杂度的操作。\n优势：\n 基于最小的单位bit进行存储，所以非常省空间。 设置时候时间复杂度O(1)、读取时候时间复杂度O(n)，操作是非常快的。 二进制数据的存储，进行相关计算的时候非常快。 方便扩容  限制：Redis中bit映射被限制在512MB之内，所以最大是 \\(2^32\\)  位。\n缓存穿透、缓存击穿、缓存雪崩 缓存穿透 访问一个不存在的key，缓存不起作用，请求会穿透到 DB，流量大时 DB 会挂掉。\n解决方案   采用布隆过滤器，使用一个足够大的bitmap，用于存储可能访问的 key，不存在的key直接被过滤；\n  访问key未在DB查询到值，也将空值写进缓存，但可以设置较短过期时间。\n  缓存雪崩 大量的 key 设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。\n解决方案 可以给缓存设置过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。\n缓存击穿 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一 key 缓存，前者则是很多key。\n缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。\n解决方案 在缓存失效的时候（判断拿出来的值为空），不是立即去 load db ，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的 SETNX）去 set 一个 mutex key ，当操作返回成功时，再进行 load db 的操作并回设缓存；否则，就重试整个 get 缓存的方法。\nRedis分布式锁  加锁：Redis.set(String key, String value, String nxxx, String expx, int time) 解锁：通过 Lua 脚本执行 if Redis.call('get', KEYS[1]) == ARGV[1] then return Redis.call('del', KEYS[1]) else return 0 end  数据淘汰机制 对象过期 Redis回收过期对象的策略：定期删除+惰性删除\n 惰性删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key 定期删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key  内存淘汰 Redis提供了下面几种淘汰策略供用户选择，其中默认的策略为noeviction策略：\n noeviction：当内存使用达到阈值的时候，所有引起申请内存的命令会报错。 allkeys-lru：在主键空间中，优先移除最近未使用的key。 volatile-lru：在设置了过期时间的键空间中，优先移除最近未使用的key。 allkeys-random：在主键空间中，随机移除某个key。 volatile-random：在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：在设置了过期时间的键空间中，具有更早过期时间的key优先移除。   这里补充一下主键空间和设置了过期时间的键空间，举个例子，假设我们有一批键存储在Redis中，则有那么一个哈希表用于存储这批键及其值，如果这批键中有一部分设置了过期时间，那么这批键还会被存储到另外一个哈希表中，这个哈希表中的值对应的是键被设置的过期时间。设置了过期时间的键空间为主键空间的子集。\n 非精准的LRU 上面提到的LRU（Least Recently Used）策略，实际上 Redis 实现的 LRU 并不是可靠的 LRU，也就是名义上我们使用LRU算法淘汰键，但是实际上被淘汰的键并不一定是真正的最久没用的，这里涉及到一个权衡的问题，如果需要在全部键空间内搜索最优解，则必然会增加系统的开销，Redis是单线程的，也就是同一个实例在每一个时刻只能服务于一个客户端，所以耗时的操作一定要谨慎。\n为了在一定成本内实现相对的LRU，早期的 Redis 版本是 基于采样的 LRU ，也就是放弃全部键空间内搜索解改为采样空间搜索最优解。自从 Redis3.0 版本之后，Redis 作者对于基于采样的 LRU 进行了一些优化，目的是在一定的成本内让结果更靠近真实的 LRU。\n"});index.add({'id':57,'href':'/interview/docs/architecture/distributed/rpc/','title':"RPC",'content':"RPC 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。\n应用发展流程 单一应用架构 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。\n垂直应用架构 当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。\n分布式服务架构 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。\n流动计算架构 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。\n"});index.add({'id':58,'href':'/interview/docs/fromwork/spring/','title':"Spring 基本",'content':"Spring Spring Framework 是一个开源的Java／Java EE全功能栈（full-stack）的应用程序框架，其提供了一个简易的开发方式，这种开发方式，将避免那些可能致使底层代码变得繁杂混乱的大量的属性文件和帮助类。\nSpring中包含的关键特性  强大的基于JavaBeans的采用 控制反转 （Inversion of Control，IoC）原则的配置管理，使得应用程序的组建更加快捷简易。 一个可用于 Java EE 等运行环境的核心 Bean 工厂。 数据库事务的一般化抽象层，允许声明式（Declarative）事务管理器，简化事务的划分使之与底层无关。 内建的针对 JTA 和单个 JDBC 数据源的一般化策略，使 Spring 的事务支持不要求Java EE环境，这与一般的JTA或者EJB CMT相反。 JDBC 抽象层提供了有针对性的异常等级（不再从SQL异常中提取原始代码），简化了错误处理，大大减少了程序员的编码量。再次利用JDBC时，你无需再写出另一个'终止\u0026rsquo;（finally）模块。并且面向JDBC的异常与Spring通用数据访问对象（Data Access Object）异常等级相一致。 以资源容器，DAO实现和事务策略等形式与 Hibernate，JDO 和 MyBatis、SQL Maps 集成。利用众多的翻转控制方便特性来全面支持，解决了许多典型的 Hibernate 集成问题。所有这些全部遵从 Spring 通用事务处理和通用数据访问对象异常等级规范。 灵活的基于核心 Spring 功能的 MVC 网页应用程序框架。开发者通过策略接口将拥有对该框架的高度控制，因而该框架将适应于多种呈现（View）技术，例如 JSP、FreeMarker、Velocity、Thymeleaf 等。值得注意的是，Spring 中间层可以轻易地结合于任何基于 MVC 框架的网页层，例如 Struts、WebWork 或 Tapestry。 提供诸如事务管理等服务的AOP框架。  "});index.add({'id':59,'href':'/interview/docs/java/jvm/string-constant-pool/','title':"String 常量池",'content':"String 常量池 在 JAVA 语言中有 8 中基本类型和一种比较特殊的类型 String 。这些类型为了使他们在运行过程中速度更快，更节省内存，都提供了一种常量池的概念。常量池就类似一个 JAVA 系统级别提供的缓存。\nString 类型的常量池比较特殊。它的主要使用方法有两种：\n 直接使用双引号声明出来的 String 对象会直接存储在常量池中 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方法。 intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中  intern  /** * Returns a canonical representation for the string object. * \u0026lt;p\u0026gt; * A pool of strings, initially empty, is maintained privately by the * class {@code String}. * \u0026lt;p\u0026gt; * When the intern method is invoked, if the pool already contains a * string equal to this {@code String} object as determined by * the {@link #equals(Object)} method, then the string from the pool is * returned. Otherwise, this {@code String} object is added to the * pool and a reference to this {@code String} object is returned. * \u0026lt;p\u0026gt; * It follows that for any two strings {@code s} and {@code t}, * {@code s.intern() == t.intern()} is {@code true} * if and only if {@code s.equals(t)} is {@code true}. * \u0026lt;p\u0026gt; * All literal strings and string-valued constant expressions are * interned. String literals are defined in section 3.10.5 of the * \u0026lt;cite\u0026gt;The Java\u0026amp;trade; Language Specification\u0026lt;/cite\u0026gt;. * * @return a string that has the same contents as this string, but is * guaranteed to be from a pool of unique strings. */ public native String intern(); JAVA 使用 jni 调用 c++ 实现的 StringTable 的 intern 方法, StringTable 跟 Java 中的 HashMap 的实现是差不多的, 只是 不能自动扩容。默认大小是 1009 。\n要注意的是， String 的 String Pool 是一个固定大小的 Hashtable ，默认值大小长度是 1009 ，如果放进 String Pool 的 String 非常多，就会造成 Hash 冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用 String.intern 时性能会大幅下降。\n在 JDK6 中 StringTable 是固定的，就是 1009 的长度，所以如果常量池中的字符串过多就会导致效率下降很快。在 jdk7 中， StringTable 的长度可以通过一个参数指定：\n-XX:StringTableSize=99991  在 JDK6 以及以前的版本中，字符串的常量池是放在堆的 Perm 区。在 JDK7 的版本中，字符串常量池已经从 Perm 区移到正常的 Java Heap 区域\n public static void main(String[] args) { String s = new String(\u0026quot;1\u0026quot;); s.intern(); String s2 = \u0026quot;1\u0026quot;; System.out.println(s == s2); String s3 = new String(\u0026quot;1\u0026quot;) + new String(\u0026quot;1\u0026quot;); s3.intern(); String s4 = \u0026quot;11\u0026quot;; System.out.println(s3 == s4); } 上述代码的执行结果：\n JDK6: false false JDK7: false true  public static void main(String[] args) { String s = new String(\u0026quot;1\u0026quot;); String s2 = \u0026quot;1\u0026quot;; s.intern(); System.out.println(s == s2); String s3 = new String(\u0026quot;1\u0026quot;) + new String(\u0026quot;1\u0026quot;); String s4 = \u0026quot;11\u0026quot;; s3.intern(); System.out.println(s3 == s4); } 上述代码的执行结果：\n JDK6: false false JDK7: false false  由于 JDK7 将字符串常量池移动到 Heap 中，导致上述版本差异，下面具体来分析下。\nJDK6  图中绿色线条代表 string 对象的内容指向，黑色线条代表地址指向\n 在 jdk6 中上述的所有打印都是 false ，因为 jdk6 中的常量池是放在 Perm 区中的， Perm 区和正常的 JAVA Heap 区域是完全分开的。上面说过如果是使用引号声明的字符串都是会直接在字符串常量池中生成，而 new 出来的 String 对象是放在 JAVA Heap 区域。所以拿一个 JAVA Heap 区域的对象地址和字符串常量池的对象地址进行比较肯定是不相同的，即使调用 String.intern 方法也是没有任何关系的。\nJDK7 因为字符串常量池移动到 JAVA Heap 区域后，再来解释为什么会有上述的打印结果。\n 在第一段代码中，先看 s3 和 s4 字符串。String s3 = new String(\u0026quot;1\u0026quot;) + new String(\u0026quot;1\u0026quot;);，这句代码中现在生成了 2个 最终对象，是字符串常量池中的 “1” 和 JAVA Heap 中的 s3 引用指向的对象。中间还有 2个 匿名的 new String(\u0026quot;1\u0026quot;) 我们不去讨论它们。此时 s3 引用对象内容是 ”11” ，但此时常量池中是没有 “11” 对象的。 接下来 s3.intern(); 这一句代码，是将 s3 中的 “11” 字符串放入 String 常量池中，因为此时常量池中不存在 “11” 字符串，因此常规做法是跟 jdk6 图中表示的那样，在常量池中生成一个 “11” 的对象，关键点是 jdk7 中常量池不在 Perm 区域了，这块做了调整。常量池中不需要再存储一份对象，可以直接存储堆中的引用。这份引用指向 s3 引用的对象。 也就是说引用地址是相同的。 最后 String s4 = \u0026quot;11\u0026quot;; 这句代码中 ”11” 是显示声明的，因此会直接去常量池中创建，创建的时候发现已经有这个对象了，此时也就是指向 s3 引用对象的一个引用。所以 s4 引用就指向和 s3 一样了。因此最后的比较 s3 == s4 是 true 。 再看 s 和 s2 对象。 String s = new String(\u0026quot;1\u0026quot;); 第一句代码，生成了2个对象。常量池中的 “1” 和 JAVA Heap 中的字符串对象。s.intern(); 这一句是 s 对象去常量池中寻找后发现 “1” 已经在常量池里了。 接下来 String s2 = \u0026quot;1\u0026quot;; 这句代码是生成一个 s2 的引用指向常量池中的 “1” 对象。 结果就是 s 和 s2 的引用地址明显不同。  接下来是第二段代码：\n 第一段代码和第二段代码的改变就是 s3.intern(); 的顺序是放在 String s4 = \u0026quot;11\u0026quot;; 后了。这样，首先执行 String s4 = \u0026quot;11\u0026quot;; 声明 s4 的时候常量池中是不存在 “11” 对象的，执行完毕后， “11“ 对象是 s4 声明产生的新对象。然后再执行 s3.intern(); 时，常量池中 “11” 对象已经存在了，因此 s3 和 s4 的引用是不同的。 第二段代码中的 s 和 s2 代码中，s.intern();，这一句往后放也不会有什么影响了，因为对象池中在执行第一句代码String s = new String(\u0026quot;1\u0026quot;); 的时候已经生成 “1” 对象了。下边的 s2 声明都是直接从常量池中取地址引用的。 s 和 s2 的引用地址是不会相等的。  小结 从上述的例子代码可以看出 jdk7 版本对 intern 操作和常量池都做了一定的修改。主要包括2点：\n 将 String 常量池 从 Perm 区移动到了 Java Heap 区 String#intern 方法时，如果存在堆中的对象，会直接保存对象的引用，而不会重新创建对象。  使用范例 static final int MAX = 1000 * 10000; static final String[] arr = new String[MAX]; public static void main(String[] args) throws Exception { Integer[] DB_DATA = new Integer[10]; Random random = new Random(10 * 10000); for (int i = 0; i \u0026lt; DB_DATA.length; i++) { DB_DATA[i] = random.nextInt(); } long t = System.currentTimeMillis(); for (int i = 0; i \u0026lt; MAX; i++) { //arr[i] = new String(String.valueOf(DB_DATA[i % DB_DATA.length])); arr[i] = new String(String.valueOf(DB_DATA[i % DB_DATA.length])).intern(); } System.out.println((System.currentTimeMillis() - t) + \u0026quot;ms\u0026quot;); System.gc(); } 运行的参数是：-Xmx2g -Xms2g -Xmn1500M 上述代码是一个演示代码，其中有两条语句不一样，一条是使用 intern，一条是未使用 intern。\n通过上述结果，我们发现不使用 intern 的代码生成了 1000w 个字符串，占用了大约 640m 空间。 使用了 intern 的代码生成了 1345 个字符串，占用总空间 133k 左右。其实通过观察程序中只是用到了 10 个字符串，所以准确计算后应该是正好相差 100w 倍。虽然例子有些极端，但确实能准确反应出 intern 使用后产生的巨大空间节省。\n细心的同学会发现使用了 intern 方法后时间上有了一些增长。这是因为程序中每次都是用了 new String 后，然后又进行 intern 操作的耗时时间，这一点如果在内存空间充足的情况下确实是无法避免的，但我们平时使用时，内存空间肯定不是无限大的，不使用 intern 占用空间导致 jvm 垃圾回收的时间是要远远大于这点时间的。 毕竟这里使用了 1000w 次 intern 才多出来1秒钟多的时间。\n不当使用 fastjson 中对所有的 json 的 key 使用了 intern 方法，缓存到了字符串常量池中，这样每次读取的时候就会非常快，大大减少时间和空间。而且 json 的 key 通常都是不变的。这个地方没有考虑到大量的 json key 如果是变化的，那就会给字符串常量池带来很大的负担。\n这个问题 fastjson 在1.1.24版本中已经将这个漏洞修复了。程序加入了一个最大的缓存大小，超过这个大小后就不会再往字符串常量池中放了。\n参考文档 深入解析String#intern\n"});index.add({'id':60,'href':'/interview/docs/java/string-builder/','title':"StringBuilder",'content':"StringBuilder StringBuilder类也封装了一个字符数组，定义如下：\n char[] value; 与String不同，它不是final的，可以修改。另外，与String不同，字符数组中不一定所有位置都已经被使用，它有一个实例变量，表示数组中已经使用的字符个数，定义如下：\n int count; StringBuilder继承自AbstractStringBuilder，它的默认构造方法是：\n public StringBuilder() { super(16); } 调用父类的构造方法，父类对应的构造方法是：\n AbstractStringBuilder(int capacity) { value = new char[capacity]; } 也就是说，new StringBuilder()这句代码，内部会创建一个长度为16的字符数组，count的默认值为0。\nappend的实现  public AbstractStringBuilder append(String str) { if (str == null) str = \u0026quot;null\u0026quot;; int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this; } append会直接拷贝字符到内部的字符数组中，如果字符数组长度不够，会进行扩展，实际使用的长度用count体现。具体来说，ensureCapacityInternal(count+len)会确保数组的长度足以容纳新添加的字符，str.getChars会拷贝新添加的字符到字符数组中，count+=len会增加实际使用的长度。\nensureCapacityInternal的代码如下：\n private void ensureCapacityInternal(int minimumCapacity) { if (minimumCapacity - value.length \u0026gt; 0) expandCapacity(minimumCapacity); } 如果字符数组的长度小于需要的长度，则调用expandCapacity进行扩展，expandCapacity的代码是：\n void expandCapacity(int minimumCapacity) { int newCapacity = value.length * 2 + 2; if (newCapacity - minimumCapacity \u0026lt; 0) newCapacity = minimumCapacity; if (newCapacity \u0026lt; 0) { if (minimumCapacity \u0026lt; 0) throw new OutOfMemoryError(); newCapacity = Integer.MAX_VALUE; } value = Arrays.copyOf(value, newCapacity); } 扩展的逻辑是，分配一个足够长度的新数组，然后将原内容拷贝到这个新数组中，最后让内部的字符数组指向这个新数组，这个逻辑主要靠下面这句代码实现：\n value = Arrays.copyOf(value, newCapacity); toString实现 字符串构建完后，我们来看toString代码：\n public String toString() { return new String(value, 0, count); } "});index.add({'id':61,'href':'/interview/docs/java/concurrent/synchronized/','title':"Synchronized",'content':"Synchronized原理 基础 在多线程并发编程中 Synchronized 一直是元老级角色，很多人都会称呼它为重量级锁，但是随着 Java SE1.6 对 Synchronized 进行了各种优化，引入了 偏向锁 和 轻量级锁。所以在 Java SE1.6 里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁，但是偏向锁状态可以被重置为无锁状态（锁撤销）。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。\n   锁状态 优点 缺点 适用场景     偏向锁 加锁、解锁无额外消耗，和非同步方式近似 如果竞争线程多，会有额外锁撤销的消耗 基本没有线程竞争的场景   轻量级锁 竞争线程不会阻塞，使用自旋等待 如果长时间不能获取锁，会消耗CPU 少量线程竞争，且线程持有锁时间不长   重量级锁 竞争线程被阻塞，减少CPU空转 线程阻塞，响应时间长 很多线程竞争，锁持有时间长    Java中的每一个对象都可以作为锁。\n 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。  当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。\n锁的升级 目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。\n偏向锁 大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁是为了在只有一个线程执行同步块时提高性能。\n轻量级锁 这里解释下其中几个重要的步骤：\n 复制 Mark Word 到锁记录：拷贝对象头中的 Mark Word 到锁记录中。 更新 Mark Word 指针：拷贝成功后，虚拟机将使用 CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record 指针，并将 Lock Record 里的 owner 指针指向对象的 Mark Word。  重量级锁 在重量级锁的状态下， JVM 基于进入和退出 Monitor 对象来实现方法同步和代码块同步，Monitor 的引用存储在对象头中。\nMonitor 本身是依赖与操作系统的互斥锁（mutex lock）实现的。由于 JVM 线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一条线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此这种转换需要耗费很多的 CPU 时间。\n锁粗化 同步块的作用范围应该尽可能小，仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，缩短阻塞时间，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。 但是加锁解锁也需要消耗资源，如果存在一系列的连续加锁解锁操作，可能会导致不必要的性能损耗。 锁粗化就是JVM将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁，避免频繁的加锁解锁操作。\n锁消除 Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，经过逃逸分析，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间\n参考链接  不可不说的Java“锁”事 Threads and Locks 从jvm源码看 synchronized  "});index.add({'id':62,'href':'/interview/docs/basic/net/tcp/','title':"TCP",'content':"TCP TCP概述 TCP的特点  TCP是面向连接的传输层协议。 TCP连接是点对点的（套接字\u0026ndash;IP:Port到套接字）。 TCP提供可靠交付的服务。 TCP提供全双工通信。 面向字节流。  TCP与UDP的区别     TCP UDP     是否连接 面向连接 面向非连接   传输可靠性 可靠 不可靠   应用场合 传输大量数据 少量数据   速度 慢 快    基本概念   发送缓存和接受缓存：用来临时保存双向通信的数据。在发送时，应用程序将数据传送给TCP发送缓存后，就可以做自己的事情，TCP在合适的时候发送数据；在接受数据时，TCP把发送的数据放入缓存，上层应用在合适的时候读取缓存即可。\n  滑动窗口：TCP的滑动窗口以字节为单位，用3个指针进行表示。当窗口内连续报文段被确认收到后，可以将窗口向前滑动。窗口大小应小于等于缓存区的大小。\n  滑动窗口协议：只有在接收窗口向前滑动时（与此同时也发送了确认），发送窗口才有可能向前滑动。收发两端的窗口按照以上规律不断地向前滑动，因此这种协议又称为滑动窗口协议。\n 当发送窗口和接收窗口的大小都等于 1时，就是停止等待协议。\n  当发送窗口大于1，接收窗口等于1时，就是回退N步协议。\n  当发送窗口和接收窗口的大小均大于1时，就是选择重发协议。\n   TCP报文结构  源端口、目的端口：16位长。标识出远端和本地的端口号。 序列号（seq）：32位长  如果含有同步标识（SYN），则此为最初的序列号；第一个数据比特的序列码为本序列号加一 如果没有同步标识（SYN），则此为第一个数据比特的序列码   确认号（ack）：32位长。希望收到的下一个数据报的序列号，表明到序列号 N-1 为止的所有数据已经正确收到。 TCP协议数据报头长：4位长。表明TCP头中包含多少个 4字节 保留：置0 ACK：期望收到的数据的开始序列号。也即已经收到的数据的字节长度加1 PSH：表示是带有PUSH标志的数据。接收方因此请求数据报一到便可送往应用程序而不必等到缓冲区装满时才传送。 RST：用于复位由于主机崩溃或其它原因而出现的错误的连接。还可以用于拒绝非法的数据报或拒绝连接请求。 SYN：用于建立连接。 FIN：用于释放连接。 窗口大小（WIN）：16位长。窗口大小字段表示在确认了字节之后还可以发送多少个字节。 校验和（Checksum）：16位长。是为了确保高可靠性而设置的。它校验头部、数据和伪TCP头部之和。 紧急指针：URG=1时才有意义。 可选项：长度可变，最长40个字节。每个选项的开始是 1 字节的 kind 字段，说明选项的类型。  0：选项表结束（1字节） 1：无操作（1字节）用于选项字段之间的字边界对齐 2：MMS 最大报文段长度，通常在创建连接而设置 SYN 标志的数据包中指明这个选项，指明本端所能接收的最大长度的报文段。通常将 MSS 设置为（MTU-40）字节，携带 TCP 报文段的 IP 数据报的长度就不会超过 MTU（MTU最大长度为1518字节，最短为64字节），从而避免本机发生IP分片。只能出现在同步报文段中，否则将被忽略。 3：窗口扩大因子（4字节，wscale），取值 0-14 。用来把 TCP 的窗口的值左移的位数，使窗口值乘倍。只能出现在同步报文段中，否则将被忽略。 4：sackOK 发送端支持并同意使用SACK选项。 5：SACK 选择确认选项 8：时间戳 计算 RTT；用于处理TCP序号超过   \\(2^32\\)  的情况，又称为防止序号回绕（PAWS）。  发送端的时间戳（Timestamp） 时间戳回显应答（Timestamp Echo）       TCP最小长度为 20 个字节。\n 三次握手  第一次握手：建立连接时，客户端发送 SYN 包（seq=j）到服务器，并进入SYN_SENT状态，等待服务器确认。 第二次握手：服务器收到 SYN 包，必须确认客户的 SYN（ack=j+1），同时自己也发送一个 SYN 包（seq=k），即 SYN + ACK 包，此时服务器进入 SYN_RECV 状态； 第三次握手：客户端收到服务器的 SYN+ACK 包，向服务器发送确认包 ACK（ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。  内核对 TCP 的处理 Socket 是一个由 （源IP、源Port、目标IP、目标Port、协议） 组成的五元组，唯一标示一个 socket 连接。\nTCP 建立连接的整体流程：\n 服务器端在调用 listen 之后，内核会建立两个队列，SYN队列和ACCEPT队列，其中ACCPET队列的长度由backlog指定。 服务器端在调用 accpet 之后，将阻塞，等待 ACCPT 队列有元素。 客户端在调用 connect 之后，将开始发起 SYN 请求，请求与服务器建立连接，此时称为第一次握手。 服务器端在接受到 SYN 请求之后，把请求方放入 SYN 队列中，并给客户端回复一个确认帧 ACK ，此帧还会携带一个请求与客户端建立连接的请求标志，也就是 SYN ，这称为第二次握手 客户端收到 SYN+ACK 帧后， connect 返回，并发送确认建立连接帧 ACK 给服务器端。这称为第三次握手 服务器端收到 ACK 帧后，会把请求方从 SYN 队列中移出，放至 ACCEPT 队列中，而 accept 函数也等到了自己的资源，从阻塞中唤醒，从 ACCEPT 队列中取出请求方，重新建立一个新的 sockfd ，并返回。  在服务端如何分发多个连接的请求？\n由于 TCP/IP 协议栈是维护着一个接收和发送缓冲区的。在接收到来自客户端的数据包后，服务器端的 TCP/IP 协议栈应该会做如下处理：\n 如果收到的是请求连接的数据包，则传给监听着连接请求端口的 socetfd 套接字。 如果是已经建立过连接后的客户端数据包，则将数据放入接收缓冲区。这样，当服务器端需要读取指定客户端的数据时，则可以利用 socketfd_new 套接字通过 recv 或者 read 函数到缓冲区里面去取指定的数据（因为 socketfd_new 代表的 socket 对象记录了客户端IP和端口，因此可以鉴别）。  数据包如何找到相对应的 socket ，这个方法在 Linux Kernel 代码里也是有体现的：\nstatic inline struct sock *__inet_lookup(struct net *net, struct inet_hashinfo *hashinfo, const __be32 saddr, const __be16 sport, const __be32 daddr, const __be16 dport, const int dif) { u16 hnum = ntohs(dport); /* 先尝试查找处于连接成功的 socket */ struct sock *sk = __inet_lookup_established(net, hashinfo, saddr, sport, daddr, hnum, dif); /* 如果没有找到连接成功的socket，那么就去处于 listen 状态的 socket 查找 */ return sk ? : __inet_lookup_listener(net, hashinfo, daddr, hnum, dif); } 四次挥手  在Time_Wait阶段，主动端等待2*MSL时间，MSL建议为2分钟。\n 由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。\n 客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送（报文段4）。 服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1（报文段5）。和SYN一样，一个FIN将占用一个序号。 服务器B关闭与客户端A的连接，发送一个FIN给客户端A（报文段6）。 客户端A发回ACK报文确认，并将确认序号设置为收到序号加1（报文段7）   TCP采用四次挥手关闭连接如图所示为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？\n  这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。\n 数据传输 可靠传输 通常在每个 TCP 报文段中都有一对序号和确认号。TCP报文发送者称自己的字节流的编号为 序号 （sequence number），称接收到对方的字节流编号为 确认号 。TCP 报文的接收者为了确保可靠性，在接收到一定数量的连续字节流后才发送确认。这是对 TCP 的一种扩展，称为选择确认（Selective Acknowledgement）。选择确认使得 TCP 接收者可以对乱序到达的数据块进行确认。每一个字节传输过后，SN号都会递增1。\n通过使用序号和确认号，TCP 层可以把收到的报文段中的字节按正确的顺序交付给应用层。序号是 32 位的无符号数，在它增大到 \\(2^{32}-1\\)  时，便会回绕到 0。对于初始化序列号(ISN)的选择是 TCP 中关键的一个操作，它可以确保强壮性和安全性。\nTCP 协议使用序号标识每端发出的字节的顺序，从而另一端接收数据时可以重建顺序，无惧传输时的包的乱序交付或丢包。在发送第一个包时（SYN包），选择一个 随机数 作为序号的初值，以克制 TCP 序号预测攻击。\n发送确认包（Acks），携带了接收到的对方发来的字节流的编号，称为确认号，以告诉对方 已经成功接收的数据流的字节位置。Ack并不意味着数据已经交付了上层应用程序。可靠性通过发送方检测到丢失的传输数据并重传这些数据。包括 超时重传（Retransmission timeout，RTO）与 重复累计确认 （duplicate cumulative acknowledgements，DupAcks）。\n重复累计确认重传 如果一个包（不妨设它的序号是 100 ，即该包始于第 100 字节）丢失，接收方就不能确认这个包及其以后的包，因为采用了 累计ACK 。接收方在收到 100 以后的包时，发出对包含第 99 字节的包的确认。这种重复确认是包丢失的信号。发送方如果收到 3 次对同一个包的确认，就重传最后一个未被确认的包。阈值设为 3 被证实可以减少乱序包导致的无作用的重传（spurious retransmission）现象。**选择性确认（SACK）**的使用能明确反馈哪个包收到了，极大改善了TCP重传必要的包的能力。\n超时重传 发送方使用一个保守估计的时间作为收到数据包的确认的超时上限。如果超过这个上限仍未收到确认包，发送方将重传这个数据包。每当发送方收到确认包后，会重置这个重传定时器。典型地，定时器的值设定为 \\({\\text{smoothed RTT}}+\\max(G,4\\times {\\text{RTT variation}})\\)  其中 \\(G\\)  是时钟粒度。进一步，如果重传定时器被触发，仍然没有收到确认包，定时器的值将被设为前次值的二倍（直到特定阈值）。这可对抗 中间人攻击方式的拒绝服务攻击，这种攻击愚弄发送者重传很多次导致接受者被压垮。\n数据传输举例  发送方首先发送第一个包含序列号为1（可变化）和 1460 字节数据的 TCP 报文段给接收方。接收方以一个没有数据的 TCP 报文段来回复（只含报头），用确认号 1461 来表示已完全收到并请求下一个报文段。 发送方然后发送第二个包含序列号为 1461 ，长度为 1460 字节的数据的 TCP 报文段给接收方。正常情况下，接收方以一个没有数据的 TCP 报文段来回复，用确认号 2921（1461+1460）来表示已完全收到并请求下一个报文段。发送接收这样继续下去。 然而当这些数据包都是相连的情况下，接收方没有必要每一次都回应。比如，他收到第 1 到 5 条TCP报文段，只需回应第五条就行了。在例子中第3条TCP报文段被丢失了，所以尽管他收到了第 4 和 5 条，然而他只能回应第 2 条。 发送方在发送了第三条以后，没能收到回应，因此当时钟（timer）过时（expire）时，他重发第三条。（每次发送者发送一条TCP报文段后，都会再次启动一次时钟：RTT）。 这次第三条被成功接收，接收方可以直接确认第5条，因为4，5两条已收到。  流量控制 流量控制用来避免主机分组发送得过快而使接收方来不及完全收下，一般由接收方通告给发送方进行调控。这里是通过 滑动窗口机制 来实现的。接收方在 接收窗口 域指出还可接收的字节数量。发送方在没有新的确认包的情况下至多发送 接收窗口 允许的字节数量。接收方可修改 接收窗口 的值。TCP的窗口单位是字节，不是报文段。\n当接收方宣布接收窗口的值为 0，发送方停止进一步发送数据，开始了“保持定时器”（persist timer），以 避免因随后的修改接收窗口的数据包丢失使连接的双侧进入死锁 ，发送方无法发出数据直至收到接收方修改窗口的指示。当“保持定时器”到期时， TCP 发送方尝试恢复发送一个小的 ZWP 包（Zero Window Probe），期待接收方回复一个带着新的接收窗口大小的确认包。一般 ZWP 包会设置成 3 次，如果 3 次过后还是 0 的话，有的 TCP 实现就会发 RST 把链接断了。\n拥塞控制 防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素。\n慢开始和拥塞避免 发送方维持一个 拥塞窗口 cwnd 的状态变量，初始值一般为 \\(2\\times MSS\\)  。发送方让自己的发送窗口小于等于拥塞窗口。\n  慢开始：由小到大的指数增大拥塞窗口。首先将 cwnd 设置为一个最大报文段 MMS ，在收到一个对新的报文段的确认后，把拥塞窗口增加一个 MMS 。\n  拥塞避免：当慢开始到阈值（ssthresh）后，使用拥塞避免算法（ cwnd 每次加1 ）。当发现网络拥塞后，将 cwnd 置为1， ssthresh 置为 cwnd 的一半，再次执行慢开始。\n  快重传和快恢复   快重传：当接收方收到一个失序报文段后就立即发送重复确认而不要等到自己发送数据时捎带确认。当发送方连续收到三个重复确认时，只将拥塞窗口减半来跳过慢启动阶段，将 ssthresh 设为当前新的 cwnd 。\n  快恢复：与快重传结合使用。\n  在连续收到三个重复确认时，将 ssthresh 减半，这是为了防止网络拥塞。\n  由于发送方现在认为 网络很可能没有拥塞，于是接下来不执行慢开始，而是将 cwnd 值设置为 ssthresh 减半后的值，然后执行拥塞避免。\n    最大分段大小 最大分段大小 (MSS) 是在单个分段中 TCP 愿意接受的数据的字节数最大值。MSS应当足够小以避免IP分片，它会导致丢包或过多的重传。\n在 TCP 连接创建时，双端在 SYN 报文中用 MSS 选项宣布各自的 MSS ，这是从双端各自直接相连的数据链路层的最大传输单元(MTU)的尺寸减去固定的 IP 首部和 TCP 首部长度。以太网MTU为 1500 字节， MSS值可达 1460 字节。使用 IEEE 802.3 的 MTU 为 1492 字节，MSS 可达 1452 字节。\n如果目的IP地址为“非本地的”，MSS通常的默认值为 536（这个默认值允许 20 字节的 IP 首部和 20 字节的 TCP 首部以适合 576字节 IP 数据报）。此外，发送方可用传输路径 MTU 发现（RFC 1191）推导出从发送方到接收方的网络路径上的最小 MTU，以此动态调整 MSS 以避免网络 IP 分片。\nMSS 发布也被称作“MSS协商”（MSS negotiation）。严格讲，这并非是协商出来一个统一的MSS值，TCP 允许连接两端使用各自不同的MSS值。例如，这会发生在参与 TCP 连接的一台设备使用非常少的内存处理到来的 TCP 分组。\n选择确认 最初采取累计确认的 TCP 协议在丢包时效率很低。例如，假设通过10个分组发出了1万个字节的数据。如果第一个分组丢失，在纯粹的累计确认协议下，接收方不能说它成功收到了 1,000 到 9,999 字节，但未收到包含 0 到 999 字节的第一个分组。因而，发送方可能必须重传所有1万个字节。\n为此，TCP采取了 选择确认（selective acknowledgment，SACK） 选项。RFC 2018 对此定义为 允许接收方确认它成功收到的分组的不连续的块，以及基础 TCP 确认的成功收到最后连续字节序号。这种确认可以指出 SACK block，包含了已经成功收到的连续范围的开始与结束字节序号。在上述例子中，接收方可以发出 SACK 指出序号 1000 到 9999 ，发送方因此知道只需重发第一个分组(字节 0 到 999)。\nTCP 发送方会把乱序收包当作丢包，因此会重传乱序收到的包，导致连接的性能下降。重复SACK选项（duplicate-SACK option）是定义在RFC 2883中的SACK的一项扩展，可解决这一问题。接收方发出 D-SACK 指出没有丢包，接收方恢复到高传输率。 D-SACK 使用了 SACK 的第一个段来做标志：\n 如果 SACK 的第一个段的范围被 ACK 所覆盖，那么就是 D-SACK; 如果 SACK 的第一个段的范围被 SACK 的第二个段覆盖，那么就是 D-SACK   D-SACK旨在告诉发送端：收到了重复的数据，数据包没有丢，丢的是ACK包；\n SACK 选项并不是强制的。仅当双端都支持时才会被使用。 TCP 连接创建时会在 TCP 头中协商 SACK 细节。在 Linux下，可以通过 tcp_sack 参数打开 SACK 功能（Linux 2.4后默认打开）。Linux下的 tcp_dsack 参数用于开启D-SACK功能（Linux 2.4后默认打开）。选择确认也用于流控制传输协议 (SCTP)。\n"});index.add({'id':63,'href':'/interview/docs/java/concurrent/threadlocal/','title':"ThreadLocal",'content':"Threadlocal原理 ThreadLocal 为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。当使用 ThreadLocal 维护变量时，ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。\n每个线程中都保有一个ThreadLocalMap的成员变量，ThreadLocalMap 内部采用WeakReference数组保存，数组的key即为ThreadLocal 内部的Hash值。\n内存泄漏 ThreadLocalMap 使用 ThreadLocal 的弱引用作为 key ，如果一个 ThreadLocal 没有外部强引用来引用它，那么系统 GC 的时候，这个 ThreadLocal 势必会被回收，这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry ，就没有办法访问这些 key 为 null 的 Entry 的 value，如果当前线程再迟迟不结束的话，这些 key 为 null 的 Entry 的 value 就会一直存在一条强引用链：Thread Ref -\u0026gt; Thread -\u0026gt; ThreaLocalMap -\u0026gt; Entry -\u0026gt; value 永远无法回收，造成内存泄漏。\nstatic class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } 其实，ThreadLocalMap 的设计中已经考虑到这种情况，也加上了一些防护措施：在 ThreadLocal 的 get(),set(),remove()的时候都会清除线程 ThreadLocalMap 里所有 key 为 null 的 value\n"});index.add({'id':64,'href':'/interview/docs/java/concurrent/volatile/','title':"Volatile",'content':"Volatile原理 计算机内存模型 计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：\ni = i + 1;  当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后 CPU 执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。\n 这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核 CPU 中，每条线程可能运行于不同的 CPU 中，因此 每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。比如同时有两个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？\n可能出现这种情况：初始时，两个线程分别读取i的值存入各自所在的 CPU 的高速缓存当中，然后 线程1 进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。\n为了解决缓存不一致性问题，通常来说有以下两种解决方法：\n 通过在总线加LOCK#锁的方式 通过 缓存一致性协议   这两种方式都是硬件层面上提供的方式。\n 在早期的 CPU 当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为 CPU 和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他 CPU 对其他部件访问（如内存），从而使得只能有一个 CPU 能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。\n所以就出现了缓存一致性协议。最出名的就是 Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。\n##　Java内存模型\n在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。\nJava内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。\n在Java中，执行下面这个语句：\ni = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。那么Java语言本身对 原子性、可见性以及有序性提供了哪些保证呢？\n原子性  即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。\n 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i：请分析以下哪些操作是原子性操作：\nx = 10; //语句1 y = x; //语句2 x++; //语句3 x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。\n 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。  也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。\n从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。\n可见性  可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。\n 对于可见性，Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。\n另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。\n有序性  即程序执行的顺序按照代码的先后顺序执行。\n  指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。\n 处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。\n在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\n在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。\n另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则，若线程 A 和线程 B 满足 happens-before 关系，则线程 A 执行操作的结果对线程 B 是可见的。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。\n下面就来具体介绍下happens-before原则（先行发生原则）：\n 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始  对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。\n第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。\n第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。\n第四条规则实际上就是体现happens-before原则具备传递性。\n深入剖析Volatile关键字 Volatile 的语义 一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：\n 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的 禁止进行指令重排序  先看一段代码，假如线程1先执行，线程2后执行：\n//线程1 boolean stop = false; while(!stop){ doSomething(); } //线程2 stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。\n下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。\n那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。但是用volatile修饰之后就变得不一样了：\n 使用volatile关键字会强制将修改的值立即写入主存； 使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。  那么线程1读取到的就是最新的正确的值。\nVolatile与原子性 从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？\n下面看一个例子：\npublic class Test { public volatile int inc = 0; public void increase() { inc++; } public static void main(String[] args) { final Test test = new Test(); for(int i=0;i\u0026lt;10;i++){ new Thread(){ public void run() { for(int j=0;j\u0026lt;1000;j++) test.increase(); }; }.start(); } while(Thread.activeCount()\u0026gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); } } 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。\n这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。\n在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：\n假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。\n根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。解决的方法也就是对提供原子性的自增操作即可。\n在Java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的 CMPXCHG 指令实现的，而处理器执行 CMPXCHG 指令是一个原子性操作。\nVolatile与有序性 在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。volatile关键字禁止指令重排序有两层意思：\n 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见，在其后面的操作肯定还没有进行； 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。  可能上面说的比较绕，举个简单的例子：\n//x、y为非volatile变量 //flag为volatile变量 x = 2; //语句1 y = 0; //语句2 flag = true; //语句3 x = 4; //语句4 y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。\n并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。\nVolatile的原理和实现机制 前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。下面这段话摘自《深入理解Java虚拟机》：\n 观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令\n lock前缀指令实际上相当于一个 内存屏障（也成内存栅栏），内存屏障会提供3个功能：\n 它 确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 它会 强制将对缓存的修改操作立即写入主存； 如果是写操作，它会导致其他CPU中对应的缓存行无效。  "});index.add({'id':65,'href':'/interview/docs/architecture/distributed/zk/','title':"Zookeeper",'content':"Zookeeper  ZK 不是解决分布式问题的银弹\n 分布式应用 分布式应用可以在给定时间（同时）在网络中的多个系统上运行，通过协调它们以快速有效的方式完成特定任务。通常来说，对于复杂而耗时的任务，非分布式应用（运行在单个系统中）需要几个小时才能完成，而分布式应用通过使用所有系统涉及的计算能力可以在几分钟内完成。\n通过将分布式应用配置为在更多系统上运行，可以进一步减少完成任务的时间。分布式应用正在运行的一组系统称为 集群，而在集群中运行的每台机器被称为 节点。\n分布式应用的优点  可靠性：单个或几个系统的故障不会使整个系统出现故障。 可扩展性：可以在需要时增加性能，通过添加更多机器，在应用程序配置中进行微小的更改，而不会有停机时间。 透明性：隐藏系统的复杂性，并将其显示为单个实体/应用程序。  分布式应用的挑战  竞争条件：两个或多个机器尝试执行特定任务，实际上只需在任意给定时间由单个机器完成。例如，共享资源只能在任意给定时间由单个机器修改。 死锁：两个或多个操作等待彼此无限期完成。 不一致：数据的部分失败。  ZooKeeper基础 Apache ZooKeeper是由集群（节点组）使用的一种服务，用于在自身之间协调，并通过稳健的同步技术维护共享数据。ZooKeeper本身是一个分布式应用程序，为写入分布式应用程序提供服务。\nZooKeeper 的好处：\n 简单的分布式协调过程 同步：服务器进程之间的相互排斥和协作。 有序性 序列化：根据特定规则对数据进行编码(Jute)。 可靠性 原子性：数据转移完全成功或完全失败，但没有事务是部分的。  架构 一个 ZooKeeper 集群通常由一组机器组成，一般 3 台以上就可以组成一个可用的 ZooKeeper 集群了。组成 ZooKeeper 集群的每台机器都会在内存中维护当前的服务器状态，并且每台机器之间都会互相保持通信。 ZooKeeper 本身就是一个 复制和分布式 应用程序，其目的作为服务运行，类似于我们运行 DNS 或任何其他集中式服务的方式。\n ZK 集群 半数以上存活 即可用\n ZooKeeper 的客户端程序会选择和集群中的任意一台服务器创建一个 TCP 连接，而且一旦客户端和服务器断开连接，客户端就会自动连接到集群中的其他服务器。\n   部分 描述     Client（客户端） 客户端是我们的分布式应用集群中的一个节点，从服务器访问信息。对于特定的时间间隔，每个客户端向服务器发送消息以使服务器知道客户端是活跃的。类似地，当客户端连接时，服务器发送确认码。如果连接的服务器没有响应，客户端会自动将消息重定向到另一个服务器。   Server（服务器） 服务器，我们的ZooKeeper总体中的一个节点，为客户端提供所有的服务。向客户端发送确认码以告知服务器是活跃的。   ZooKeeper Service ZooKeeper服务器组。形成 Service 所需的最小节点数为3。   Leader 服务器节点，如果任何连接的节点失败，则执行自动恢复。Leader在服务启动时被选举。   Follower 用于接受客户端请求并向客户端返回结果，在选主过程中参与投票   Observer 接受客户端连接，将写请求转发给leader，但 observer 不参与 投票过程，只同步 leader 的状态， observer 的目的是为了扩展系统，提高读取速度    数据模型 到znode是一个标准的文件系统，层次结构很像一棵树。 需要注意的一些要点如下：\n 根节点有一个名为 /zoo 的子节点，它又有三个 znode 。 ZooKeeper 树中的每个 znode 都由一个路径标识，路径元素由/分隔。 这些节点被称为数据寄存器，因为它们可以存储数据。 因此，一个 znode 可以有子节点以及与之相关的数据。 这与文件系统可以把文件作为路径很类似。  znode 中的数据通常以字节格式存储，每个 znode 中的最大数据大小不超过1 MB。 ZooKeeper 是为协调而设计的，几乎所有形式的协调数据都比较小， 因此，对数据大小的限制是强制的。\n与文件系统中的文件一样， znode 维护一个 stat 结构，其中包含数据更改的 版本号 以及随更改相关的时间戳而更改的 访问控制列表（ACL）。 只要 znode 的数据发生变化，版本号就会增加。 ZooKeeper 使用版本号以及相关的时间戳来验证它的核心内缓存。 znode 版本号还允许客户端通过 ZooKeeper API 更新或删除特定的 znode。 如果指定的版本号与 znode 的当前版本不匹配，则操作失败。 但是，执行 znode 更新或删除操作时，可以通过指定 0 作为版本号来覆盖。\nZnode  persistent：即使在创建该特定znode的客户端断开连接后，持久节点仍然存在。默认情况下，除非另有说明，否则所有znode都是持久的。 ephemeral：客户端活跃时，临时节点就是有效的。当客户端与 ZooKeeper 集合断开连接时，临时节点会自动删除。因此，只有临时节点不允许有子节点。如果临时节点被删除，则下一个合适的节点将填充其位置。临时节点在 leader 选举中起着重要作用。 sequential：顺序节点可以是持久的或临时的。当一个新的 znode 被创建为一个顺序节点时，ZooKeeper 通过将 10位 的序列号附加到原始名称来设置 znode 的路径。例如，如果将具有路径 /myapp 的znode创建为顺序节点，则ZooKeeper会将路径更改为 /myapp0000000001 ，并将下一个序列号设置为0000000002。如果两个顺序节点是同时创建的，那么 ZooKeeper 不会对每个znode使用相同的数字。顺序节点在锁定和同步中起重要作用。  Sessions 会话对于 ZooKeeper 的操作非常重要。会话中的请求按 FIFO 顺序执行。一旦客户端连接到服务器，将建立会话并向客户端分配 会话ID 。\n客户端 以特定的时间间隔发送心跳 以保持会话有效。如果 ZooKeeper 集合在超过服务器开启时指定的期间（会话超时）都没有从客户端接收到心跳，则它会判定客户端死机。\n会话超时通常以毫秒为单位。当会话由于任何原因结束时，在该会话期间创建的临时节点也会被删除。\nWatcher ZooKeeper 的设计是一种可伸缩的、健壮的集中式服务。在客户端访问此类服务时，常见的设计模式是通过轮询或拉式（pull）模型。当在大型和复杂的分布式系统中实现时，拉模型常常会受到可伸缩性问题的影响。为了解决这个问题，ZooKeeper设计了一种机制，客户端可以从 ZooKeeper 服务中获取通知。客户端接收到这个消息通知之后，需要主动到服务端获取最新的数据。\n客户可以使用 ZooKeeper 服务注册与 znode 相关的任何更改。 这种注册被称为在 ZooKeeper 术语中的 znode 上设置 watch。 监视允许客户以任何方式更改 znode 时收到通知。 Watcher 是一次性操作，这意味着它只触发一个通知。 要继续接收通知，客户必须在收到每个事件通知后重新注册一个监视。\n监视触发：\n 对 znode 数据的任何更改，例如使用 setData 操作将新数据写入 znode 的数据字段时。 对 znode 的子节点的任何更改。 例如，一个 znode 的子节点被删除。 正在创建或删除的 znode ，如果将新的 znode 添加到路径中或现有的 znode 被删除，则可能发生这种情况。  同样，ZooKeeper 针对监视和通知声明以下保证：\n ZooKeeper 确保监视始终以先进先出（FIFO）方式排序，并且通知总是按顺序发送 在对同一个 znode 进行任何其他更改之前，监视会将通知发送给客户端 监视事件的顺序是按照 ZooKeeper 服务的更新顺序排列的  Zookeeper 工作流程 一旦 ZooKeeper 集合启动，它将等待客户端连接。客户端将连接到 ZooKeeper 集合中的一个节点。它可以是 leader 或 follower 节点。一旦客户端被连接，节点将向特定客户端分配 会话ID 并向该客户端发送确认。如果客户端没有收到确认，它将尝试连接 ZooKeeper 集合中的另一个节点。 一旦连接到节点，客户端将以有规律的间隔向节点发送 心跳，以确保连接不会丢失。\n  如果客户端想要读取特定的znode，它将会向具有znode路径的节点发送读取请求，并且节点通过从其自己的数据库获取来返回所请求的znode。为此，在ZooKeeper集合中读取速度很快。\n  如果客户端想要将数据存储在ZooKeeper集合中，则会将 znode 路径和数据发送到服务器。连接的服务器将该请求转发给 leader，然后leader将向所有的follower重新发出写入请求。如果只有大部分节点成功响应，而写入请求成功，则成功返回代码将被发送到客户端。 否则，写入请求失败。绝大多数节点被称为 Quorum 。\n  ZooKeeper Service 节点数量的影响  如果我们有 单个节点，则当该节点故障时，ZooKeeper Service 将故障。即“单点故障\u0026rdquo;，不建议在生产环境中使用。 如果我们有 两个节点 而一个节点故障，我们没有占多数，ZooKeeper Service 故障，因为两个中的一个不是多数。 如果我们有 三个节点 而一个节点故障，那么我们有大多数，因此，这是 最低要求。ZooKeeper集合在实际生产环境中必须至少有三个节点。 如果我们有 四个节点 而两个节点故障，它将再次故障。类似于有三个节点，额外节点不用于任何目的，因此，最好添加奇数的节点，例如 3，5，7。  我们知道写入过程比 ZooKeeper 集合中的读取过程要耗时，因为 所有节点都需要在数据库中写入相同的数据。因此，对于平衡的环境拥有较少数量（例如3，5，7）的节点比拥有大量的节点要好。\nZAB 协议 ZAB 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。\n 读取时：客户端连接 zk 的任一节点，节点直接拿出自己对应的数据返回，这时该节点扮演 Observer 角色； 写入时：客户端的任一提交都会由 Leader 去广播给所有的节点，有半数以上的节点写入成功即视为写入成功；  ZAB 的所有动作都是节点们通过协议同步的。在 ZAB 协议的事务编号 Zxid 设计中， Zxid 是一个 64 位的数字，其中低 32 位是一个简单的单调递增的计数器，针对客户端每一个事务请求，计数器加 1；而高 32 位则代表 Leader 周期 epoch 的编号，每个当选产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务的 ZXID ，并从中读取 epoch 值，然后加 1，以此作为新的 epoch，并将低 32 位从 0 开始计数。\nepoch 可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所以每次改朝换代，leader 变更之后，都会在前一个年代的基础上加 1。这样就算旧的 leader 崩溃恢复之后，也没有人听他的了，因为 follower 只听从当前年代的 leader 的命令。\n消息广播 在 zookeeper 集群中，数据副本的传递策略就是采用消息广播模式。 zookeeper 中数据副本的同步方式与二段提交相似。二段提交要求协调者必须等到所有的参与者全部反馈 ACK 确认消息后，再发送 commit 消息。要求所有的参与者要么全部成功，要么全部失败，因此二段提交会产生严重的阻塞问题。 Zab 协议中 Leader 等待半数以上的Follower成功反馈即可，不需要收到全部Follower反馈。\n消息广播具体步骤\n 客户端发起一个写操作请求。 Leader 服务器将客户端的请求转化为事务 Proposal 提案，同时为每个 Proposal 分配一个全局的ID，即 zxid。 Leader 服务器为每个 Follower 服务器分配一个单独的队列，然后将需要广播的 Proposal 依次放到队列中取，并且根据 FIFO 策略进行消息发送。 Follower 接收到 Proposal 后，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向 Leader 反馈一个 Ack 响应消息。 Leader 接收到超过半数以上 Follower 的 Ack 响应消息后，即认为消息发送成功，可以发送 commit 消息。 Leader 向所有 Follower 广播 commit 消息，同时自身也会完成事务提交。Follower 接收到 commit 消息后，会将上一条事务提交。  崩溃恢复保证数据一致性 主从架构下，leader 崩溃，为了保证数据一致性，会在选出新leader后进入恢复阶段，新 leader 具有所有已经提交的提议，因此它会保证让 followers 同步已经提交的提议，丢弃未提交的提议（以 leader 的记录为准）\n选举 下面任何一种情况，都会触发 Leader 选举：\n 启动时，集群服务器刚启动 运行时，Leader 崩溃  服务器的状态流转：\nLeader 选举过程，本质就是 广播优先级消息 的过程，选出 数据最新的服务节点，选出优先级最高的服务节点，基本步骤：\n 各个服务器节点，广播自己的优先级标识 (sid，zxid) 服务器节点收到其他广播消息后，跟自己的优先级对比，自己优先级低，则变更当前节点投票的优先级(sid，zxid) ，并广播变更后的结果 当任意一个服务器节点收到的投票数，超过了法定数量(quorum)，则，升级为 Leader，并广播结果。    由于网络延时，节点得不到足够多广播信息时，会做出错误的投票判断，纠正过程更耗时 选举过程中，服务器节点会等待一定时间，再广播投票信息，时间间隔一般设定为 200 ms 上面 Leader 选举，采取事件触发 Push 方式 广播消息，称为 快速 Leader 选举，因为之前的 Leader 选举，采用 Pull 方式，每隔 1s 拉取一次。   应用场景 发布订阅 通过 Zookeeper 进行数据的发布与订阅其实可以说是它提供的最基本功能，它能够允许多个客户端同时订阅某一个节点的变更并在变更发生时执行我们预先设置好的回调函数，在运行时改变服务的配置和行为\n命名服务 除了实现服务配置数据的发布与订阅功能，Zookeeper 还能帮助分布式系统实现命名服务，在每一个分布式系统中，客户端应用都有根据指定名字获取资源、服务器地址的需求，在这时就要求整个集群中的全部服务有着唯一的名字。\n在大型分布式系统中，有两件事情非常常见，一是不同服务之间的可能拥有相同的名字，另一个是同一个服务可能会在集群中部署很多的节点，Zookeeper 就可以通过文件系统和顺序节点解决这两个问题。\n协调分布式事务 Zookeeper 的另一个作用就是担任分布式事务中的协调者角色，在之前介绍 分布式事务 的文章中我们曾经介绍过分布式事务本质上都是通过 2PC 来实现的，在两阶段提交中就需要一个协调者负责协调分布式事务的执行。\n所有的事务参与者会向当前节点中写入提交或者终止，一旦当前的节点改变了事务的状态，其他节点就会得到通知，如果出现一个写入终止的节点，所有的节点就会回滚对分布式事务进行回滚。\n分布式锁 在数据库中，锁的概念其实是非常重要的，常见的关系型数据库就会对排他锁和共享锁进行支持，而 Zookeeper 提供的 API 也可以让我们非常简单的实现分布式锁。\n作为分布式协调服务，Zookeeper 的应用场景非常广泛，不仅能够用于服务配置的下发、命名服务、协调分布式事务以及分布式锁，还能够用来实现微服务治理中的服务注册以及发现等功能，这些其实都源于 Zookeeper 能够提供高可用的分布式协调服务，能够为客户端提供分布式一致性的支持。\nZooKeeper 的缺陷 zookeeper 不是为高可用性设计的  由于要跨机房容灾，很多系统实际上是需要跨机房部署的。出于性价比的考虑我们通常会让多个机房同时工作，而不会搭建N倍的冗余。也就是说单个机房肯定撑不住全流量（你能设想谷歌在全球只剩下一个机房在干活吗）。由于 zookeeper 集群只能有一个 master，因此一旦机房之间连接出现故障，zookeeper master 就只能照顾一个机房，其他机房运行的业务模块由于没有 master 都只能停掉。于是所有流量集中到有 master 的那个机房，于是系统 crash。 即使是在同一个机房里面，由于网段的不同，在调整机房交换机的时候偶尔也会发生网段隔离的情况。实际上机房每个月基本上都会发生短暂的网络隔离之类的子网段调整。在那个时刻 zookeeper 将处于不可用状态。如果整个业务系统基于 zookeeper （比如要求每个业务请求都先去 zookeeper 获取业务系统的master地址），则系统的可用性将非常脆弱。 由于 zookeeper 对于网络隔离的极度敏感，导致 zookeeper 对于网络的任何风吹草动都会做出激烈反应。这使得 zookeeper 的‘不可用’时间比较多，我们不能让 zookeeper 的‘不可用’，变成系统的不可用。  zookeeper 的选举过程速度很慢  这是一个很难从理论分析上看到的弱点，但是你一旦遇到就会痛不欲生。 前面我们已经说过，网络实际上常常是会出现隔离等不完整状态的，而 zookeeper 对那种情况非常敏感。一旦出现网络隔离， zookeeper 就要发起选举流程。 zookeeper 的选举流程通常耗时 30 到 120 秒，期间 zookeeper 由于没有master，都是不可用的。 对于网络里面偶尔出现的，比如半秒一秒的网络隔离，zookeeper 会由于选举过程，而把不可用时间放大几十倍。  zookeeper 的性能是有限的  典型的 zookeeper 的 tps(transaction peer secondes) 大概是一万多，无法覆盖系统内部每天动辄几十亿次的调用。因此每次请求都去 zookeeper 获取业务系统 master 信息是不可能的。 因此 zookeeper 的 client 必须自己缓存业务系统的 master 地址。 因此 zookeeper 提供的‘强一致性’实际上是不可用的。如果我们需要强一致性，还需要其他机制来进行保障：比如用自动化脚本把业务系统的 old master 给 kill 掉，但是那会有很多陷阱。  zookeeper 无法进行有效的权限控制  zookeeper 的权限控制非常薄弱 在大型的复杂系统里面，使用 zookeeper 必须自己再额外的开发一套权限控制系统，通过那套权限控制系统再访问 zookeeper 额外的权限控制系统不但增加了系统复杂性和维护成本，而且降低了系统的总体性能  即使有了 zookeeper 也很难避免业务系统的数据不一致  前面已经讨论过了，由于 zookeeper 的性能限制，我们无法让每次系统内部调用都走 zookeeper ，因此总有某些时刻，业务系统会存在两个 master（业务系统 client 那边缓存的业务系统 master 信息是定时从 zookeeper 更新的，因此会有更新不同步的问题）。 如果要在业务系统 client 的 master 信息不一致的情况下，仍要保持系统的数据一致性的方法是 先 kill 掉老 master ，再在 zookeeper 上更新 master 信息。但是在是否要 kill current master 这个问题上，程序是无法完全自动决定的（因为网络隔离的时候zookeeper已经不可用了，自动脚本没有全局信息，不管怎么做都可能是错的，什么都不做也可能是错的。当网络故障的时候，只有运维人员才有全局信息，程序是无法接电话得知其他机房的情况的）。因此系统无法自动的保障数据一致性，必须要人工介入。而人工介入的典型时间是半个小时以上，我们不能让系统这么长时间不可用。因此我们必须在某个方向上进行妥协，最常见的妥协方式是放弃 ‘强一致性’，而接受‘最终一致性’。 如果我们需要人工介入才能保证‘可靠的强一致性’，那么 zookeeper 的价值就大打折扣。  Zookeeper 并不保证读取的是最新数据 ZooKeeper 并不保证在每个实例中，两个不同的客户端将具有相同的 ZooKeeper 数据的视图。由于诸如网络延迟的因素，一个客户端可以在另一客户端被通知该改变之前执行更新，考虑两个客户端A和B的场景。如果客户端A将 /a 的值从 0 设置为 1 ，客户端B读取 /a ，客户端 B 可以读取旧值 0，这取决于它连接到的服务器。如果客户端A 和客户端B 读取相同的值很重要，则客户端B应该在执行读取之前从 ZooKeeper API 方法调用 sync() 方法。\n对于 Zookeeper 来说，它实现了A可用性、P分区容错性、C中的写入强一致性，丧失的是C中的读取一致性。\n我们能做什么  我们或者选择人工介入的强一致性，或者选择程序自动化进行的弱一致性。需要进行取舍。 最终一致性甚至未必是程序来做的，有时候人工修正数据反而在灵活、可靠、低成本上有优势。这需要权衡。 不要迷信zookeeper，有时候不妨考虑一下主备数据库。数据库自带权限控制，用起来比zookeeper方便多了。 zookeeper 比较有价值的东西也许是内容变化的时候，可以阻塞回调的方式通知所有在线的 client 实时更新信息，但这个功能用处不大。  FAQ 这段时间来，也在和公司里的一些同学交流使用zk的心得，整理了一些常见的zookeeper问题。这个页面的目标是解答一些zk常见的使用问题，同时也让大家明确zk不能干什么。页面会一直更新。\n客户端对 ServerList 的轮询机制是什么 随机，客户端在初始化( new ZooKeeper(String connectString, int sessionTimeout, Watcher watcher) )的过程中，将所有 Server 保存在一个 List 中，然后随机打散，形成一个环。之后从 0 号位开始一个一个使用。两个注意点：\n Server地址能够重复配置，这样能够弥补客户端无法设置Server权重的缺陷，但是也会加大风险。（比如: 192.168.1.1:2181,192.168.1.1:2181,192.168.1.2:2181). 如果客户端在进行 Server 切换过程中耗时过长，那么将会收到 SESSION_EXPIRED . 这也是上面第1点中的加大风险之处。  客户端如何正确处理 CONNECTIONLOSS (连接断开) 和 SESSIONEXPIRED (Session 过期)两类连接异常 在 ZooKeeper 中，服务器和客户端之间维持的是一个 长连接，在 SESSION_TIMEOUT 时间内，服务器会确定客户端是否正常连接(客户端会定时向服务器发送 heart_beat ),服务器重置下次 SESSION_TIMEOUT 时间。因此，在正常情况下， Session 一直有效，并且 zk 集群所有机器上都保存这个 Session 信息。在出现问题情况下，客户端与服务器之间连接断了（客户端所连接的那台zk机器挂了，或是其它原因的网络闪断），这个时候客户端会主动在地址列表（初始化的时候传入构造方法的那个参数 connectString ）中选择新的地址进行连接。\n好了，上面基本就是服务器与客户端之间维持长连接的过程了。在这个过程中，用户可能会看到两类异常 CONNECTIONLOSS (连接断开) 和 SESSIONEXPIRED (Session 过期)。\n CONNECTIONLOSS ：应用在进行操作A时，发生了 CONNECTIONLOSS ，此时用户不需要关心我的会话是否可用，应用所要做的就是等待客户端帮我们自动连接上新的 zk 机器，一旦成功连接上新的 zk 机器后，确认刚刚的操作A是否执行成功了。 SESSIONEXPIRED ：这个通常是zk客户端与服务器的连接断了，试图连接上新的 zk 机器，这个过程如果耗时过长，超过 SESSION_TIMEOUT 后还没有成功连接上服务器，那么服务器认为这个 session 已经结束了（服务器无法确认是因为其它异常原因还是客户端主动结束会话），开始清除和这个会话有关的信息，包括这个会话创建的临时节点和注册的 Watcher 。在这之后，客户端重新连接上了服务器在，但是很不幸，服务器会告诉客户端 SESSIONEXPIRED 。此时客户端要做的事情就看应用的复杂情况了，总之，要重新实例 zookeeper 对象，重新操作所有临时数据（包括临时节点和注册 Watcher ）。  一个客户端修改了某个节点的数据，其它客户端能够马上获取到这个最新数据吗 ZooKeeper 不能确保任何客户端能够获取（即 Read Request ）到一样的数据，除非客户端自己要求：方法是客户端在获取数据之前调用org.apache.zookeeper.AsyncCallback.VoidCallback, java.lang.Object) sync.\n通常情况下（这里所说的通常情况满足：1. 对获取的数据是否是最新版本不敏感，2. 一个客户端修改了数据，其它客户端需要不需要立即能够获取最新），可以不关心这点。\n在其它情况下，最清晰的场景是这样：ZK 客户端 A 对 /my_test 的内容从 v1-\u0026gt;v2, 但是 ZK 客户端 B 对 /my_test 的内容获取，依然得到的是 v1. 请注意，这个是实际存在的现象，当然延时很短。解决的方法是客户端B先调用 sync(), 再调用 getData().\nZK为什么不提供一个永久性的Watcher注册机制 不支持用持久Watcher的原因很简单，ZK无法保证性能。\n使用watch需要注意的几点  Watches 通知是一次性的，必须重复注册. 发生 CONNECTIONLOSS 之后，只要在 session_timeout 之内再次连接上（即不发生 SESSIONEXPIRED ），那么这个连接注册的 watches 依然在。 节点数据的版本变化会触发 NodeDataChanged ，注意，这里特意说明了是版本变化。存在这样的情况，只要成功执行了 setData()方法，无论内容是否和之前一致，都会触发 NodeDataChanged 。 对某个节点注册了 watch ，但是节点被删除了，那么注册在这个节点上的 watches 都会被移除。 同一个 zk 客户端对某一个节点注册相同的 watch ，只会收到一次通知。 Watcher 对象只会保存在客户端，不会传递到服务端。  我能否收到每次节点变化的通知 如果节点数据的更新频率很高的话，不能。\n原因在于：当一次数据修改，通知客户端，客户端再次注册 watch ，在这个过程中，可能数据已经发生了许多次数据修改，因此，千万不要做这样的测试：\u0026ldquo;数据被修改了n次，一定会收到n次通知\u0026quot;来测试 server 是否正常工作。\n能为临时节点创建子节点吗 不能。\n是否可以拒绝单个IP对ZK的访问,操作 ZK 本身不提供这样的功能，它仅仅提供了对单个 IP 的连接数的限制。你可以通过修改 iptables 来实现对单个 ip 的限制。\n在[getChildren(String path, boolean watch)]注册对节点子节点的变化，那么子节点的子节点变化能通知吗 不能\n创建的临时节点什么时候会被删除，是连接一断就删除吗？延时是多少？ 连接断了之后，ZK 不会马上移除临时数据，只有当 SESSIONEXPIRED 之后，才会把这个会话建立的临时数据移除。因此，用户需要谨慎设置 Session_TimeOut\nzookeeper是否支持动态进行机器扩容？如果目前不支持，那么要如何扩容呢？ 3.4.3版本的zookeeper，还不支持这个功能，在3.5.0版本开始，支持动态加机器了。\nZooKeeper集群中个服务器之间是怎样通信的？ Leader服务器会和每一个 Follower/Observer 服务器都建立TCP连接，同时为每个 F/O 都创建一个叫做 LearnerHandler 的实体。LearnerHandler 主要负责 Leader 和 F/O 之间的网络通讯，包括数据同步，请求转发和 Proposal 提议的投票等。Leader 服务器保存了所有 F/O 的 LearnerHandler 。\nzookeeper是否会自动进行日志清理？如果进行日志清理？ zk自己不会进行日志清理，需要运维人员进行日志清理\n参考文档  ZooKeeper FAQ Apache ZooKeeper数据模型 Zookeeper并不保证读取的是最新数据 详解分布式协调服务 ZooKeeper ZooKeeper 架构 阿里巴巴为什么不用ZooKeeper 做服务发现？ ZooKeeper 技术内幕：Leader 选举  "});index.add({'id':66,'href':'/interview/docs/leetcode/threeSum/','title':"三数之和",'content':"头条重点\n题目 给定一个包含 n 个整数的数组 nums ，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\n例如, 给定数组 nums = [-1, 0, 1, 2, -1, -4]， 满足要求的三元组集合为： [ [-1, 0, 1], [-1, -1, 2] ] 解题思路  将数组排序 固定一位数，然后通过两个指针对撞，寻找总和为 0 的三个数  public static List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; threeSum(int[] nums) { if (nums.length \u0026lt; 3) { return Collections.emptyList(); } Set\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res = new HashSet\u0026lt;\u0026gt;(); Arrays.sort(nums); int zCount = 0; for (int num : nums) { if (num == 0) { zCount++; } } for (int i = 0; i \u0026lt; nums.length \u0026amp;\u0026amp; nums[i] \u0026lt; 0; i++) { int first = nums[i]; int j = i + 1; int k = nums.length - 1; while (j \u0026lt; k) { int t = nums[j] + nums[k] + first; if (t == 0) { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(first); list.add(nums[j]); list.add(nums[k]); res.add(list); j++; k--; } else if (t \u0026gt; 0) { k--; } else { j++; } } } if (zCount \u0026gt;= 3) { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(0); list.add(0); list.add(0); res.add(list); } return new ArrayList\u0026lt;\u0026gt;(res); } "});index.add({'id':67,'href':'/interview/docs/offer/Add/','title':"不用加减乘除做加法",'content':"题目 牛客网\n写一个函数，求两个整数之和，要求在函数体内不得使用+、-、*、/四则运算符号。\n解题思路  将加法分解成两步 两个数不计算进位相加得到 sum，计算进位 carry 再将进位加上：sum = sum + carry 直到没有进位为止  public int Add(int num1, int num2) { int sum, carry; do { sum = num1 ^ num2; carry = (num1 \u0026amp; num2) \u0026lt;\u0026lt; 1; num1 = sum; num2 = carry; } while (num2 != 0); return sum; } "});index.add({'id':68,'href':'/interview/docs/offer/GetUglyNumber/','title':"丑数",'content':"牛客网\n把只包含质因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含质因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。\n解题思路  通过保存已有丑数的方式，用空间换时间 对于已有丑数   \\(M\\)  ，那么下一个丑数 \\(M=\\min(M_{2}\\times2,M_{3}\\times3,M_{5}\\times5)\\)    \\(M_{max}\\)  是目前最大的丑数，那么 \\(M_{2}\\)  是已有丑数中 \\(M_{2}\\times2\\)  第一个大于 \\(M_{max}\\)  的丑数  public int GetUglyNumber_Solution(int index) { if (index == 0) { return 0; } if (index == 1) { return 1; } ArrayList\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(index); list.add(1); int preIndex2 = 0; int preIndex3 = 0; int preIndex5 = 0; for (int i = 0; i \u0026lt; index; i++) { int next2 = list.get(preIndex2) * 2; int next3 = list.get(preIndex3) * 3; int next5 = list.get(preIndex5) * 5; int nextV = Math.min(Math.min(next2, next3), next5); list.add(nextV); while (preIndex2 \u0026lt; list.size() - 1 \u0026amp;\u0026amp; list.get(preIndex2) * 2 \u0026lt;= nextV) preIndex2++; while (preIndex3 \u0026lt; list.size() - 1 \u0026amp;\u0026amp; list.get(preIndex3) * 3 \u0026lt;= nextV) preIndex3++; while (preIndex5 \u0026lt; list.size() - 1 \u0026amp;\u0026amp; list.get(preIndex5) * 5 \u0026lt;= nextV) preIndex5++; } return list.get(index - 1); } "});index.add({'id':69,'href':'/interview/docs/offer/FindFirstCommonNode/','title':"两个链表的第一个公共结点",'content':"题目 牛客网\n输入两个链表，找出它们的第一个公共结点。\n解决思路 空间复杂度 O(n) 的算法  使用辅助容器，保存第一个链表的所有元素 遍历第二个链表，并对比当前节点是否在辅助容器中  /** * 空间 O(n) * * @param pHead1 * @param pHead2 * @return */ public ListNode FindFirstCommonNode_1(ListNode pHead1, ListNode pHead2) { Set\u0026lt;ListNode\u0026gt; node1s = new HashSet\u0026lt;\u0026gt;(); while (pHead1 != null) { node1s.add(pHead1); pHead1 = pHead1.next; } while (pHead2 != null) { if (node1s.contains(pHead2)) { return pHead2; } pHead2 = pHead2.next; } return null; } 空间复杂度 O(1) 的算法  由于两个链表有可能不一样长，首先通过遍历找到他们的长度 移动较长的那个链表，使得两个链表长度一致 同步遍历两个链表   原理：如果两个链表相交，那么它们一定有相同的尾节点\n /** * 空间 O(1) * * @param pHead1 * @param pHead2 * @return */ public ListNode FindFirstCommonNode_2(ListNode pHead1, ListNode pHead2) { int len1 = 0, len2 = 0; ListNode cursor1 = pHead1, cursor2 = pHead2; while (cursor1 != null) { cursor1 = cursor1.next; len1++; } while (cursor2 != null) { cursor2 = cursor2.next; len2++; } cursor1 = pHead1; cursor2 = pHead2; if (len1 \u0026gt; len2) { int i = len1; while (i != len2) { cursor1 = cursor1.next; i--; } } else if (len1 \u0026lt; len2) { int i = len2; while (i != len1) { cursor2 = cursor2.next; i--; } } while (cursor1 != null \u0026amp;\u0026amp; cursor2 != null) { if (cursor1 == cursor2) { return cursor1; } cursor1 = cursor1.next; cursor2 = cursor2.next; } return null; } "});index.add({'id':70,'href':'/interview/docs/leetcode/addTwoNumbers/','title':"两数相加",'content':"两数相加 头条重点\n题目 给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。\n如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。\n您可以假设除了数字 0 之外，这两个数都不会以 0 开头。\n示例： 输入：(2 -\u0026gt; 4 -\u0026gt; 3) + (5 -\u0026gt; 6 -\u0026gt; 4) 输出：7 -\u0026gt; 0 -\u0026gt; 8 原因：342 + 465 = 807 解题思路 public ListNode addTwoNumbers(ListNode l1, ListNode l2) { if (l1 == null || l2 == null) { return null; } StringBuilder builder1 = new StringBuilder(); while (l1 != null) { builder1.append(l1.val); l1 = l1.next; } StringBuilder builder2 = new StringBuilder(); while (l2 != null) { builder2.append(l2.val); l2 = l2.next; } BigDecimal bigDecimal1 = new BigDecimal(builder1.reverse().toString()); BigDecimal bigDecimal2 = new BigDecimal(builder2.reverse().toString()); String resStr = bigDecimal1.add(bigDecimal2).toPlainString(); ListNode head = new ListNode(Integer.parseInt(String.valueOf(resStr.charAt(resStr.length() - 1)))); ListNode cur = head; for (int i = resStr.length() - 2; i \u0026gt;= 0; i--) { cur.next = new ListNode(Integer.parseInt(String.valueOf(resStr.charAt(i)))); cur = cur.next; } return head; } "});index.add({'id':71,'href':'/interview/docs/offer/SumOfNDice/','title':"个骰子的点数",'content':"题目 把 n 个骰子扔在地上，所有骰子朝上一面的和为 s，输入 n，打印 s 所有可能值的概率\n解题思路  首先考虑一个骰子的情况，那么有 1～6 出现的次数均为 1 再增加一个骰子时，由于各个点数出现的概率一致。用   \\(f(n,s)=f(n-1,s-1)+f(n-1,s-2)+f(n-1,s-3)+f(n-1,s-4)+f(n-1,s-5)+f(n-1,s-6)\\)   使用两个数组循环求解  public void SumOfNDice(int n) { if (n \u0026lt; 1) { return; } int[][] nums = new int[2][n * 6 + 1]; int flag = 0; //初始化第一个骰子各总和出现的次数 int maxLen = nums[0].length; for (int i = 1; i \u0026lt; maxLen; i++) { nums[flag][i] = 1; } for (int i = 2; i \u0026lt;= n; i++) { int newFlag = flag ^ 0x01; Arrays.fill(nums[newFlag], 0); for (int j = i; j \u0026lt; maxLen; j++) { int sum = 0; for (int k = 1; k \u0026lt;= 6 \u0026amp;\u0026amp; (j - k \u0026gt;= 0); k++) { sum += nums[flag][j - k]; } nums[newFlag][j] = sum; } flag = newFlag; } //debug out System.out.println(Arrays.toString(nums[flag])); int sum = 0; for (int i : nums[flag]) { sum += i; } for (int i = 0; i \u0026lt; nums[flag].length; i++) { System.out.println(i + \u0026quot;:\u0026quot; + nums[flag][i] * 1.0 / sum); } } "});index.add({'id':72,'href':'/interview/docs/basic/os/interrupt/','title':"中断",'content':"中断 中断（英语：Interrupt）是指 处理器接收到来自硬件或软件的信号，提示发生了某个事件，应该被注意，这种情况就称为中断。\n通常，在接收到来自外围硬件（相对于中央处理器和内存）的异步信号，或来自软件的同步信号之后，处理器将会进行相应的 硬件／软件 处理。发出这样的信号称为进行中断请求（interrupt request，IRQ）。硬件中断导致处理器通过一个运行信息切换（context switch）来保存执行状态（以程序计数器和程序状态字等寄存器信息为主）；软件中断则通常作为CPU指令集中的一个指令，以可编程的方式直接指示这种运行信息切换，并将处理导向一段中断处理代码。中断在计算机多任务处理，尤其是即时系统中尤为有用。\n中断分类 硬件中断 由硬件发出或产生的中断称为硬中断，按硬中断事件的来源和实现手段可将中断划分为外中断和内中断：\n 外中断：又称为中断或异步中断，是指 来自处理器以外的中断信号，包括时钟中断、键盘中断、外部设备中断等。外中断又分为可屏蔽中断和不可屏蔽中断，各个中断具有不同的优先级，表示事件的紧急程度，在处理高一级中断时，往往会部分或全部屏蔽低等级中断。 内中断：又称为异常或同步中断（产生时必须考虑与处理器时钟同步），是指 来自处理器内部的中断信号，通常是由于程序执行过程中，发现与当前指令关联的、不正常的或错误的事件。内中断可以细分为：  访管中断，由执行系统调用而引起的。 硬件故障中断，如电源失效、总线超时等。 程序性中断，如非法操作、地址越界、除数为0和浮点溢出等。    软件中断 软件中断：是一条CPU指令，用以自陷一个中断。由于 软中断指令通常要运行一个切换CPU至内核态（Kernel Mode/Ring 0）的子例程，它常被用作实现系统调用（System call）。\n处理器通常含有一个内部中断屏蔽位，并允许通过软件来设定。一旦被设定，所有外部中断都将被系统忽略。这个屏蔽位的访问速度显然快于中断控制器上的中断屏蔽寄存器，因此可提供更快速地中断屏蔽控制。\n中断尽管可以提高计算机处理性能，但 过于密集的中断请求／响应反而会影响系统性能。这类情形被称作中断风暴（interrupt storm）。\n"});index.add({'id':73,'href':'/interview/docs/leetcode/maxProfit/','title':"买卖股票的最佳时机",'content':"头条重点\n题目 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。\n注意你不能在买入股票前卖出股票。\n示例 1: 输入: [7,1,5,3,6,4] 输出: 5 解释: 在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。 注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格。 示例 2: 输入: [7,6,4,3,1] 输出: 0 解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。 解题思路  要先买入才能卖出，先找最低价格点 再找最低价格之后的最高价格，用 res 表示最大利润  public int maxProfit(int[] prices) { if (prices.length \u0026lt;= 1) { return 0; } int res = 0; int minBuy = prices[0]; for (int price : prices) { res = Math.max(res, price - minBuy); minBuy = Math.min(minBuy, price); } return res; } "});index.add({'id':74,'href':'/interview/docs/leetcode/maxProfit2/','title':"买卖股票的最佳时机",'content':"头条重点\n题目 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。\n注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\n示例 1: 输入: [7,1,5,3,6,4] 输出: 7 解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。 随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。 示例 2: 输入: [1,2,3,4,5] 输出: 4 解释: 在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。 注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出。 因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。 示例 3: 输入: [7,6,4,3,1] 输出: 0 解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。 解题思路  贪心算法，尽可能的多进行交易  public int maxProfit(int[] prices) { if (prices.length \u0026lt;= 1) { return 0; } int res = 0; for (int i = 1; i \u0026lt; prices.length; i++) { int profit = prices[i] - prices[i - 1]; if (profit \u0026gt; 0) { res += profit; } } return res; } "});index.add({'id':75,'href':'/interview/docs/offer/BST-Link-Convert/','title':"二叉搜索树与双向链表",'content':"题目 牛客网\n输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。\n解题思路  由于 BST 的特性，采用中序遍历正好符合排序 要考虑 root 节点要与 左节点的最大值连接，与右节点的最小值连接 增加一个已排序链表的指针，指向最后一个已排序节点  public TreeNode Convert(TreeNode pRootOfTree) { if (pRootOfTree == null) { return null; } TreeNode[] nodeList = {new TreeNode(-1)}; ConvertToLink(pRootOfTree, nodeList); TreeNode cursor = pRootOfTree; while (cursor.left != null) { cursor = cursor.left; } cursor.right.left = null; return cursor.right; } private void ConvertToLink(TreeNode root, TreeNode[] nodeList) { if (root == null) { return; } ConvertToLink(root.left, nodeList); root.left = nodeList[0]; nodeList[0].right = root; nodeList[0] = root; ConvertToLink(root.right, nodeList); } "});index.add({'id':76,'href':'/interview/docs/offer/VerifySquenceOfBST/','title':"二叉搜索树的后序遍历序列",'content':"题目 牛客网\n输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出 Yes ,否则输出 No 。假设输入的数组的任意两个数字都互不相同。\n解题思路  后序遍历中，最后一个节点为 root 节点 由于 BST 的左子树都小于 root，右子树都大于 root，那么可以判定该节点是否为 BST 依次类推，通过递归方式，再判定左右子树  public boolean VerifySquenceOfBST(int[] sequence) { if (sequence.length == 0) { return false; } if (sequence.length == 1) { return true; } return isBST(sequence, 0, sequence.length - 1); } private boolean isBST(int[] sequence, int start, int end) { if (start \u0026lt; 0 || end \u0026lt; 0 || start \u0026gt;= end) { return true; } int rootV = sequence[end]; int rightIndex = -1, rightV = Integer.MIN_VALUE; for (int i = start; i \u0026lt; end; i++) { if (rightV == Integer.MIN_VALUE \u0026amp;\u0026amp; sequence[i] \u0026gt; rootV) { rightV = sequence[i]; rightIndex = i; continue; } if (rightV != Integer.MIN_VALUE \u0026amp;\u0026amp; sequence[i] \u0026lt; rootV) { return false; } } return isBST(sequence, start, rightIndex - 1) \u0026amp;\u0026amp; isBST(sequence, rightIndex, end - 1); } "});index.add({'id':77,'href':'/interview/docs/offer/BSTKthNode/','title':"二叉搜索树的第",'content':"题目 给定一棵二叉搜索树，请找出其中的第 k 小的结点。例如，5，3，7，2，4，6，8 中，按结点数值大小顺序第三小结点的值为4。\n牛客网\n解题思路  BST 中序遍历的结果就是排序后的结果  public TreeNode KthNode(TreeNode pRoot, int k) { TreeNode[] nodes = new TreeNode[1]; int[] ints = {0}; KthNode(pRoot, k, nodes, ints); return nodes[0]; } private void KthNode(TreeNode root, int k, TreeNode[] res, int[] cursor) { if (root == null) return; if (res[0] != null) return; KthNode(root.left, k, res, cursor); cursor[0]++; if (cursor[0] == k) { res[0] = root; return; } KthNode(root.right, k, res, cursor); } "});index.add({'id':78,'href':'/interview/docs/offer/FindPath/','title':"二叉树中和为某一值的路径",'content':"题目 二叉树中和为某一值的路径\n输入一颗二叉树的跟节点和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。(注意: 在返回值的 list 中，数组长度大的数组靠前)\n解题思路  将走过的路径记录下来，当走过路径总和 = target 并且当前节点是叶子节点时，该路径符合要求 通过递归遍历所有可能的路径  public ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; FindPath(TreeNode root, int target) { ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); FindPath(res, new LinkedList\u0026lt;\u0026gt;(), root, 0, target); res.sort(Comparator.comparingInt(list -\u0026gt; -list.size())); return res; } private void FindPath(ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; res, LinkedList\u0026lt;Integer\u0026gt; path, TreeNode node, int pathSum, int target) { if (node == null) { return; } if (pathSum \u0026gt; target) { return; } if (pathSum + node.val == target \u0026amp;\u0026amp; node.right == null \u0026amp;\u0026amp; node.left == null) { ArrayList\u0026lt;Integer\u0026gt; resPath = new ArrayList\u0026lt;\u0026gt;(path); resPath.add(node.val); res.add(resPath); return; } path.addLast(node.val); if (node.left != null) { FindPath(res, path, node.left, pathSum + node.val, target); } if (node.right != null) { FindPath(res, path, node.right, pathSum + node.val, target); } path.removeLast(); } "});index.add({'id':79,'href':'/interview/docs/offer/GetNext/','title':"二叉树的下一个结点",'content':"题目 给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。\n解题思路 public TreeLinkNode GetNext(TreeLinkNode pNode) { if (pNode == null) return null; TreeLinkNode parent = pNode.next; if (pNode.right == null) { if (parent == null) { return null; } //右节点 if (parent.right == pNode) { TreeLinkNode cursor = parent; while (true) { TreeLinkNode p = cursor.next; if (p == null) return null; if (cursor == p.left) return p; cursor = p; } } else { return parent; } } else { TreeLinkNode cursor = pNode.right; while (cursor.left != null) { cursor = cursor.left; } return cursor; } } "});index.add({'id':80,'href':'/interview/docs/leetcode/lowestCommonAncestor/','title':"二叉树的最近公共祖先",'content':"题目 给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。\n百度百科中最近公共祖先的定义为：“对于有根树 T 的两个结点 p、q，最近公共祖先表示为一个结点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。”\n示例 1: 输入: root = [3,5,1,6,2,0,8,null,null,7,4], p = 5, q = 1 输出: 3 解释: 节点 5 和节点 1 的最近公共祖先是节点 3。 解题思路  通过 DFS 找到节点的路径 从头开始遍历两个节点的路径，找到最后一个相等的节点  public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { LinkedList\u0026lt;TreeNode\u0026gt; pathP = new LinkedList\u0026lt;\u0026gt;(); LinkedList\u0026lt;TreeNode\u0026gt; pathQ = new LinkedList\u0026lt;\u0026gt;(); findNodePath(pathP, root, p); findNodePath(pathQ, root, q); TreeNode last = null; while (!pathP.isEmpty() \u0026amp;\u0026amp; !pathQ.isEmpty()) { TreeNode pi = pathP.pollFirst(); TreeNode qi = pathQ.pollFirst(); if (qi==pi) { last = pi; }else break; } return last; } private void findNodePath(LinkedList\u0026lt;TreeNode\u0026gt; path, TreeNode root, TreeNode target) { if (root == null) { return; } if (!path.isEmpty() \u0026amp;\u0026amp; path.getLast().val == target.val) { return; } path.addLast(root); findNodePath(path, root.left, target); if (!path.isEmpty() \u0026amp;\u0026amp; path.getLast().val == target.val) { return; } findNodePath(path, root.right, target); if (!path.isEmpty() \u0026amp;\u0026amp; path.getLast().val != target.val) { path.removeLast(); } } "});index.add({'id':81,'href':'/interview/docs/offer/TreeDepth/','title':"二叉树的深度",'content':"题目 牛客网\n输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。\n解题思路  深度优先遍历  public int TreeDepth(TreeNode root) { int[] max = {0}; depth(root, max, 1); return max[0]; } private void depth(TreeNode root, int[] max, int curDepth) { if (root == null) return; if (curDepth \u0026gt; max[0]) max[0] = curDepth; depth(root.left, max, curDepth + 1); depth(root.right, max, curDepth + 1); } "});index.add({'id':82,'href':'/interview/docs/offer/number-of-one/','title':"二进制中",'content':"题目 [](https://www.nowcoder.com/practice/8ee967e43c2c4ec193b040ea7fbb10b8?tpId=13\u0026amp;tqId=11164\u0026amp;rp=1\u0026amp;ru=%2Fta%2Fcoding-interviews\u0026amp;qru=%2Fta%2Fcoding-interviews%2Fquestion-ranking\u0026amp;tPage=1)\n输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。\n解题思路  负数是补码表示 \u0026gt;\u0026gt;\u0026gt; 为无符号右移，\u0026gt;\u0026gt;为有符号右移，当 n 为负数是会增加多余的1  public int NumberOf1(int n) { int mask = 0x01; int res = 0; int t = n; while (t != 0) { if ((t \u0026amp; mask) == 1) { res++; } t = t \u0026gt;\u0026gt;\u0026gt; 1; } return res; } "});index.add({'id':83,'href':'/interview/docs/offer/PrintFromTopToBottom/','title':"从上往下打印二叉树",'content':"题目 牛客网\n从上往下打印出二叉树的每个节点，同层节点从左至右打印。\n解题思路  层次遍历，通过队列进行辅助遍历  public ArrayList\u0026lt;Integer\u0026gt; PrintFromTopToBottom(TreeNode root) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); LinkedList\u0026lt;TreeNode\u0026gt; nodeQueue = new LinkedList\u0026lt;\u0026gt;(); if (root == null) { return res; } nodeQueue.addLast(root); while (!nodeQueue.isEmpty()) { TreeNode node = nodeQueue.pollFirst(); if (node == null) { continue; } nodeQueue.addLast(node.left); nodeQueue.addLast(node.right); res.add(node.val); } return res; } "});index.add({'id':84,'href':'/interview/docs/offer/print-link-from-tail/','title':"从尾到头打印链表",'content':"题目 牛客网\n输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。\n解题思路  栈  public ArrayList\u0026lt;Integer\u0026gt; printListFromTailToHead(ListNode listNode) { LinkedList\u0026lt;Integer\u0026gt; stack = new LinkedList\u0026lt;\u0026gt;(); while (listNode != null) { stack.addLast(listNode.val); listNode = listNode.next; } ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); while (!stack.isEmpty()) { res.add(stack.pollLast()); } return res; } 递归：当链表过长时，会导致栈溢出  public ArrayList\u0026lt;Integer\u0026gt; printListFromTailToHead(ListNode listNode) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); print(res,listNode); return res; } private void print(ArrayList\u0026lt;Integer\u0026gt; res, ListNode listNode) { if (listNode == null) return; print(res, listNode.next); res.add(listNode.val); } "});index.add({'id':85,'href':'/interview/docs/leetcode/AllOne/','title':"全 O(1) 的数据结构",'content':"全 O(1) 的数据结构 题目 实现一个数据结构支持以下操作：\n Inc(key) - 插入一个新的值为 1 的 key。或者使一个存在的 key 增加一，保证 key 不为空字符串。 Dec(key) - 如果这个 key 的值是 1，那么把他从数据结构中移除掉。否者使一个存在的 key 值减一。如果这个 key 不存在，这个函数不做任何事情。key 保证不为空字符串。 GetMaxKey() - 返回 key 中值最大的任意一个。如果没有元素存在，返回一个空字符串\u0026rdquo;\u0026quot;。 GetMinKey() - 返回 key 中值最小的任意一个。如果没有元素存在，返回一个空字符串\u0026rdquo;\u0026quot;。  挑战：以 O(1) 的时间复杂度实现所有操作。\n解题思路  设计一个 Bucket 保存所有值为 value 的 key 并且有临近 value 的 Bucket 指针  class AllOne { /** Initialize your data structure here. */ public AllOne() { } private static class Bucket { private int value; private Set\u0026lt;String\u0026gt; keys = new HashSet\u0026lt;\u0026gt;(); private Bucket next; private Bucket pre; public Bucket(int value) { this.value = value; } @Override public String toString() { return \u0026quot;Bucket{\u0026quot; + \u0026quot;value=\u0026quot; + value + \u0026quot;, keys=\u0026quot; + keys + '}'; } } private Map\u0026lt;String, Bucket\u0026gt; data = new HashMap\u0026lt;\u0026gt;(); private List\u0026lt;Bucket\u0026gt; bucketList = new ArrayList\u0026lt;\u0026gt;(); /** * Inserts a new key \u0026lt;Key\u0026gt; with value 1. Or increments an existing key by 1. */ public void inc(String key) { if (data.containsKey(key)) { Bucket bucket = data.get(key); bucket.keys.remove(key); if (bucket.next == null) { bucket.next = new Bucket(bucket.value + 1); bucket.next.pre = bucket; bucketList.add(bucket.next); } bucket.next.keys.add(key); data.put(key, bucket.next); } else { if (bucketList.size() == 0) { bucketList.add(new Bucket(1)); } Bucket bucket = bucketList.get(0); bucket.keys.add(key); data.put(key, bucket); } } /** * Decrements an existing key by 1. If Key's value is 1, remove it from the data structure. */ public void dec(String key) { if (!data.containsKey(key)) { return; } Bucket bucket = data.get(key); if (bucket.pre == null) { bucket.keys.remove(key); data.remove(key); } else { bucket.keys.remove(key); bucket.pre.keys.add(key); data.put(key, bucket.pre); } } /** * Returns one of the keys with maximal value. */ public String getMaxKey() { if (bucketList.size() == 0) { return \u0026quot;\u0026quot;; } for (int i = bucketList.size() - 1; i \u0026gt;= 0; i--) { Bucket bucket = bucketList.get(i); if (!bucket.keys.isEmpty()) { Iterator\u0026lt;String\u0026gt; iterator = bucket.keys.iterator(); if (iterator.hasNext()) { return iterator.next(); } else { return \u0026quot;\u0026quot;; } } } return \u0026quot;\u0026quot;; } /** * Returns one of the keys with Minimal value. */ public String getMinKey() { if (bucketList.size() == 0) { return \u0026quot;\u0026quot;; } for (Bucket bucket : bucketList) { if (!bucket.keys.isEmpty()) { Iterator\u0026lt;String\u0026gt; iterator = bucket.keys.iterator(); if (iterator.hasNext()) { return iterator.next(); } else { return \u0026quot;\u0026quot;; } } } return \u0026quot;\u0026quot;; } } "});index.add({'id':86,'href':'/interview/docs/basic/os/memory/','title':"内存管理",'content':"内存管理 存储器工作原理 应用程序如何在计算机系统上运行的呢？首先，用编程语言编写和编辑应用程序，所编写的程序称为源程序，源程序不能再计算机上直接被运行，需要通过三个阶段的处理：编译程序处理源程序并生成目标代码，链接程序把他们链接为一个可重定位代码，此时该程序处于逻辑地址空间中；下一步装载程序将可执行代码装入物理地址空间，直到此时程序才能运行。\n程序编译 源程序经过编译程序的处理生成目标模块（目标代码）。一个程序可由独立编写且具有不同功能的多个源程序模块组成，由于模块包含外部引用（即指向其他模块中的数据或指令地址，或包含对库函数的引用），编译程序负责记录引用发生的位置，其处理结果将产生相应的多个目标模块，每个模块都附有供引用使用的内部符号表和外部符号表。符号表中依次给出各个符号名及在本目标模块中的名字地址，在模块链接时进行转换。\n程序链接 链接程序(Linker)的作用是根据目标模块之间的调用和依赖关系，将主调模块、被调模块以及所用到的库函数装配和链接成一个完整的可装载执行模块。根据程序链接发生的时间和链接方式，程序链接可分为以下三种方式：\n  静态链接：在程序装载到内存和运行前，就已将它所有的目标模块及所需要的库函数进行链接和装配成一个完整的可执行程序且此后不再拆分。\n  动态链接：在程序装入内存前并未事先进行程序各目标模块的链接，而是在程序装载时一边装载一边链接，生成一个可执行程序。在装载目标模块时，若发生外部模块调用，将引发响应外部目标模块的搜索、装载和链接。\n  运行时链接：在程序执行过程中，若发现被调用模块或库函数尚未链接，先在内存中进行搜索以查看是否装入内存；若已装入，则直接将其链接到调用程序中，否则进行该模块在外存上的搜索，以及装入内存和进行链接，生成一个可执行程序。\n  运行时链接将链接推迟到程序执行时，可以很好的提高系统资源的利用率和系统效率。\n程序装载 程序装载就是将可执行程序装入内存，这里有三种方式：\n  绝对装载：装载模块中的指令地址始终与其内存中的地址相同，即模块中出现的所有地址均为绝对地址。\n  可重定位装载：根据内存当时的使用情况，决定将装载代码模块放入内存的物理位置。模块内使用的都是相对地址。\n  动态运行时装载：为提高内存利用率，装入内存的程序可换出到磁盘上，适当时候再换入内存中，对换前后程序在内存中的位置可能不同，即允许进程的内存映像在不同时候处于不同位置，此时模块内使用的地址必定为相对地址。\n  磁盘中的装载模块所使用的是逻辑地址，其逻辑地址集合称为进程的逻辑地址空间。进程运行时，其装载代码模块将被装入物理地址空间中，此时程序和数据的实际地址不可能同原来的逻辑一致。可执行程序逻辑地址转换为物理地址的过程被称为 “地址重定位”。\n  静态地址重定位：由装载程序实现装载代码模块的加载和物理地址转换，把它装入分配给进程的内存指定区域，其中所有逻辑地址修改为物理地址。地址转换在进程执行前一次完成，易于实现，但不允许程序在执行过程中移动位置。\n  动态地址重定位：由装载程序实现装载代码模块的加载，把它装入分配给进程的内存指定区域，但对链接程序处理过的程序的逻辑地址不做任何改变，程序内存起始地址被置入硬件专用寄存器 —— 重定位寄存器。程序执行过程中，每当CPU引用内存地址时，有硬件截取此逻辑地址，并在它被发送到内存之前加上重定位寄存器的值，以实现地址转换。\n  运行时链接地址重定位：对于静态和动态地址重定位装载方式而言，装载代码模块是由整个程序的所有目标模块及库函数经链接和整合构成的可执行程序，即在程序启动执行前已经完成了程序的链接过程。可见，装载代码的正文结构是静态的，在程序运行期间保持不变。运行时链接装载方式必然采用运行时链接地址重定位。\n   重定位寄存器：用于保存程序内存起始地址。\n 连续存储管理 固定分区存储管理 固定分区存储管理又称为静态分区模式，基本思想是：内存空间被划分成数目固定不变的分区，各分区大小不等，每个分区装入一个作业，若多个分区中都有作业，则他们可以并发执行。\n为说明各分区分配和使用情况，需要设置一张内存分配表，记录内存中划分的分区及其使用情况。内存分配表中指出各分区起始地址和长度，占用标志用来指示此分区是否被使用。\n可变分区存储管理 可变分区存储管理按照作业大小来划分分区，但划分的时间、大小、位置都是动态的。系统把作业装入内存时，根据其所需要的内存容量查看是否有足够空间，若有则按需分割一个分区分配给此作业；若无则令此作业等待内存资源。\n在可变分区模式下，内存中分区数目和大小随作业的执行而不断改变，为了方便内存空间的分配和去配，用于管理的数据结构可由两张表组成：已分配区表和未分配区表。当装入新作业时，从未分配区表中找出一个足够容纳它的空闲区，将此区分为两个部分，一部分用来装入作业，成为已分配区；另一部分仍是空闲区（若有）。这时，应从已分配区表中找出一个空栏目登记新作业的起始地址、占用长度，同时修改未分配区表中空闲区的长度和起始地址。当作业撤离时，已分配区表中的相应状态改为空闲，而将收回的分区登记到为分配区中，若有相邻空闲区再将其连接后登记。\n常用的可变分区分配算法   最先适应分配算法：该算法顺序查找未分配区表，直到找到第一个能满足长度要求的空闲区为止，分割此分区，一部分分配给作业，另一部分仍为空闲区。\n  下次适应分配算法：该算法总是从未分配区的上次扫描结束处顺序查找未分配区表，直到找到第一个能满足长度要求的空闲区为止。\n  最优适应分配算法：该算法扫描整个未分配区表，从空闲区中挑选一个能满足用户进程要求的最小分区进行分配。\n  最坏适应分配算法：该算法扫描整个未分配区表，总是挑选一个最大的空闲区分割给作业使用，其优点是使剩下的空闲区不至于过小。\n  快速适应分配算法：该算法为那些经常用到的长度的空闲区设立单独的空闲区链表。\n  分页存储管理  逻辑空间等分为页；并从0开始编号 内存空间等分为块，与页面大小相同；从0开始编号 分配内存时，以块为单位将进程中的若干个页分别装入到多个可以不相邻接的物理块中。  分段存储管理  逻辑空间分为若干个段，每个段定义了一组有完整逻辑意义的信息（如主程序Main()）。 内存空间为每个段分配一个连续的分区。  分页和分段的主要区别：\n 分页：信息的物理单位。大小一样，由系统决定。地址空间是一维的。 分段：信息的逻辑单位。大小不一样，由程序员决定。地址空间是二维的。  段页式存储管理 用户程序先分段，每个段内部再分页（内部原理同基本的分页、分段相同）\n内存分配   虚拟地址：用户编程时将代码（或数据）分成若干个段，每条代码或每个数据的地址由段名称 + 段内相对地址构成，这样的程序地址称为虚拟地址\n  逻辑地址：虚拟地址中，段内相对地址部分称为逻辑地址\n  物理地址：实际物理内存中所看到的存储地址称为物理地址\n  逻辑地址空间：在实际应用中，将虚拟地址和逻辑地址经常不加区分，通称为逻辑地址。逻辑地址的集合称为逻辑地址空间\n  线性地址空间：CPU地址总线可以访问的所有地址集合称为线性地址空间\n  物理地址空间：实际存在的可访问的物理内存地址集合称为物理地址空间\n  MMU(Memery Management Unit内存管理单元)：实现将用户程序的虚拟地址（逻辑地址） -\u0026gt; 物理地址映射的CPU中的硬件电路\n  基地址：在进行地址映射时，经常以段或页为单位并以其最小地址（即起始地址）为基值来进行计算\n  偏移量：在以段或页为单位进行地址映射时，相对于基地址的地址值\n  虚拟地址先经过分段机制映射到线性地址，然后线性地址通过分页机制映射到物理地址。\n虚拟内存\u0026ndash;请求分页虚拟存储管理 请求调页，也称按需调页，即对不在内存中的“页”，当进程执行时要用时才调入，否则有可能到程序结束时也不会调入。\n页面置换算法   FIFO算法：先入先出，即淘汰最早调入的页面。\n  OPT(MIN)算法：选未来最远将使用的页淘汰，是一种最优的方案，可以证明缺页数最小。可惜，MIN需要知道将来发生的事，只能在理论中存在，实际不可应用。\n  LRU(Least-Recently-Used)算法：用过去的历史预测将来，选最近最长时间没有使用的页淘汰(也称最近最少使用)。性能最接近OPT。与页面使用时间有关。\n  LFU(Least Frequently Used)算法：即最不经常使用页置换算法，要求在页置换时置换引用计数最小的页，因为经常使用的页应该有一个较大的引用次数。与页面使用次数有关。\n  Clock：给每个页帧关联一个使用位，当该页第一次装入内存或者被重新访问到时，将使用位置为1。每次需要替换时，查找使用位被置为0的第一个帧进行替换。在扫描过程中，如果碰到使用位为1的帧，将使用位置为0，在继续扫描。如果所谓帧的使用位都为0，则替换第一个帧。\n  内存抖动现象：页面的频繁更换，导致整个系统效率急剧下降，这个现象称为内存抖动（或颠簸）。抖动一般是内存分配算法不好，内存太小引或者程序的算法不佳引起的。\n交换区：用于保存请求分页淘汰出来的页面。\n"});index.add({'id':87,'href':'/interview/docs/architecture/distributed/transaction/','title':"分布式事务",'content':"分布式事务 分布式事务的实现主要有以下 5 种方案：\n XA 方案 TCC 方案 可靠消息最终一致性方案 最大努力通知方案  2PC/XA方案 所谓的 XA 方案，即：两阶段提交，有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先问问各个数据库你准备好了吗？如果每个数据库都回复 ok，那么就正式提交事务，在各个数据库上执行操作；如果任何其中一个数据库回答不 ok，那么就回滚事务。\n这种分布式事务方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。\n一般来说某个系统内部如果出现跨多个库的这么一个操作，是不合规的。如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库。\nTCC强一致性方案 TCC 的全称是：Try、Confirm、Cancel。\n Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行 锁定或者预留。 Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。 Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要 进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）   这种方案说实话几乎很少人使用，但是也有使用的场景。因为这个 事务回滚实际上是严重依赖于你自己写代码来回滚和补偿 了，会造成补偿代码巨大，非常之恶心。\n可靠消息最终一致性方案 基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。大概的意思就是：\n A 系统先发送一个 prepared 消息到 MQ，如果这个 prepared 消息发送失败那么就直接取消操作别执行了； 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 MQ 发送确认消息，如果失败就告诉 MQ 回滚消息； 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务； mq 会自动定时轮询所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。  这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。\n最大努力通知方案 这个方案的大致意思就是：\n 系统 A 本地事务执行完之后，发送个消息到 MQ； 这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口； 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。  "});index.add({'id':88,'href':'/interview/docs/architecture/distributed/cache/','title':"分布式缓存",'content':"分布式缓存 高并发环境下，例如典型的淘宝双11秒杀，几分钟内上亿的用户涌入淘宝，这个时候如果访问不加拦截，让大量的读写请求涌向数据库，由于磁盘的处理速度与内存显然不在一个量级，服务器马上就要宕机。从减轻数据库的压力和提高系统响应速度两个角度来考虑，都会在数据库之前加一层缓存，访问压力越大的，在缓存之前就开始 CDN 拦截图片等访问请求。\n并且由于最早的单台机器的内存资源以及承载能力有限，如果大量使用本地缓存，也会使相同的数据被不同的节点存储多份，对内存资源造成较大的浪费，因此，才催生出了分布式缓存。\n应用场景  页面缓存：用来缓存Web 页面的内容片段,包括HTML、CSS 和图片等; 应用对象缓存：缓存系统作为ORM 框架的二级缓存对外提供服务,目的是减轻数据库的负载压力,加速应用访问;解决分布式Web部署的 session 同步问题，状态缓存.缓存包括Session 会话状态及应用横向扩展时的状态数据等,这类数据一般是难以恢复的,对可用性要求较高,多应用于高可用集群。 并行处理：通常涉及大量中间计算结果需要共享; 云计算领域提供分布式缓存服务  常见问题和挑战 缓存雪崩 缓存雪崩我们可以简单的理解为：由于原有缓存失效、新缓存未到之间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。\n缓存穿透 缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。\n缓存预热 缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！\n缓存更新 除了缓存服务器自带的缓存失效策略之外，我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：\n 定时去清理过期的缓存； 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。  两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。\n缓存降级 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。\n降级的最终目的是 保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。\n在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：\n 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警； 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级； 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。  缓存与数据库不一致问题 首先，缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，大家没啥疑问，都是按照下图的流程来进行业务操作。\n但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实大家存在很大的争议。\n从理论上来说，给 缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。\n先删除缓存，再更新数据库 该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:\n 请求A进行写操作，删除缓存 请求B查询发现缓存不存在 请求B去数据库查询得到旧值 请求B将旧值写入缓存 请求A将新值写入数据库  上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。\n可以通过：\n 更新操作数据库后，再次更新缓存来实现 缓存设置过期时间，等待过期时间后，数据恢复  "});index.add({'id':89,'href':'/interview/docs/architecture/distributed/lock/','title':"分布式锁",'content':"分布式锁 Redis 锁 单节点 Redis 锁 锁的获取：\nSET resource_name my_random_value NX PX 30000 锁释放：\nif redis.call(\u0026quot;get\u0026quot;,KEYS[1]) == ARGV[1] then return redis.call(\u0026quot;del\u0026quot;,KEYS[1]) else return 0 end RedLock 为了解决 Redis 单点的问题。 Redis 的作者提出了 RedLock 的解决方案。方案非常的巧妙和简洁。 RedLock 的核心思想就是，同时使用多个 Redis Master 来冗余，且这些节点都是完全的独立的，也不需要对这些节点之间的数据进行同步。\n假设我们有N个Redis节点，N应该是一个大于2的奇数。RedLock的实现步骤:\n 取得当前时间 使用单节点获取锁的方式，依次获取 N 个节点的 Redis 锁。 如果获取到的锁的数量大于   \\(N/2+1\\)  个，且获取的时间小于锁的有效时间(lock validity time)就认为获取到了一个有效的锁，锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间。 如果获取锁的数量小于 \\(N/2+1\\)  ，或者在锁的有效时间(lock validity time)内没有获取到足够的锁，就认为获取锁失败，这个时候需要向所有节点发送释放锁的消息。  对于释放锁的实现就很简单了，向所有的 Redis 节点发起释放的操作，无论之前是否获取锁成功。\n缺陷 RedLock中，为了防止死锁，锁是具有过期时间的。\n 如果 Client 1 在持有锁的时候，发生了一次很长时间的 FGC 超过了锁的过期时间。锁就被释放了。 这个时候 Client 2 又获得了一把锁，提交数据。 这个时候 Client 1 从 FGC 中苏醒过来了，又一次提交数据。  这种情况下，数据就发生了错误。RedLock 只是保证了锁的高可用性，并没有保证锁的正确性。\n解决方案可以为锁增加一个自增标识，类似于 Kafka 脑裂的处理方式：\n同时 RedLock 是严重依赖系统时钟的一致性。如果某个 Redis Master的系统时间发生了错误，造成了它持有的锁提前过期被释放。\n 每一个系统设计都有自己的侧重或者局限。工程也不是完美的。在现实中工程中不存在完美的解决方案。我们应当深入了解其中的原理，了解解决方案的优缺点。明白选用方案的局限性。是否可以接受方案的局限带来的后果。架构本来就是一门平衡的艺术。\n 实现基于数据库的乐观锁 提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。\nConnection conn = DriverManager.getConnection(url, user, password); conn.setAutoCommit(false); Statement stmt = conn.createStatement(); // step 1 int oldVersion = getOldVersion(stmt); // step 2 // 用这个数据库连接做其他的逻辑 // step 3 可用预编译语句 int i = stmt.executeUpdate( \u0026quot;update optimistic_lock set version = \u0026quot; + (oldVersion + 1) + \u0026quot; where version = \u0026quot; + oldVersion); // step 4 if (i \u0026gt; 0) { conn.commit(); // 更新成功表明数据没有被修改，提交事务。 } else { conn.rollback(); // 更新失败，数据被修改，回滚。 } 乐观锁的缺点：\n 会带来大数量的无效更新请求、事务回滚，给DB造成不必要的额外压力。 无法保证先到先得，后面的请求可能由于并发压力小了反而有可能处理成功。  基于 ZooKeeper 的分布式锁 基于 ZK 的特性，很容易得出使用 ZK 实现分布式锁的落地方案：\n 使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下。 创建节点成功后，获取 /lock 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听。  缺陷  ZK 集群的读写吞吐量不高 网络抖动可能导致 Session 离线，锁被释放  参考链接  Redis实现分布式锁 Redis RedLock 完美的分布式锁么？  "});index.add({'id':90,'href':'/interview/docs/offer/CutRope/','title':"剪绳子",'content':"题目 给定一根长度为n的绳子，请把绳子剪成m段（m、n都是整数，n\u0026gt;1并且m\u0026gt;1），每段绳子的长度记为k[0],k[1],…,k[m]。请问k[0]* k[1] * … *k[m]可能的最大乘积是多少？\n解题思路  尽可能剪长度为 3 的绳子 当长度剩下的为 4 时，不能再减去 3，而是 2*2  public int cutRope(int n) { if (n \u0026lt; 2) return 0; if (n == 2) return 1; if (n == 3) return 2; int timesOf3 = n / 3; if (n - timesOf3 * 3 == 1) { timesOf3 = 1; } int timesOf2 = (n - (timesOf3 * 3)) / 2; return (int) (Math.pow(3, timesOf3) * Math.pow((2), timesOf2)); } "});index.add({'id':91,'href':'/interview/docs/offer/MinStack/','title':"包含",'content':"题目 牛客网\n定义栈的数据结构，请在该类型中实现一个能够得到栈中所含最小元素的 min 函数（时间复杂度应为O（1））。\n解题思路  通过增加最小栈来记录当前最小节点  private LinkedList\u0026lt;Integer\u0026gt; stack = new LinkedList\u0026lt;\u0026gt;(); private LinkedList\u0026lt;Integer\u0026gt; min = new LinkedList\u0026lt;\u0026gt;(); public void push(int node) { stack.addLast(node); if (min.isEmpty()) { min.addLast(node); return; } if (node \u0026lt; min.peekLast()) { min.addLast(node); } else { min.addLast(min.peekLast()); } } public void pop() { if (stack.isEmpty()) { return; } stack.removeLast(); min.removeLast(); } public int top() { if (stack.peekLast() == null) { return 0; } return stack.peekLast(); } public int min() { if (min.peekLast() == null) { return 0; } return min.peekLast(); } "});index.add({'id':92,'href':'/interview/docs/offer/Singleton/','title':"单例",'content':"题目 设计一个类，我们只能生成该类的一个实例\n解题思路  线程安全 延迟加载 序列化与反序列化安全  /** * 需要额外的工作(Serializable、transient、readResolve())来实现序列化，否则每次反序列化一个序列化的对象实例时都会创建一个新的实例。 * \u0026lt;p\u0026gt; * 可能会有人使用反射强行调用我们的私有构造器（如果要避免这种情况，可以修改构造器，让它在创建第二个实例的时候抛异常）。 * * @author haoyang.shi */ public class Singleton { private Singleton() { } public static Singleton getInstance() { return Holder.instance; } private static final class Holder { private static Singleton instance = new Singleton(); } } /** * 使用枚举除了线程安全和防止反射强行调用构造器之外，还提供了自动序列化机制，防止反序列化的时候创建新的对象。 * \u0026lt;p\u0026gt; * 因此，Effective Java推荐尽可能地使用枚举来实现单例。 */ enum SingletonEnum { INSTANCE; private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } } "});index.add({'id':93,'href':'/interview/docs/leetcode/reverseList/','title':"反转链表",'content':"头条重点\n题目 反转一个单链表。\n示例: 输入: 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;NULL 输出: 5-\u0026gt;4-\u0026gt;3-\u0026gt;2-\u0026gt;1-\u0026gt;NULL 解题思路  三个指针进行反转  public ListNode reverseList(ListNode head) { if (head == null) { return head; } if (head.next == null) { return head; } ListNode pre = head; ListNode cur = head.next; while (cur != null) { ListNode next = cur.next; cur.next = pre; pre = cur; cur = next; } head.next = null; return pre; } "});index.add({'id':94,'href':'/interview/docs/offer/revert-link/','title':"反转链表",'content':"题目 牛客网\n输入一个链表，反转链表后，输出新链表的表头。\n解题思路  三个指针  public ListNode ReverseList(ListNode head) { if (head == null || head.next == null) { return head; } ListNode pre = head, cur = head.next, next; pre.next = null; while (cur != null) { next = cur.next; cur.next = pre; pre = cur; cur = next; } return pre; } "});index.add({'id':95,'href':'/interview/docs/leetcode/mergeKLists/','title':"合并",'content':"头条重点\n题目 合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。\n示例: 输入: [ 1-\u0026gt;4-\u0026gt;5, 1-\u0026gt;3-\u0026gt;4, 2-\u0026gt;6 ] 输出: 1-\u0026gt;1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;4-\u0026gt;5-\u0026gt;6 解题思路  通过小根堆，将所有元素放入小根堆 从小根堆依次取出数据  public ListNode mergeKLists(ListNode[] lists) { if (lists == null) { return null; } Queue\u0026lt;ListNode\u0026gt; set = new PriorityQueue\u0026lt;\u0026gt;(Comparator.comparingInt(o -\u0026gt; o.val)); for (ListNode node : lists) { while (node != null) { set.add(node); node = node.next; } } ListNode head = new ListNode(-1); ListNode res = head; ListNode cur; while ((cur = set.poll()) != null) { head.next = cur; head = head.next; } head.next = null; return res.next; } "});index.add({'id':96,'href':'/interview/docs/offer/merge-sort-link/','title':"合并两个排序的链表",'content':"题目 牛客网\n输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。\n解题思路  双指针指向两个链表 循环选取最小值，加入结果集  public ListNode Merge(ListNode list1, ListNode list2) { ListNode head = new ListNode(-1); ListNode cursor = head; while (list1 != null || list2 != null) { if (list1 == null) { while (list2 != null) { cursor.next = list2; cursor = cursor.next; list2 = list2.next; } continue; } if (list2 == null) { while (list1 != null) { cursor.next = list1; cursor = cursor.next; list1 = list1.next; } continue; } if (list1.val \u0026lt; list2.val) { cursor.next = list1; cursor = cursor.next; list1 = list1.next; } else { cursor.next = list2; cursor = cursor.next; list2 = list2.next; } } return head.next; } "});index.add({'id':97,'href':'/interview/docs/leetcode/mergeTwoLists/','title':"合并两个有序链表",'content':"题目 将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。\n示例： 输入：1-\u0026gt;2-\u0026gt;4, 1-\u0026gt;3-\u0026gt;4 输出：1-\u0026gt;1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;4 解题思路 public ListNode mergeTwoLists(ListNode l1, ListNode l2) { if (l1 == null \u0026amp;\u0026amp; l2 == null) { return null; } if (l1 == null) { return l2; } if (l2 == null) { return l1; } ListNode head; if (l1.val \u0026gt; l2.val) { head = l2; l2 = l2.next; } else { head = l1; l1 = l1.next; } ListNode res = head; while (true) { ListNode cur; if (l1 == null \u0026amp;\u0026amp; l2 == null) { break; } if (l1 == null) { cur = l2; l2 = l2.next; } else if (l2 == null) { cur = l1; l1 = l1.next; } else if (l1.val \u0026gt; l2.val) { cur = l2; l2 = l2.next; } else { cur = l1; l1 = l1.next; } head.next = cur; head = head.next; } return res; } "});index.add({'id':98,'href':'/interview/docs/leetcode/mergeRagen/','title':"合并区间",'content':"题目 给出一个区间的集合，请合并所有重叠的区间。\n示例 1: 输入: [[1,3],[2,6],[8,10],[15,18]] 输出: [[1,6],[8,10],[15,18]] 解释: 区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2: 输入: [[1,4],[4,5]] 输出: [[1,5]] 解释: 区间 [1,4] 和 [4,5] 可被视为重叠区间。 解题思路  将区间按起始地址排序 遍历所有区间，如果 Last 与当前区间没有重合，则将当前区间加入结果集合。 如果重合，并且 last.end \u0026lt; t.end，修改 Last 的边界  public List\u0026lt;Interval\u0026gt; merge(List\u0026lt;Interval\u0026gt; intervals) { if (intervals.size() \u0026lt;= 1) { return intervals; } intervals.sort(Comparator.comparingInt(o -\u0026gt; o.start)); List\u0026lt;Interval\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); res.add(intervals.get(0)); for (int i = 1; i \u0026lt; intervals.size(); i++) { Interval t = intervals.get(i); Interval last = res.get(res.size() - 1); if (last.end \u0026gt;= t.start) { if (last.end \u0026lt; t.end) last.end = t.end; } else { res.add(t); } } return res; } "});index.add({'id':99,'href':'/interview/docs/offer/FindContinuousSequence/','title':"和为",'content':"题目 牛客网\n输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序\n解题思路  与上一个题目类似，需要确定的是序列的最大值，不超过 sum 使用窗口模式，两个指针定义一个窗口，和为 t  public ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; FindContinuousSequence(int sum) { ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (sum == 1) { return res; } int start = 1, end = 2; int t = start + end; while (start \u0026lt; end) { if (t == sum) { ArrayList\u0026lt;Integer\u0026gt; ints = new ArrayList\u0026lt;\u0026gt;(); for (int i = start; i \u0026lt;= end; i++) { ints.add(i); } res.add(ints); t -= start; start++; } else if (t \u0026gt; sum) { t -= start; start++; } else { if (end \u0026gt;= sum) break; end++; t += end; } } return res; } "});index.add({'id':100,'href':'/interview/docs/offer/FindNumbersWithSum/','title':"和为",'content':"题目 牛客网\n输入一个递增排序的数组和一个数字S，在数组中查找两个数，使得他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。\n 对应每个测试案例，输出两个数，小的先输出。\n 解题思路  利用二分查找的思想，由于是排序数组，通过两个指针来进行遍历  public ArrayList\u0026lt;Integer\u0026gt; FindNumbersWithSum(int[] array, int sum) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (array == null || array.length == 1) { return res; } int start = 0, end = array.length - 1; int minMulti = Integer.MAX_VALUE; int a = -1, b = -1; while (start \u0026lt; end) { int t = array[start] + array[end]; if (t == sum) { int multi = array[start] * array[end]; if (multi \u0026lt; minMulti) { a = array[start]; b = array[end]; minMulti = multi; } start++; end--; } else if (t \u0026gt; sum) end--; else start++; } if (a == -1 || b == -1) { return res; } res.add(a); res.add(b); return res; } "});index.add({'id':101,'href':'/interview/docs/basic/algo/hash/','title':"哈希",'content':"Hash 哈希表（Hash Table，也叫散列表），是根据关键码值 (Key-Value) 而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。哈希表的实现主要需要解决两个问题，哈希函数和冲突解决。\n哈希函数 哈希函数也叫散列函数，它对不同的输出值得到一个固定长度的消息摘要。理想的哈希函数对于不同的输入应该产生不同的结构，同时散列结果应当具有同一性（输出值尽量均匀）和雪崩效应（微小的输入值变化使得输出值发生巨大的变化）。\n冲突解决  开放地址法：以发生冲突的哈希地址为输入，通过某种哈希冲突函数得到一个新的空闲的哈希地址的方法。有以下几种方式：  线性探查法：从发生冲突的地址开始，依次探查下一个地址，直到找到一个空闲单元。 平方探查法：设冲突地址为d0，则探查序列为：d0+1^2,d0-1^2,d0+2^2\u0026hellip;   拉链法：把所有的同义词用单链表链接起来。在这种方法下，哈希表每个单元中存放的不再是元素本身，而是相应同义词单链表的头指针。HashMap就是使用这种方法解决冲突的。  "});index.add({'id':102,'href':'/interview/docs/offer/LastRemaining/','title':"圆圈中最后剩下的数",'content':"题目 牛客网\n每年六一儿童节,牛客都会准备一些小礼物去看望孤儿院的小朋友,今年亦是如此。HF 作为牛客的资深元老,自然也准备了一些小游戏。其中,有个游戏是这样的:首先,让小朋友们围成一个大圈。然后,他随机指定一个数m,让编号为0的小朋友开始报数。每次喊到m-1的那个小朋友要出列唱首歌,然后可以在礼品箱中任意的挑选礼物,并且不再回到圈中,从他的下一个小朋友开始,继续0\u0026hellip;m-1报数\u0026hellip;.这样下去\u0026hellip;.直到剩下最后一个小朋友,可以不用表演,并且拿到牛客名贵的“名侦探柯南”典藏版。请你试着想下,哪个小朋友会得到这份礼品呢？(注：小朋友的编号是从 0 到 n-1 )\n解题思路 模拟 最简单直接的解法，但是时间效率不够\npublic int LastRemaining_Solution(int n, int m) { if (n == 1) return 1; LinkedList\u0026lt;Integer\u0026gt; data = new LinkedList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { data.addLast(i); } while (data.size() != 1) { for (int i = 0; i \u0026lt; m; i++) { Integer first = data.pollFirst(); if (i != m - 1) { data.addLast(first); } } } return data.pollFirst(); } 通过数学推导的解法 时间效率和空间效率都很高，但是。。。没看懂\n$$ f(n,m)= \\begin{cases} 0\u0026amp;n=1 \\\n[f(n-1,m)+m]%n \u0026amp; n\u0026gt;1 \\end{cases} $$\npublic int LastRemaining_Solution(int n, int m) { if (n == 0) return -1; if (n == 1) return 0; int last = 0; for (int i = 2; i \u0026lt;= n; i++) { last = (last + m) % i; } return last; } "});index.add({'id':103,'href':'/interview/docs/offer/O1DeleteNode/','title':"在",'content':"题目 给定单向链表的头指针以及待删除的指针，定义一个函数在 O(1) 的时间复杂度下删除\n解题思路  待删除节点非尾节点，将后一个节点的值复制到当前节点，然后删除后一个节点 待删除节点为尾节点，从头节点开始，找到待删除节点的前一个节点进行删除  public void O1DeleteNode(ListNode head, ListNode needDelete) { if (needDelete.next != null) { ListNode next = needDelete.next.next; needDelete.val = needDelete.next.val; needDelete.next = next; } else { ListNode cursor = head; while (cursor != null) { if (cursor.next == needDelete) break; cursor = cursor.next; } if (cursor == null) return; cursor.next = needDelete.next; } } "});index.add({'id':104,'href':'/interview/docs/offer/CountOfSortedArray/','title':"在排序数组中查找数字",'content':"题目 统计一个数字在排序数组中出现的次数。\n解题思路  通过二分查找分别找到 n 的第一个位置和最后一个位置 再进行计算就可以得出结果  public int countOfSortedArray2(int[] nums, int n) { if (nums == null || nums.length == 0) return 0; int firstN = getFirstN(nums, n); int lastN = getLastN(nums, n); return lastN - firstN + 1; } private int getFirstN(int[] nums, int n) { int s = 0, e = nums.length - 1; int mid = -1; while (s \u0026lt;= e) { mid = (s + e) / 2; if (mid \u0026gt; 0 \u0026amp;\u0026amp; nums[mid - 1] == n) { e = mid - 1; continue; } if (nums[mid] \u0026gt; n) { e = mid - 1; continue; } if (nums[mid] \u0026lt; n) { s = mid + 1; continue; } break; } return mid; } private int getLastN(int[] nums, int n) { int s = 0, e = nums.length - 1; int mid = -1; while (s \u0026lt;= e) { mid = (s + e) / 2; if (mid \u0026lt; nums.length - 1 \u0026amp;\u0026amp; nums[mid + 1] == n) { s = mid + 1; continue; } if (nums[mid] \u0026gt; n) { e = mid - 1; continue; } if (nums[mid] \u0026lt; n) { s = mid + 1; continue; } break; } return mid; } "});index.add({'id':105,'href':'/interview/docs/leetcode/restoreIpAddresses/','title':"复原",'content':"头条重点\n题目 给定一个只包含数字的字符串，复原它并返回所有可能的 IP 地址格式。\n示例: 输入: \u0026quot;25525511135\u0026quot; 输出: [\u0026quot;255.255.11.135\u0026quot;, \u0026quot;255.255.111.35\u0026quot;] 解题思路  利用回溯法，遍历所有可能的 IP  public static List\u0026lt;String\u0026gt; restoreIpAddresses(String s) { if (s.length() \u0026gt; 12 || s.length() \u0026lt; 4) { return Collections.emptyList(); } List\u0026lt;String\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); ArrayList\u0026lt;String\u0026gt; ip = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 4; i++) { ip.add(\u0026quot;\u0026quot;); } p(res, s.toCharArray(), 0, ip, 0); return res; } private static void p(List\u0026lt;String\u0026gt; res, char[] chars, int startIndex, List\u0026lt;String\u0026gt; ip, int segmentIndex) { StringBuilder builder = new StringBuilder(); for (int i = startIndex; i \u0026lt; chars.length; i++) { builder.append(chars[i]); String ipStr = builder.toString(); int parseInt = Integer.parseInt(ipStr); if (parseInt \u0026gt; 255) { return; } if (ipStr.length() \u0026gt; 1 \u0026amp;\u0026amp; ipStr.startsWith(\u0026quot;0\u0026quot;)) { return; } ip.set(segmentIndex, ipStr); if (segmentIndex == 3 \u0026amp;\u0026amp; i == chars.length - 1) { res.add(String.join(\u0026quot;.\u0026quot;, ip)); } if (segmentIndex \u0026lt; 3) { p(res, chars, i + 1, ip, segmentIndex + 1); } } "});index.add({'id':106,'href':'/interview/docs/offer/CloneLink/','title':"复杂链表的复制",'content':"题目 牛客网\n输入一个复杂链表（每个节点中有节点值，以及两个指针，一个指向下一个节点，另一个特殊指针指向任意一个节点），返回结果为复制后复杂链表的 head 。（注意，输出结果中请不要返回参数中的节点引用，否则判题程序会直接返回空）\n解题思路  复制每个节点，如：复制节点 A 得到 A1 ，将 A1 插入节点 A 后面 遍历链表，并将 A1-\u0026gt;random = A-\u0026gt;random-\u0026gt;next; 将链表拆分成原链表和复制后的链表  public RandomListNode Clone(RandomListNode pHead) { if (pHead == null) { return null; } RandomListNode cursor = pHead; while (cursor != null) { RandomListNode copyNode = new RandomListNode(cursor.label); RandomListNode nextNode = cursor.next; cursor.next = copyNode; copyNode.next = nextNode; cursor = nextNode; } cursor = pHead; while (cursor != null) { RandomListNode copyNode = cursor.next; if (cursor.random == null) { cursor = copyNode.next; continue; } copyNode.random = cursor.random.next; cursor = copyNode.next; } RandomListNode copyHead = pHead.next; cursor = pHead; while (cursor.next != null) { RandomListNode copyNode = cursor.next; cursor.next = copyNode.next; cursor = copyNode; } return copyHead; } "});index.add({'id':107,'href':'/interview/docs/leetcode/checkInclusion/','title':"字符串的排列",'content':"字符串的排列 题目 给定两个字符串 s1 和 s2，写一个函数来判断 s2 是否包含 s1 的排列。\n换句话说，第一个字符串的排列之一是第二个字符串的子串。\n示例1: 输入: s1 = \u0026quot;ab\u0026quot; s2 = \u0026quot;eidbaooo\u0026quot; 输出: True 解释: s2 包含 s1 的排列之一 (\u0026quot;ba\u0026quot;). 解题思路  这道题，我们用到的算法是 滑动窗口 首先字符串s1的排列的可能性应该是它的长度的阶乘，因为字符串长度可能为10000，所以找出所有排列情况是不太可能。 我们可以转换思路，不要关注排列的形式，而是关注排列中元素的数量关系 比如 aab，那么，转换为数量关系就是{a:2,b:1}，因为 S1 长度为 3，所以我们的窗口长度也为3 如果我们在 S2 的找到了这样一个窗口符合出现 a 的次数是两个， b 是一个，那么 S2 就是包含 S1 的排列的  public boolean checkInclusion(String s1, String s2) { int len1 = s1.length(); int len2 = s2.length(); int[] c1 = new int[26]; int[] c2 = new int[26]; for (char c : s1.toCharArray()) { c1[c - 'a']++; } for (int i = 0; i \u0026lt; len2; i++) { if (i \u0026gt;= len1) --c2[s2.charAt(i - len1) - 'a'];//先把坐标查过的减掉 c2[s2.charAt(i) - 'a']++; if (Arrays.equals(c1, c2)) return true; } return false; } "});index.add({'id':108,'href':'/interview/docs/offer/Permutation/','title':"字符串的排列",'content':"题目 牛客网\n输入一个字符串,按字典序打印出该字符串中字符的所有排列。例如输入字符串abc,则打印出由字符a,b,c所能排列出来的所有字符串abc,acb,bac,bca,cab和cba。\n输入描述:输入一个字符串,长度不超过9(可能有字符重复),字符只包括大小写字母。\n解题思路  将字符串划分为两个部分，第一个字符以及后面的其他字符 将第一个字符和后面所有字符进行交换  对于 abc 这个字符串，计算出的排列顺序为：\nabc acb bac bca cba cab 代码：\npublic ArrayList\u0026lt;String\u0026gt; Permutation(String str) { Set\u0026lt;String\u0026gt; res = new HashSet\u0026lt;\u0026gt;(); if (str == null || str.length() == 0) { return new ArrayList\u0026lt;\u0026gt;(); } Permutation(res, str.toCharArray(), 0); ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(res); list.sort(String::compareTo); return list; } private void Permutation(Set\u0026lt;String\u0026gt; res, char[] chars, int start) { if (start == chars.length) { res.add(new String(chars)); return; } for (int i = start; i \u0026lt; chars.length; i++) { swap(chars, start, i); Permutation(res, chars, start + 1); swap(chars, start, i); } } private void swap(char[] chars, int i, int j) { char temp = chars[i]; chars[i] = chars[j]; chars[j] = temp; } "});index.add({'id':109,'href':'/interview/docs/leetcode/StringMultiply/','title':"字符串相乘",'content':"题目 给定两个以字符串形式表示的非负整数 num1 和 num2，返回 num1 和 num2 的乘积，它们的乘积也表示为字符串形式。\n示例 1: 输入: num1 = \u0026quot;2\u0026quot;, num2 = \u0026quot;3\u0026quot; 输出: \u0026quot;6\u0026quot;  num1 和 num2 的长度小于110。 num1 和 num2 只包含数字 0-9。 num1 和 num2 均不以零开头，除非是数字 0 本身。 不能使用任何标准库的大数类型（比如 BigInteger）或直接将输入转换为整数来处理。  解题思路   对于字符串 num2 中的每一位数与字符串 num1 相乘所得的结果，不再分开计算最后相加，而是先全部累加，最后再考虑进位的影响。\n  对于最终结果的第i + j位数，可以由 num1 数组的第 i 位数和 num2 数组的第 j 位数组成。\n  public String multiply(String num1, String num2) { if (num1.length() == 0 || num2.length() == 0) { return ZEO; } if (num1.equals(ZEO) || num2.equals(ZEO)) { return ZEO; } if (num1.equals(ONE)) { return num2; } if (num2.equals(ONE)) { return num1; } int[] num = new int[num1.length() + num2.length() - 1]; Arrays.fill(num, 0); for (int i = 0; i \u0026lt; num1.length(); i++) { for (int j = 0; j \u0026lt; num2.length(); j++) { num[i + j] += (num1.charAt(i) - '0') * (num2.charAt(j) - '0'); } } StringBuilder res = new StringBuilder(); int addIn = 0; for (int i = num.length - 1; i \u0026gt;= 0; i--) { int t = num[i] + addIn; addIn = t / 10; res.append(t % 10); } if (addIn \u0026gt; 0) { res.append(addIn); } return res.reverse().toString(); } "});index.add({'id':110,'href':'/interview/docs/basic/cryptology/','title':"密码学",'content':"密码学 对称加密 对称加密算法的加密和解密使用的密匙是相同的，也就是说如果通讯两方如果使用对称加密算法来加密通讯数据，那么通讯双方就需要都知道这个密匙，收到通讯数据后用这个密匙来解密数据。\n这类算法在加密和解密时使用相同的密钥，或是使用两个可以简单地相互推算的密钥。事实上，这组密钥成为在两个或多个成员间的共同秘密，以便维持专属的通信联系。与非对称加密相比，要求双方获取相同的密钥是对称密钥加密的主要缺点之一。常见的对称加密算法有 DES、3DES、AES、Blowfish、IDEA、RC5、RC6。\n对称加密的速度比公钥加密快很多，在很多场合都需要对称加密。\n非对称加密 它需要两个密钥，一个是公开密钥，另一个是私有密钥；一个用作加密的时候，另一个则用作解密。使用其中一个密钥把明文加密后所得的密文，只能用相对应的另一个密钥才能解密得到原本的明文；甚至连最初用来加密的密钥也不能用作解密。由于加密和解密需要两个不同的密钥，故被称为非对称加密；\n虽然两个密钥在数学上相关，但如果知道了其中一个，并不能凭此计算出另外一个；因此其中一个可以公开，称为 公钥，任意向外发布；不公开的密钥为 私钥 ，必须由用户自行严格秘密保管，绝不透过任何途径向任何人提供，也不会透露给要通信的另一方，即使他被信任。\n 公钥 \u0026amp; 私钥 均可以作为加密密钥\n 数字签名 数字签名是一种类似写在纸上的签名，但是使用了 公钥加密领域的技术实现 ，用于鉴别数字信息的方法。在网络上，我们可以使用“数字签名”来进行身份确认。数字签名是一个独一无二的数值，若公钥能通过验证，那我们就能确定对应的公钥的正确性，数字签名兼具这两种双重属性：\u0026ldquo;可确认性\u0026quot;及\u0026quot;不可否认性（不需要笔迹专家验证）\u0026quot;。\n数字签名就是将公钥密码反过来使用。签名者将讯息用私钥加密（这是一种反用，因为通常非对称加密中私钥用于解密），然后公布公钥;验证者使用公钥将加密讯息解密并比对消息（一般签名对象为消息的散列值）。\n密码散列函数 密码散列函数（英语：Cryptographic hash function），又译为加密散列函数、密码散列函数、加密散列函数，是散列函数的一种。它被认为是一种 单向函数，也就是说极其难以由散列函数输出的结果，回推输入的数据是什么。这种散列函数的输入数据，通常被称为消息（ message ），而它的输出结果，经常被称为消息摘要（ message digest ）或摘要（ digest ）。\n"});index.add({'id':111,'href':'/interview/docs/offer/IsSymmetrical/','title':"对称的二叉树",'content':"题目 请实现一个函数，用来判断一颗二叉树是不是对称的。注意，如果一个二叉树同此二叉树的镜像是同样的，定义其为对称的。\n解题思路  定义一个对称的前序遍历，即root -\u0026gt; right -\u0026gt; left 与普通的前序遍历进行对比 相同则认为树是对称的  boolean isSymmetrical(TreeNode pRoot) { LinkedList\u0026lt;Integer\u0026gt; scanner = new LinkedList\u0026lt;\u0026gt;(); LinkedList\u0026lt;Integer\u0026gt; symmetricalScanner = new LinkedList\u0026lt;\u0026gt;(); preScanner(scanner, pRoot); symmetricalPreScanner(symmetricalScanner, pRoot); return scanner.equals(symmetricalScanner); } /** * 普通的前序遍历 * @param res * @param root */ private void preScanner(LinkedList\u0026lt;Integer\u0026gt; res, TreeNode root) { if (root == null) { res.addLast(null); return; } res.addLast(root.val); preScanner(res, root.left); preScanner(res, root.right); } /** * 先右再左的前序遍历 * @param res * @param root */ private void symmetricalPreScanner(LinkedList\u0026lt;Integer\u0026gt; res, TreeNode root) { if (root == null) { res.addLast(null); return; } res.addLast(root.val); symmetricalPreScanner(res, root.right); symmetricalPreScanner(res, root.left); } "});index.add({'id':112,'href':'/interview/docs/java/jvm/jvm-object-lifecycle/','title':"对象的生命周期",'content':"对象的生命周期 一旦一个类被装载、连接和初始化，它就随时可以被使用。程序可以访问它的静态字段，调用它的静态方法，或者创建它的实例。作为Java程序员有必要了解Java对象的生命周期。\n类实例化 在Java程序中，类可以被明确或隐含地实例化。明确的实例化类有四种途径：\n 明确调用new。 调用Class或者java.lang.reflect.Constructor对象的newInstance方法。 调用任何现有对象的clone。 通过java.io.ObjectInputStream.getObject()反序列化。  隐含的实例化：\n 可能是保存命令行参数的String对象。 对于Java虚拟机装载的每个类，都会暗中实例化一个Class对象来代表这个类型 当Java虚拟机装载了在常量池中包含CONSTANT_String_info入口的类的时候，它会创建新的String对象来表示这些常量字符串。 执行包含字符串连接操作符的表达式会产生新的对象。  Java编译器为它编译的每个类至少生成一个实例初始化方法。在Java class文件中，这个方法被称为\u0026lt;init\u0026gt;。针对源代码中每个类的构造方法，Java编译器都会产生一个\u0026lt;init\u0026gt;()方法。如果类没有明确的声明任何构造方法，编译器会默认产生一个无参数的构造方法，它仅仅调用父类的无参构造方法。\n一个\u0026lt;init\u0026gt;()中可能包含三种代码：调用另一个\u0026lt;init\u0026gt;()、实现对任何实例变量的初始化、构造方法体的代码。\n如果构造方法明确的调用了同一个类中的另一个构造方法(this())，那么它对应的\u0026lt;init\u0026gt;()由两部分组成：\n 一个同类的\u0026lt;init\u0026gt;()的调用。 实现了对应构造方法的方法体的字节码。   在它对应的\u0026lt;init\u0026gt;()方法中不会有父类的\u0026lt;init\u0026gt;()，但不代表不会调用父类的\u0026lt;init\u0026gt;()，因为this()中也会调用父类\u0026lt;init\u0026gt;()\n 如果构造方法不是通过一个this()调用开始的，而且这个对象不是Object，\u0026lt;init\u0026gt;()则有三部分组成：\n 一个父类的\u0026lt;init\u0026gt;()调用。如果这个类是Object,则没有这个部分 任意实例变量初始化方法的字节码。 实现了对应构造方法的方法体的字节码。  如果构造方法明确的调用父类的构造方法super()开始，它的\u0026lt;init\u0026gt;()会调用对应父类的\u0026lt;init\u0026gt;()。比如，如果一个构造方法明确的调用super(int,String)开始，对应的\u0026lt;init\u0026gt;()会从调用父类的\u0026lt;init\u0026gt;(int,String)方法开始。如果构造方法没有明确地从this()或super()开始，对应的\u0026lt;init\u0026gt;()默认会调用父类的无参\u0026lt;init\u0026gt;()。\n垃圾收集和对象的终结 程序可以明确或隐含的为对象分配内存，但不能明确的释放内存。一个对象不再为程序引用，虚拟机必须回收那部分内存。\n卸载类 在很多方面，Java虚拟机中类的生命周期和对象的生命周期很相似。当程序不再使用某个类的时候，可以选择卸载它们。\n 类的垃圾收集和卸载值所以在Java虚拟机中很重要，是因为Java程序可以在运行时通过用户自定义的类装载器装载类型来动态的扩展程序。所有被装载的类型都在方法区占据内存空间。\n Java虚拟机通过判断类是否在被引用来进行垃圾收集。判断动态装载的类的Class实例在正常的垃圾收集过程中是否可触及有两种方式：\n 如果程序保持非Class实例的明确引用。 如果在堆中还存在一个可触及的对象，在方法区中它的类型数据指向一个Class实例。  "});index.add({'id':113,'href':'/interview/docs/leetcode/maxAreaOfIsland/','title':"岛屿的最大面积",'content':"头条重点\n题目 给定一个包含了一些 0 和 1的非空二维数组 grid , 一个 岛屿 是由四个方向 (水平或垂直) 的 1 (代表土地) 构成的组合。你可以假设二维矩阵的四个边缘都被水包围着。\n找到给定的二维数组中最大的岛屿面积。(如果没有岛屿，则返回面积为0。)\n示例 1: [[0,0,1,0,0,0,0,1,0,0,0,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,1,1,0,1,0,0,0,0,0,0,0,0], [0,1,0,0,1,1,0,0,1,0,1,0,0], [0,1,0,0,1,1,0,0,1,1,1,0,0], [0,0,0,0,0,0,0,0,0,0,1,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,0,0,0,0,0,0,1,1,0,0,0,0]] 对于上面这个给定矩阵应返回 6。注意答案不应该是11，因为岛屿只能包含水平或垂直的四个方向的‘1’。 示例 2: [[0,0,0,0,0,0,0,0]] 对于上面这个给定的矩阵, 返回 0。 注意: 给定的矩阵 grid 的长度和宽度都不超过 50。 解题思路  通过循环遍历，找到 1 再通过递归遍历该 1 临近的所有 1，并计算总面积  private static int[][] steps = new int[][]{{1, 0}, {0, 1}, {-1, 0}, {0, -1}}; /** * 上学时做过，属于图的 DFS * @param grid * @return */ public static int maxAreaOfIsland(int[][] grid) { if (grid.length == 0) { return 0; } int[][] marks = new int[grid.length][grid[0].length]; for (int[] mark : marks) { Arrays.fill(mark, 0); } Wrapper\u0026lt;Integer\u0026gt; maxArea = new Wrapper\u0026lt;\u0026gt;(0); for (int i = 0; i \u0026lt; grid.length; i++) { for (int j = 0; j \u0026lt; grid[i].length; j++) { p(grid, marks, i, j, new Wrapper\u0026lt;\u0026gt;(0), maxArea); } } return maxArea.v; } private static void p(int[][] grid, int[][] mark, int i, int j, Wrapper\u0026lt;Integer\u0026gt; curArea, Wrapper\u0026lt;Integer\u0026gt; maxArea) { if (i \u0026lt; 0 || j \u0026lt; 0 || i \u0026gt;= grid.length || j \u0026gt;= grid[0].length) { return; } if (grid[i][j] == 1 \u0026amp;\u0026amp; mark[i][j] == 0) { curArea.v++; maxArea.v = Math.max(maxArea.v, curArea.v); } else { return; } for (int[] step : steps) { mark[i][j] = 1; p(grid, mark, i + step[0], j + step[1], curArea, maxArea); // mark[i][j] = 0; } } private static final class Wrapper\u0026lt;V\u0026gt; { V v; public Wrapper(V v) { this.v = v; } } "});index.add({'id':114,'href':'/interview/docs/offer/LeftRotateString/','title':"左旋转字符串",'content':"题目 牛客网\n汇编语言中有一种移位指令叫做循环左移（ROL），现在有个简单的任务，就是用字符串模拟这个指令的运算结果。对于一个给定的字符序列S，请你把其循环左移K位后的序列输出。例如，字符序列S=”abcXYZdef”,要求输出循环左移3位后的结果，即“XYZdefabc”。是不是很简单？OK，搞定它！\n解题思路  对于 abcXYZdef 左移 3位，可以将字符串分为两个部分：abc \u0026amp; XYZdef 分别将两个部分进行反转得到：cba \u0026amp; fedZYX 将两部分和在一起再进行反转：XYZdefabc  public String LeftRotateString(String str, int n) { if (str == null || str.trim().equals(\u0026quot;\u0026quot;)) return str; String res = revert(str, 0, n - 1); res = revert(res, n, str.length() - 1); res = revert(res, 0, str.length() - 1); return res; } private String revert(String str, int start, int end) { char[] chars = str.toCharArray(); while (start \u0026lt; end) { char t = chars[start]; chars[start] = chars[end]; chars[end] = t; start++; end--; } return new String(chars); } "});index.add({'id':115,'href':'/interview/docs/basic/os/concurrency/','title':"并发",'content':"并发 进程 进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。\n进程的概念主要有两点：\n 进程是一个实体，每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。 进程是一个“执行中的程序”，程序是一个没有生命的实体，只有处理器赋予程序生命时，它才能成为一个活动的实体，我们称其为进程。  进程的基本状态  阻塞态：等待某个事件的完成； 就绪态：等待系统分配处理器以便运行； 执行态：占有处理器正在运行。   执行态 -\u0026gt; 阻塞态：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。\n  阻塞态 -\u0026gt; 就绪态：则是等待的条件已满足，只需分配到处理器后就能运行。\n  执行态 -\u0026gt; 就绪态：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。\n  就绪态 -\u0026gt; 执行态：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态\n 进程调度 调度种类 高级、中级和低级调度作业从提交开始直到完成，往往要经历下述三级调度：\n 高级调度：又称为作业调度，它决定把后备作业调入内存运行； 中级调度：又称为在虚拟存储器中引入，在内、外存对换区进行进程对换。 低级调度：又称为进程调度，它决定把就绪队列的某进程获得CPU；  非抢占式调度与抢占式调度   非抢占式：分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生进程调度进程调度某事件而阻塞时，才把处理机分配给另一个进程。\n  抢占式：操作系统将正在运行的进程强行暂停，由调度程序将CPU分配给其他就绪进程的调度方式。\n  调度策略的设计  响应时间：从用户输入到产生反应的时间 周转时间：从任务开始到任务结束的时间 平均周转时间：周转总时间除以作业个数  CPU任务可以分为交互式任务和批处理任务，调度最终的目标是合理的使用CPU，使得交互式任务的响应时间尽可能短，用户不至于感到延迟，同时使得批处理任务的周转时间尽可能短，减少用户等待的时间。\n调度算法  FCFS：调度的顺序就是任务到达就绪队列的顺序。对短作业不公平。   公平、简单(FIFO队列)、非抢占、不适合交互式。未考虑任务特性，平均等待时间可以缩短\n SJF：最短的作业(CPU区间长度最小)最先调度。   可以证明，SJF可以保证最小的平均等待时间。\n  SRJF：SJF的可抢占版本，比SJF更有优势。  SJF(SRJF): 如何知道下一CPU区间大小？根据历史进行预测: 指数平均法。\n HRN：最高响应比优先法，是FCFS和SJF的综合平衡，响应比R定义如下： R =(W+T)/T 。\n  优先权调度：每个任务关联一个优先权，调度优先权最高的任务。\n   注意：优先权太低的任务一直就绪，得不到运行，出现“饥饿”现象。\n FCFS是RR的特例，SJF是优先权调度的特例。这些调度算法都不适合于交互式系统。\nRound-Robin(RR)：设置一个时间片，按时间片来轮转调度  优点: 定时有响应，等待时间较短；缺点: 上下文切换次数较多；\n 时间片太大，响应时间太长；吞吐量变小，周转时间变长；当时间片过长时，退化为FCFS。\n 多级队列调度   按照一定的规则建立多个进程队列 不同的队列有固定的优先级（高优先级有抢占权） 不同的队列可以给不同的时间片和采用不同的调度方法   存在问题1：没法区分I/O bound和CPU bound；\n  存在问题2：也存在一定程度的“饥饿”现象；\n 多级反馈队列：在多级队列的基础上，任务可以在队列之间移动，更细致的区分任务。可以根据“享用”CPU时间多少来移动队列，阻止“饥饿”。   最通用的调度算法，多数OS都使用该方法或其变形，如UNIX、Windows等。\n 进程同步 临界资源与临界区 在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。\n对于临界资源的访问，必须是互斥进行。也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。而进程内访问临界资源的代码被成为临界区。\n对于临界区的访问过程分为四个部分：\n 进入区:查看临界区是否可访问，如果可以访问，则转到步骤二，否则进程会被阻塞 临界区:在临界区做操作 退出区:清除临界区被占用的标志 剩余区：进程与临界区不相关部分的代码  解决临界区问题可能的方法：\n 一般软件方法 关中断方法 硬件原子指令方法 信号量方法  信号量 信号量是一个确定的二元组（s，q），其中s是一个具有非负初值的整形变量，q是一个初始状态为空的队列，整形变量s表示系统中某类资源的数目：\n 当其值 \u0026gt;= 0 时，表示系统中当前可用资源的数目 当其值 \u0026lt; 0 时，其绝对值表示系统中因请求该类资源而被阻塞的进程数目  除信号量的初值外，信号量的值仅能由P操作和V操作更改，操作系统利用它的状态对进程和资源进行管理\nP操作 P操作记为P(s)，其中s为一信号量，它执行时主要完成以下动作：\ns.value = s.value - 1； /*可理解为占用1个资源，若原来就没有则记帐“欠”1个*/ 若s.value ≥ 0，则进程继续执行，否则（即s.value \u0026lt; 0），则进程被阻塞，并将该进程插入到信号量s的等待队列s.queue中\n 实际上，P操作可以理解为分配资源的计数器，或是使进程处于等待状态的控制指令\n V操作 V操作记为V(s)，其中s为一信号量，它执行时，主要完成以下动作：\ns.value = s.value + 1；/*可理解为归还1个资源，若原来就没有则意义是用此资源还1个欠帐*/ 若s.value \u0026gt; 0，则进程继续执行，否则（即s.value ≤ 0），则从信号量s的等待队s.queue中移出第一个进程，使其变为就绪状态，然后返回原进程继续执行\n 实际上，V操作可以理解为归还资源的计数器，或是唤醒进程使其处于就绪状态的控制指令\n 锁  互斥锁：同一时间只能有一个线程访问加锁的数据。 自旋锁：互斥锁的一种实现，如果自旋锁已经被别的执行单元保持，调用者就一直 循环等待 是否该自旋锁的保持者已经释放了锁。 读写锁：一种特殊的自旋锁，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。写者是排他性的，一个读写锁同时只能有一个写者或多个读者（与CPU数相关），但不能同时既有读者又有写者。 阻塞锁：与自旋锁不同，改变了线程的运行状态。让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进入运行状态。   在Java中synchronized,ReentrantLock,Object.wait() / notify()都属于阻塞锁。\n  可重入锁：也叫做递归锁，指的是同一线程上该锁是可重入的，对于不同线程则相当于普通的互斥锁。 公平锁：加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得。 非公平锁：加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待。ReentrantLock中的lock()默认就是非公平锁。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。加锁的时间可能会很长，也就是说悲观锁的并发访问性不好。 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题，可以通过添加时间戳和版本来来解决。  CAS 比较并交换(compare and swap, CAS)，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作。该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。\n在使用上，通常会记录下某块内存中的旧值，通过对旧值进行一系列的操作后得到新值，然后通过CAS操作将新值与旧值进行交换。如果这块内存的值在这期间内没被修改过，则旧值会与内存中的数据相同，这时CAS操作将会成功执行使内存中的数据变为新值。如果内存中的值在这期间内被修改过，则一般来说旧值会与内存中的数据不同，这时CAS操作将会失败，新值将不会被写入内存。\n死锁 死锁是指多个进程因循环等待资源而造成无法执行的现象。死锁会造成进程无法执行，同时会造成系统资源的极大浪费(资源无法释放)。\n死锁产生的四个必要条件   互斥使用：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。\n  不可抢占：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。\n  请求和保持：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。\n  循环等待：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。\n  死锁避免 银行家算法：判断此次请求是否造成死锁若会造成死锁，则拒绝该请求。\n进程间通信 本地进程间通信的方式有很多，可以总结为下面四类：\n 消息传递（管道、FIFO、消息队列） 同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量） 共享内存（匿名的和具名的） 远程过程调用（Solaris门和Sun RPC）  子进程 在 Unix 和类 Unix 系统中，子进程通常为系统调用 fork 的产物。调用 fork 后的父子进程会运行在不同的内存空间中，当 fork 发生时两者的内存空间有着完全相同的内容，对内存的写入和修改、文件的映射都是独立的，两个进程不会相互影响。除此之外，子进程几乎是父进程的完整副本。\n既然父进程和子进程拥有完全相同的内存空间并且两者对内存的写入都不会相互影响，那么是否意味着子进程在 fork 时需要对父进程的内存进行全量的拷贝呢？\n在一些早期的 *nix 系统上，系统调用 fork 确实会立刻对父进程的内存空间进行复制，但是在今天的多数系统中， fork 并不会立刻触发这一过程，而是在内存被修改时，才会进行数据复制（Copy-On-Write）。\n当 fork 函数调用时，父进程和子进程会被 Kernel 分配到不同的虚拟内存空间中，所以在两个进程看来它们访问的是不同的内存：\n 在真正访问虚拟内存空间时，Kernel 会将虚拟内存映射到物理内存上，所以父子进程共享了物理上的内存空间； 当父进程或者子进程对共享的内存进行修改时，共享的内存才会以页为单位进行拷贝，父进程会保留原有的物理空间，而子进程会使用拷贝后的新物理空间；  线程 线程是 操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。在Unix System V及SunOS中也被称为轻量进程(lightweight processes)，但轻量进程更多指内核线程(kernel thread)，而把用户线程(user thread)称为线程。\n线程是独立调度和分派的基本单位。线程可以操作系统内核调度的内核线程，如Win32线程；由用户进程自行调度的用户线程，如Linux平台的POSIX Thread；或者由内核与用户进程，如Windows 7的线程，进行混合调度。\n同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈，自己的寄存器环境，自己的线程本地存储。\n线程的属性   轻型实体：线程中的实体基本上不拥有系统资源，只是有一点必不可少的、能保证独立运行的资源。线程的实体包括程序、数据和TCB。线程是动态概念，它的动态特性由线程控制块TCB（Thread Control Block）描述。TCB包括以下信息：\n 线程状态。 当线程不运行时，被保存的现场资源。 一组执行堆栈。 存放每个线程的局部变量主存区。 访问同一个进程中的主存和其它资源。  用于指示被执行指令序列的程序计数器、保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈。\n  独立调度和分派的基本单位：在多线程OS中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。由于线程很“轻”，故线程的切换非常迅速且开销小（在同一进程中的）。\n  可并发执行：在一个进程中的多个线程之间，可以并发执行，甚至允许在一个进程中所有线程都能并发执行；同样，不同进程中的线程也能并发执行，充分利用和发挥了处理机与外围设备并行工作的能力。\n  共享进程资源：在同一进程中的各个线程，都可以共享该进程所拥有的资源，这首先表现在：所有线程都具有相同的地址空间（进程的地址空间），这意味着，线程可以访问该地址空间的每一个虚地址；此外，还可以访问进程所拥有的已打开文件、定时器、信号量机构等。由于同一个进程内的线程共享内存和文件，所以线程之间互相通信不必调用内核。\n   线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。\n 线程是程序执行的一条路径，在多线程的OS中，线程是调度和分配的基本单位，而进程是拥有资源的基本单位。\n"});index.add({'id':116,'href':'/interview/docs/java/serilaser/','title':"序列化",'content':"序列化 ProtoBuffer Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。\nProtobuf 的优点  Protobuf 更小、更快、也更简单。你可以定义自己的数据结构，然后使用代码生成器生成的代码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。只需使用 Protobuf 对数据结构进行一次描述，即可利用各种不同语言或从各种不同数据流中对你的结构化数据轻松读写。 “向后”兼容性好，人们不必破坏已部署的、依靠“老”数据格式的程序就可以对数据结构进行升级。这样您的程序就可以不必担心因为消息结构的改变而造成的大规模的代码重构或者迁移的问题。因为添加新的消息中的 field 并不会引起已经发布的程序的任何改变。 Protobuf 语义更清晰，无需类似 XML 解析器的东西（因为 Protobuf 编译器会将 .proto 文件编译生成对应的数据访问类以对 Protobuf 数据进行序列化、反序列化操作）。 Protobuf 的编程模式比较友好，简单易学，同时它拥有良好的文档和示例，对于喜欢简单事物的人们而言，Protobuf 比其他的技术更加有吸引力。  Protobuf 的不足 由于文本并不适合用来描述数据结构，所以 Protobuf 也不适合用来对基于文本的标记文档（如 HTML）建模。另外，由于 XML 具有某种程度上的自解释性，它可以被人直接读取编辑，在这一点上 Protobuf 不行，它以二进制的方式存储，除非你有 .proto 定义，否则你没法直接读出 Protobuf 的任何内容。\n"});index.add({'id':117,'href':'/interview/docs/offer/SerializeTree/','title':"序列化二叉树",'content':"题目 请实现两个函数，分别用来序列化和反序列化二叉树\n解题思路  通过前序遍历，进行序列化和反序列化 对于空节点用 $ 来代替  String Serialize(TreeNode root) { if (root==null) return \u0026quot;\u0026quot;; LinkedList\u0026lt;String\u0026gt; res = new LinkedList\u0026lt;\u0026gt;(); serialize(res, root); StringBuilder builder = new StringBuilder(); res.forEach(v-\u0026gt; builder.append(v).append(\u0026quot;,\u0026quot;)); return builder.toString(); } private void serialize(LinkedList\u0026lt;String\u0026gt; res, TreeNode root) { if (root == null) { res.addLast(\u0026quot;$\u0026quot;); return; } res.addLast(String.valueOf(root.val)); serialize(res, root.left); serialize(res, root.right); } TreeNode Deserialize(String str) { if (str == null || str.length() == 0) return null; return deserialize(str.split(\u0026quot;,\u0026quot;), new int[]{0}); } private TreeNode deserialize(String[] str, int[] index) { if (index[0] \u0026gt;= str.length) return null; String c = str[index[0]++]; if (c.equals(\u0026quot;$\u0026quot;)) return null; TreeNode node = new TreeNode(Integer.valueOf(c)); node.left = deserialize(str, index); node.right = deserialize(str, index); return node; } "});index.add({'id':118,'href':'/interview/docs/offer/isContinuous/','title':"扑克牌顺子",'content':"题目 牛客网\nLL今天心情特别好,因为他去买了一副扑克牌,发现里面居然有 2 个大王, 2 个小王(一副牌原本是 54 张)\u0026hellip;他随机从中抽出了 5 张牌,想测测自己的手气,看看能不能抽到顺子,如果抽到的话,他决定去买体育彩票,嘿嘿！！“红心A,黑桃3,小王,大王,方片5”,“Oh My God!”不是顺子\u0026hellip;..LL不高兴了,他想了想,决定大\\小 王可以看成任何数字,并且A看作1,J为11,Q为12,K为13。上面的5张牌就可以变成“1,2,3,4,5”(大小王分别看作2和4),“So Lucky!”。LL决定去买体育彩票啦。 现在,要求你使用这幅牌模拟上面的过程,然后告诉我们 LL 的运气如何， 如果牌能组成顺子就输出 true，否则就输出 false。为了方便起见,你可以认为大小王是0。\n解题思路  对数组进行排序 计算非0元素之间的间隔总和 如果有相同元素则直接认为失败 如果间隔大于0，那么间隔的总个数等于0的总个数，即为成功  public boolean isContinuous(int[] numbers) { if (numbers == null || numbers.length \u0026lt; 5) return false; Arrays.sort(numbers); int count = 0; int zeroCount = 0; int pre = -1; for (int number : numbers) { if (number == 0) { zeroCount++; continue; } if (pre == -1) pre = number; else { int t = number - pre - 1; if (t \u0026gt; 0) { count += t; } else if (t \u0026lt; 0) return false; pre = number; } } if (count == 0) return true; else return count == zeroCount; } "});index.add({'id':119,'href':'/interview/docs/offer/printn/','title':"打印最大的",'content':"输入n，打印出 1 到最大的 n 位十进制数。比如输入3，则打印出1、2、3 直到最大的 3 位数 999。\n解题思路  n 可能很大，导致输出的数字超过 int 或者 long  public void PrintN(int n) { if (n \u0026lt;= 0) { return; } String res = \u0026quot;0\u0026quot;; while (true) { boolean all9 = true; res = Plus(res, 1); System.out.println(res); for (int i = 0; i \u0026lt; res.length(); i++) { if (res.charAt(i) != '9') { all9 = false; break; } } if (all9 \u0026amp;\u0026amp; res.length() == n) { break; } } } private String Plus(String t, int i) { char[] chars = t.toCharArray(); StringBuilder res = new StringBuilder(); chars[chars.length - 1] += i; boolean flag = false; for (int j = chars.length - 1; j \u0026gt;= 0; j--) { int a = chars[j]; if (flag) { a++; flag = false; } if (a \u0026gt; '9') { flag = true; a = a - '9' + '0' - 1; } res.append((char) a); } if (flag) { res.append('1'); } return res.reverse().toString(); } "});index.add({'id':120,'href':'/interview/docs/offer/TranslateNumToStr/','title':"把数字翻译成字符串",'content':"题目 给定一个数字，按照如下规则翻译成字符串：0 翻译成“a”，1 翻译成“b”… 25翻译成“z”。一个数字有多种翻译可能，例如12258一共有5种，分别是bccfi，bwfi，bczi，mcfi，mzi。实现一个函数，用来计算一个数字有多少种不同的翻译方法。\n解题思路  定义   \\(f(i)\\)  表示第 i 位有多少种翻译的方法，动态规划方程： \\(f(i)=f(i+1)+g(i,i+1) \\times f(i+2)\\)   其中 \\(g(i,i+1)\\)  表示 i,i+1 是否能组成 10 ~ 25  public int translateNumToStr(int num) { char[] str = String.valueOf(num).toCharArray(); int[] res = new int[str.length]; for (int i = str.length - 1; i \u0026gt;= 0; i--) { if (i + 1 \u0026gt;= str.length) { res[i] = 1; continue; } res[i] = res[i + 1]; if (i + 2 \u0026lt; str.length \u0026amp;\u0026amp; str[i] \u0026lt;= '2' \u0026amp;\u0026amp; str[i] \u0026gt;= '1' \u0026amp;\u0026amp; str[i + 1] \u0026lt;= '5') { res[i] += res[i + 2]; } } return res[0]; } "});index.add({'id':121,'href':'/interview/docs/offer/PrintMinNumber/','title':"把数组排成最小的数",'content':"题目 把数组排成最小的数\n输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。\n解题思路  最直接的办法就是，找到数组中数字的所有排列组合，找到最小的 对于   \\(m, n\\)  ，可以组成 \\(mn , nm\\)  这两个数，如果 \\(mn 那么， \\(m\\)  应该在 \\(n\\)  之前 对于一组数，可以通过上述规则进行排序，依次打印出来就是最小的数 由于组合之后的数可能超出 int 的表示范围，注意使用字符串来处理大数问题  public String PrintMinNumber(int[] numbers) { List\u0026lt;String\u0026gt; nums = new ArrayList\u0026lt;\u0026gt;(); for (int number : numbers) { nums.add(String.valueOf(number)); } nums.sort(Comparator.comparing(s -\u0026gt; s, (o1, o2) -\u0026gt; (o1 + o2).compareTo(o2 + o1))); StringJoiner joiner = new StringJoiner(\u0026quot;\u0026quot;); nums.forEach(joiner::add); return joiner.toString(); } "});index.add({'id':122,'href':'/interview/docs/basic/algo/sort/','title':"排序算法",'content':"排序算法 常见排序算法 稳定排序：  冒泡排序 — O(n²) 插入排序 — O(n²) 桶排序 — O(n); 需要 O(k) 额外空间 归并排序 — O(nlogn); 需要 O(n) 额外空间 二叉排序树排序 — O(n log n) 期望时间; O(n²)最坏时间; 需要 O(n) 额外空间 基数排序 — O(n·k); 需要 O(n) 额外空间  不稳定排序  选择排序 — O(n²) 希尔排序 — O(nlogn) 堆排序 — O(nlogn) 快速排序 — O(nlogn) 期望时间, O(n²) 最坏情况; 对于大的、乱数串行一般相信是最快的已知排序  交换排序 冒泡排序 它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。冒泡排序总的平均时间复杂度为O(n^2)。冒泡排序是一种稳定排序算法。\n 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。  void bubble_sort(int a[], int n) { int i, j, temp; for (j = 0; j \u0026lt; n - 1; j++) for (i = 0; i \u0026lt; n - 1 - j; i++) { if(a[i] \u0026gt; a[i + 1]) { temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; } } } 快速排序 快速排序-百度百科 快速排序是一种 不稳定 的排序算法，平均时间复杂度为 O(nlogn)。快速排序使用分治法（Divide and conquer）策略来把一个序列（list）分为两个子序列（sub-lists）。 步骤为：\n 从数列中挑出一个元素，称为\u0026quot;基准\u0026rdquo;（pivot）， 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。   快排的时间花费主要在划分上，所以\n 最坏情况：时间复杂度为O(n^2)。因为最坏情况发生在每次划分过程产生的两个区间分别包含n-1个元素和1个元素的时候。 最好情况：每次划分选取的基准都是当前无序区的中值。如果每次划分过程产生的区间大小都为n/2，则快速排序法运行就快得多了。   public void sort(int[] arr, int low, int high) { int l = low; int h = high; int povit = arr[low]; while (l \u0026lt; h) { while (l \u0026lt; h \u0026amp;\u0026amp; arr[h] \u0026gt;= povit) h--; if (l \u0026lt; h) { arr[l] = arr[h]; l++; } while (l \u0026lt; h \u0026amp;\u0026amp; arr[l] \u0026lt;= povit) l++; if (l \u0026lt; h) { arr[h] = arr[l]; h--; } } arr[l] = povit; System.out.print(\u0026#34;l=\u0026#34; + (l + 1) + \u0026#34;;h=\u0026#34; + (h + 1) + \u0026#34;;povit=\u0026#34; + povit + \u0026#34;\\n\u0026#34;); System.out.println(Arrays.toString(arr)); if (l - 1 \u0026gt; low) sort(arr, low, l - 1); if (h + 1 \u0026lt; high) sort(arr, h + 1, high); } 快排的优化  当待排序序列的长度分割到一定大小后，使用插入排序。 快排函数在函数尾部有两次递归操作，我们可以对其使用尾递归优化。优化后，可以缩减堆栈深度，由原来的O(n)缩减为O(logn)，将会提高性能。 从左、中、右三个数中取中间值。  插入排序 直接插入排序 插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序，时间复杂度为O(n^2)。是稳定的排序方法。 插入算法把要排序的数组分成两部分：第一部分包含了这个数组的所有元素，但将最后一个元素除外（让数组多一个空间才有插入的位置），而第二部分就只包含这一个元素（即待插入元素）。在第一部分排序完成后，再将这个最后元素插入到已排好序的第一部分中。\nvoid insert_sort(int* a, int len) { for (int i = 1; i \u0026lt; len; ++i) { int j = i - 1; int temp = a[i]; while (j \u0026gt;= 0 \u0026amp;\u0026amp; temp \u0026lt; a[j]) { a[j + 1] = a[j]; j--; } a[j + 1] = temp; } } 希尔排序 也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。\n希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。\nvoid shell_sort(int* a, int len) { int step = len / 2; int temp; while (step \u0026gt; 0) { for (int i = step; i \u0026lt; len; ++i) { temp = a[i]; int j = i - step; while (j \u0026gt;= 0 \u0026amp;\u0026amp; temp \u0026lt; a[j]) { a[j + step] = a[j]; j -= step; } a[j + step] = temp; } step /= 2; } } 选择排序 直接选择排序 首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。实际适用的场合非常罕见。\nvoid selection_sort(int arr[], int len) { int i, j, min, temp; for (i = 0; i \u0026lt; len - 1; i++) { min = i; for (j = i + 1; j \u0026lt; len; j++) if (arr[min] \u0026gt; arr[j]) min = j; temp = arr[min]; arr[min] = arr[i]; arr[i] = temp; } } 堆排序 堆排序利用了大根堆（或小根堆）堆顶记录的关键字最大（或最小）这一特征，使得在当前无序区中选取最大（或最小）关键字的记录变得简单。\n 将数组分为有序区和无序区，在无序区中建立最大堆 将堆顶的数据与无序区末尾的数据交换 从后往前，直到所有数据排序完成  public void heapSort(int[] nums) { for (int i = nums.length - 1; i \u0026gt;= 0; i--) { maxHeap(nums, 0, i); swap(nums, 0, i); } } public void maxHeap(int[] heap, int start, int end) { if (start == end) { return; } int parent = start; int childLeft = start * 2 + 1; int childRight = childLeft + 1; if (childLeft \u0026lt;= end) { maxHeap(heap, childLeft, end); if (heap[childLeft] \u0026gt; heap[parent]) { swap(heap, parent, childLeft); } } if (childRight \u0026lt;= end) { maxHeap(heap, childRight, end); if (heap[childRight] \u0026gt; heap[parent]) { swap(heap, parent, childRight); } } } private void swap(int[] nums, int a, int b) { int t = nums[a]; nums[a] = nums[b]; nums[b] = t; } 归并排序 归并排序采用分治的思想：\n Divide：将n个元素平均划分为各含n/2个元素的子序列； Conquer：递归的解决俩个规模为n/2的子问题； Combine：合并俩个已排序的子序列。  性能：时间复杂度总是为O(NlogN)，空间复杂度也总为为O(N)，算法与初始序列无关，排序是稳定的。\npublic void mergeSort(int[] array, int start, int end, int[] temp) { if (start \u0026gt;= end) { return; } int mid = (start + end) / 2; mergeSort(array, start, mid, temp); mergeSort(array, mid + 1, end, temp); int f = start, s = mid + 1; int t = 0; while (f \u0026lt;= mid \u0026amp;\u0026amp; s \u0026lt;= end) { if (array[f] \u0026lt; array[s]) { temp[t++] = array[f++]; } else { temp[t++] = array[s++]; } } while (f \u0026lt;= mid) { temp[t++] = array[f++]; } while (s \u0026lt;= end) { temp[t++] = array[s++]; } for (int i = 0, j = start; i \u0026lt; t; i++) { array[j++] = temp[i]; } } 桶排序 桶排序工作的原理是将 数组分到有限数量的桶 里。每个桶再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。当要被排序的数组内的数值是均匀分配的时候，桶排序使用线性时间   \\(O(n)\\)  。由于桶排序不是比较排序，他不受到 \\(O(n\\log n)\\)  下限的影响。\n桶排序以下列程序进行：\n 设置一个定量的数组当作空桶子。 寻访序列，并且把项目一个一个放到对应的桶子去。 对每个不是空的桶子进行排序。 从不是空的桶子里把项目再放回原来的序列中。  private int indexFor(int a, int min, int step) { return (a - min) / step; } public void bucketSort(int[] arr) { int max = arr[0], min = arr[0]; for (int a : arr) { if (max \u0026lt; a) max = a; if (min \u0026gt; a) min = a; } // 该值可根据实际情况选择 \tint bucketNum = max / 10 - min / 10 + 1; List buckList = new ArrayList\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt;(); // create bucket \tfor (int i = 1; i \u0026lt;= bucketNum; i++) { buckList.add(new ArrayList\u0026lt;Integer\u0026gt;()); } // push into the bucket \tfor (int i = 0; i \u0026lt; arr.length; i++) { int index = indexFor(arr[i], min, 10); ((ArrayList\u0026lt;Integer\u0026gt;) buckList.get(index)).add(arr[i]); } ArrayList\u0026lt;Integer\u0026gt; bucket = null; int index = 0; for (int i = 0; i \u0026lt; bucketNum; i++) { bucket = (ArrayList\u0026lt;Integer\u0026gt;) buckList.get(i); insertSort(bucket); for (int k : bucket) { arr[index++] = k; } } } // 把桶內元素插入排序 private void insertSort(List\u0026lt;Integer\u0026gt; bucket) { for (int i = 1; i \u0026lt; bucket.size(); i++) { int temp = bucket.get(i); int j = i - 1; for (; j \u0026gt;= 0 \u0026amp;\u0026amp; bucket.get(j) \u0026gt; temp; j--) { bucket.set(j + 1, bucket.get(j)); } bucket.set(j + 1, temp); } } 基数排序 对于有d个关键字时，可以分别按关键字进行排序。有俩种方法：\n MSD：先从高位开始进行排序，在每个关键字上，可采用基数排序 LSD：先从低位开始进行排序，在每个关键字上，可采用桶排序   即通过每个数的每位数字的大小来比较\n //找出最大数字的位数 int maxNum(int arr[], int len) { int _max = 0; for (int i = 0; i \u0026lt; len; ++i) { int d = 0; int a = arr[i]; while (a) { a /= 10; d++; } if (_max \u0026lt; d) { _max = d; } } return _max; } void radixSort(int *arr, int len) { int d = maxNum(arr, len); int *temp = new int[len]; int count[10]; int radix = 1; for (int i = 0; i \u0026lt; d; ++i) { for (int j = 0; j \u0026lt; 10; ++j) { count[j] = 0; } for (int k = 0; k \u0026lt; len; ++k) { count[(arr[k] / radix) % 10]++; } for (int l = 1; l \u0026lt; 10; ++l) { count[l] += count[l - 1]; } for (int m = 0; m \u0026lt; len; ++m) { int index = (arr[m] / radix) % 10; temp[count[index] - 1] = arr[m]; count[index]--; } for (int n = 0; n \u0026lt; len; ++n) { arr[n] = temp[n]; } radix *= 10; } delete (temp); } 拓扑排序 在有向图中找拓扑序列的过程，就是拓扑排序。拓扑序列常常用于判定图是否有环。\n 从有向图中选择一个入度为0的结点，输出它。 将这个结点以及该结点出发的所有边从图中删除。 重复前两步，直到没有入度为0的点。   如果所有点都被输出，即存在一个拓扑序列，则图没有环。\n "});index.add({'id':123,'href':'/interview/docs/leetcode/sortList/','title':"排序链表",'content':"头条重点\n题目 在 O(n log n) 时间复杂度和常数级空间复杂度下，对链表进行排序。\n示例 1: 输入: 4-\u0026gt;2-\u0026gt;1-\u0026gt;3 输出: 1-\u0026gt;2-\u0026gt;3-\u0026gt;4 示例 2: 输入: -1-\u0026gt;5-\u0026gt;3-\u0026gt;4-\u0026gt;0 输出: -1-\u0026gt;0-\u0026gt;3-\u0026gt;4-\u0026gt;5 解题思路  通过快慢指针将链表拆分 递归进行拆分，再通过合并两个排序链表的方式进行合并 类似于归并排序  public ListNode sortList(ListNode head) { if (head == null || head.next == null) { return head; } ListNode slow = head, fast = head; while (fast.next != null \u0026amp;\u0026amp; fast.next.next != null) { fast = fast.next.next; slow = slow.next; } ListNode mid = slow.next; slow.next = null; ListNode l1 = sortList(head); ListNode l2 = sortList(mid); return merge(l1, l2); } private ListNode merge(ListNode l1, ListNode l2) { if (l1 == null) { return l2; } if (l2 == null) { return l1; } ListNode head,res; if (l1.val \u0026gt; l2.val) { head = l2; l2 = l2.next; } else { head = l1; l1 = l1.next; } res = head; // head.next = null; while (l1 != null || l2 != null) { if (l1 == null) { head.next = l2; l2 = l2.next; } else if (l2 == null) { head.next = l1; l1 = l1.next; } else { if (l1.val \u0026gt; l2.val) { head.next = l2; l2 = l2.next; } else { head.next = l1; l1 = l1.next; } } head = head.next; } return res; } "});index.add({'id':124,'href':'/interview/docs/leetcode/trap/','title':"接雨水",'content':"头条重点\n题目 给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。\n上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 感谢 Marcos 贡献此图。\n示例: 输入: [0,1,0,2,1,0,1,3,2,1,2,1] 输出: 6 解题思路  首先找到最高点，然后从首尾向中间遍历，找到局部高点，然后就可以计算总量  public int trap(int[] height) { if (height.length \u0026lt;= 2) { return 0; } int max = 0, maxIndex = 0; for (int i = 0; i \u0026lt; height.length; i++) { if (height[i] \u0026gt; max) { max = height[i]; maxIndex = i; } } int total = 0; int topIndex = 0;//局部最高点 for (int i = 0; i \u0026lt; maxIndex; i++) { if (height[topIndex] \u0026lt; height[i]) { topIndex = i; } else { total += height[topIndex] - height[i]; } } topIndex = height.length - 1; for (int i = height.length - 1; i \u0026gt; maxIndex; i--) { if (height[topIndex] \u0026lt; height[i]) { topIndex = i; } else { total += height[topIndex] - height[i]; } } return total; } "});index.add({'id':125,'href':'/interview/docs/offer/search-a-2d-matrix/','title':"搜索二维矩阵",'content':"题目 Leetcode\n编写一个高效的算法来搜索 m x n 矩阵 matrix 中的一个目标值 target。该矩阵具有以下特性：\n 每行的元素从左到右升序排列。 每列的元素从上到下升序排列。  示例:\n现有矩阵 matrix 如下：\n[ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30] ]  给定 target = 5，返回 true。 给定 target = 20，返回 false。  解题思路 二维数组是有规律的：右上角的数字是一列中最小的、一行中最大的，通过这个数字和 target 进行对比，可以将一行或者一列作为候选区域排出，那么 target 可能存在的范围缩小，最终得出结果。\npublic boolean searchMatrix(int[][] matrix, int target) { if (matrix.length == 0) { return false; } for (int i = 0, j = matrix[0].length - 1; i \u0026lt; matrix.length \u0026amp;\u0026amp; j \u0026gt;= 0; ) { if (matrix[i][j] \u0026gt; target) { j--; } else if (matrix[i][j] \u0026lt; target) { i++; } else { return true; } } return false; } "});index.add({'id':126,'href':'/interview/docs/leetcode/searchRote/','title':"搜索旋转排序数组",'content':"头条重点\n题目 假设按照升序排序的数组在预先未知的某个点上进行了旋转。( 例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] )。\n搜索一个给定的目标值，如果数组中存在这个目标值，则返回它的索引，否则返回 -1 。\n你可以假设数组中不存在重复的元素。\n你的算法时间复杂度必须是 O(log n) 级别。\n示例 1: 输入: nums = [4,5,6,7,0,1,2], target = 0 输出: 4 示例 2: 输入: nums = [4,5,6,7,0,1,2], target = 3 输出: -1 解题思路  旋转数组是分为两段有序，主要得注意 mid 落在哪个段上  public static int search(int[] nums, int target) { int start = 0, end = nums.length - 1; while (start \u0026lt;= end) { int mid = (start + end) / 2; if (nums[mid]==target) return mid; if (nums[mid] \u0026gt;= nums[start]) { if (target \u0026lt; nums[mid] \u0026amp;\u0026amp; target \u0026gt;= nums[start]) { end = mid - 1; } else { start = mid + 1; } } if (nums[mid] \u0026lt;= nums[end]) { if (target \u0026gt; nums[mid] \u0026amp;\u0026amp; target \u0026lt;= nums[end]) { start = mid + 1; } else { end = mid - 1; } } } return -1; } "});index.add({'id':127,'href':'/interview/docs/basic/os/','title':"操作系统基础",'content':"操作系统基础 操作系统提供的服务 操作系统的五大功能，分别为：作业管理、文件管理、存储管理、输入输出设备管理、进程及处理机管理\n中断 所谓的中断就是在计算机执行程序的过程中，由于出现了某些特殊事情，使得CPU暂停对程序的执行，转而去执行处理这一事件的程序。等这些特殊事情处理完之后再回去执行之前的程序。中断一般分为三类：\n 内部异常中断：由计算机硬件异常或故障引起的中断； 软中断：由程序中执行了引起中断的指令而造成的中断（这也是和我们将要说明的系统调用相关的中断）； 外部中断：由外部设备请求引起的中断，比如I/O请求。   简单来说，对中断的理解就是对一些特殊事情的处理。\n 与中断紧密相连的一个概念就是中断处理程序了。当中断发生的时候，系统需要去对中断进行处理，对这些中断的处理是由操作系统内核中的特定函数进行的，这些处理中断的特定的函数就是我们所说的中断处理程序了。\n另一个与中断紧密相连的概念就是中断的优先级。中断的优先级说明的是当一个中断正在被处理的时候，处理器能接受的中断的级别。中断的优先级也表明了中断需要被处理的紧急程度。每个中断都有一个对应的优先级，当处理器在处理某一中断的时候，只有比这个中断优先级高的中断可以被处理器接受并且被处理。优先级比这个当前正在被处理的中断优先级要低的中断将会被忽略。\n典型的中断优先级如下所示：\n机器错误 \u0026gt; 时钟 \u0026gt; 磁盘 \u0026gt; 网络设备 \u0026gt; 终端 \u0026gt; 软件中断 当发生软件中断时，其他所有的中断都可能发生并被处理；但当发生磁盘中断时，就只有时钟中断和机器错误中断能被处理了。\n系统调用 在讲系统调用之前，先说下进程的执行在系统上的两个级别：用户级和核心级，也称为用户态和系统态(user mode and kernel mode)。\n程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件等，就需要向操作系统发出调用服务的请求，这就是系统调用。\nLinux系统有专门的函数库来提供这些请求操作系统服务的入口，这个函数库中包含了操作系统所提供的对外服务的接口。当进程发出系统调用之后，它所处的运行状态就会由用户态变成核心态。但这个时候，进程本身其实并没有做什么事情，这个时候是由内核在做相应的操作，去完成进程所提出的这些请求。\n系统调用和中断的关系就在于，当进程发出系统调用申请的时候，会产生一个软件中断。产生这个软件中断以后，系统会去对这个软中断进行处理，这个时候进程就处于核心态了。\n那么用户态和核心态之间的区别是什么呢？\n 用户态的进程能存取它们自己的指令和数据，但不能存取内核指令和数据（或其他进程的指令和数据）。然而，核心态下的进程能够存取内核和用户地址 某些机器指令是特权指令，在用户态下执行特权指令会引起错误  对此要理解的一个是，在系统中内核并不是作为一个与用户进程平行的估计的进程的集合，内核是为用户进程运行的。\n"});index.add({'id':128,'href':'/interview/docs/offer/GetNumberOfK/','title':"数字在排序数组中出现的次数",'content':"题目 牛客网\n统计一个数字在排序数组中出现的次数。\n解题思路  利用二分查找，找到任意一个 k 由于 k 有多个，并且当前找到的 k 可能在任意位置。所以，在当前 k 的前后进行遍历查找  public int GetNumberOfK(int[] array, int k) { if (array == null || array.length == 0) { return 0; } //二分查找 int start = 0, end = array.length - 1; int t = -1; while (start \u0026lt; end) { int mid = (start + end) / 2; if (array[mid] == k) { t = mid; break; } else if (array[mid] \u0026gt; k) { end = mid - 1; } else { start = mid + 1; } } if (array[start] == k) { t = start; } if (t == -1) { return 0; } //左侧 int sum = 0; int a = t; while (a \u0026gt;= 0 \u0026amp;\u0026amp; array[a] == k) { sum++; a--; } //右侧 a = t + 1; while (a \u0026lt; array.length \u0026amp;\u0026amp; array[a] == k) { sum++; a++; } return sum; } "});index.add({'id':129,'href':'/interview/docs/offer/NOfNumberSerialize/','title':"数字序列中的某一位的数字",'content':"题目 数字以0123456789101112131415…的格式序列化到一个字符序列中。在这个序列中，第5位（从0开始计数，即从第0位开始）是5，第13位是1，第19位是4，等等。请写一个函数，求任意第n位对应的数字。\n解题思路  可以将 n 进行拆分，1位数一共10个数字、10位，2位数一共90个数字、180位，依此类推 当确定 n 所在位数范围时，对位数取商，计算出 n 位对应的数字 a，再取余，计算出结果位于 a 的第几位  public int nOfNumberSerialize(int n) { int i = 1; int count = 0; int nLeft = n; while (true) { nLeft -= count; count = countOfIntegers(i) * i; if (nLeft \u0026lt; count) { break; } i++; } int a = nLeft / i; String s = String.valueOf(a); return s.charAt(nLeft % i) - '0'; } private int countOfIntegers(int n) { int sum = 0; if (n == 1) { sum = 10; } else { sum = (int) (9 * Math.pow(10, n - 1)); } return sum; } "});index.add({'id':130,'href':'/interview/docs/offer/StreamMid/','title':"数据流中的中位数",'content':"题目 牛客网\n如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。我们使用 Insert() 方法读取数据流，使用 GetMedian() 方法获取当前读取数据的中位数。\n解题思路  同两个堆来表示中位数的左右两部分，左边是大根堆，右边是小根堆 在插入元素时，两边元素个数最多只能相差1，并且要保证左边的元素均小于右边的元素 当插入大堆的元素大于部分小堆元素时，需要将大堆的 top 元素移动到小堆，反之亦然  private PriorityQueue\u0026lt;Integer\u0026gt; maxHeap = new PriorityQueue\u0026lt;\u0026gt;((o1, o2) -\u0026gt; -o1.compareTo(o2)); private PriorityQueue\u0026lt;Integer\u0026gt; minHeap = new PriorityQueue\u0026lt;\u0026gt;(); private int size = 0; public void Insert(Integer num) { if (size % 2 == 0) { maxHeap.add(num); if (minHeap.isEmpty() || num \u0026gt; minHeap.peek()) { minHeap.add(maxHeap.poll()); } } else { minHeap.add(num); if (maxHeap.isEmpty() || num \u0026lt; maxHeap.peek()) { maxHeap.add(minHeap.poll()); } } size++; } public Double GetMedian() { if (maxHeap.isEmpty() \u0026amp;\u0026amp; minHeap.isEmpty()) return 0.0; if (maxHeap.isEmpty()) return minHeap.peek() * 1.0; if (minHeap.isEmpty()) return maxHeap.peek() * 1.0; if (maxHeap.size() == minHeap.size()) { return (maxHeap.peek() + minHeap.peek()) / 2.0; } return maxHeap.size() \u0026gt; minHeap.size() ? maxHeap.peek() * 1.0 : minHeap.peek() * 1.0; } "});index.add({'id':131,'href':'/interview/docs/offer/MoreThanHalfNum/','title':"数组中出现次数超过一半的数字",'content':"题目 牛客网\n数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。例如输入一个长度为9的数组{1,2,3,2,2,2,5,4,2}。由于数字2在数组中出现了5次，超过数组长度的一半，因此输出 2 。如果不存在则输出 0 。\n解题思路  由于数组的特性，在排序数组中，超过半数的数字一定包含中位数 通过 partition 方法，借用快排的思想，随机选取一个 key，将数组中小于 key 的移动到 key 的左侧，数组中大于 key 的移动到 key 的右侧 最终找到中位数的下标，还需要检查中位数是否超过半数  public int MoreThanHalfNum_Solution(int[] array) { int start = 0, end = array.length - 1; int mid = array.length / 2; int index = partition(array, start, end); if (index == mid) { return array[index]; } while (index != mid \u0026amp;\u0026amp; start \u0026lt;= end) { if (index \u0026gt; mid) { end = index - 1; index = partition(array, start, end); } else { start = index + 1; index = partition(array, start, end); } } if (checkIsHalf(array, index)) return array[index]; return 0; } private boolean checkIsHalf(int[] array, int index) { if (index \u0026lt; 0) { return false; } int count = 0; for (int i : array) { if (array[index] == i) { count++; } } return count \u0026gt; array.length / 2; } private int partition(int[] array, int start, int end) { if (start \u0026gt;= array.length || start \u0026lt; 0 || end \u0026gt;= array.length || end \u0026lt; 0) { return -1; } int key = array[start]; int left = start, right = end; while (left \u0026lt; right) { while (left \u0026lt; right \u0026amp;\u0026amp; array[right] \u0026gt;= key) { right--; } if (left \u0026lt; right) { array[left] = array[right]; left++; } while (left \u0026lt; right \u0026amp;\u0026amp; array[left] \u0026lt;= key) { left++; } if (left \u0026lt; right) { array[right] = array[left]; right--; } } array[left] = key; return left; } "});index.add({'id':132,'href':'/interview/docs/offer/FindNumsAppearOnce/','title':"数组中只出现一次的数字",'content':"题目 牛客网\n一个整型数组里除了两个数字之外，其他的数字都出现了两次。请写程序找出这两个只出现一次的数字。\n解题思路  两个相等的数字进行异或的结果为0 在这个特殊的数组中，重复出现的数字只能为2次，那么如果将所有数字异或 就等价与将两个不同的数字进行异或 异或的结果肯定有一位为1，那么这两个不同的数字，在这一位上不同。 找到第一个为1的位，并将第一位为1的位是否为1作为分组条件，相同的数字一定在同一个分组里，整个数组分组异或 得到两个结果，即为两个不同的数  /** * num1,num2分别为长度为1的数组。传出参数。将num1[0],num2[0]设置为返回结果 * @param array * @param num1 * @param num2 */ public void FindNumsAppearOnce(int[] array, int num1[], int num2[]) { if (array == null || array.length \u0026lt; 3) { return; } int result = array[0]; for (int i = 1; i \u0026lt; array.length; i++) { result ^= array[i]; } //找到第一个为1的位 int indexOfFirstBit1 = 0; int temp = result; while (temp != 0) { indexOfFirstBit1++; temp \u0026gt;\u0026gt;\u0026gt;= 1; } int mask = 1; for (int i = 1; i \u0026lt; indexOfFirstBit1; i++) { mask \u0026lt;\u0026lt;= 1; } //将第一位为1的位是否为1作为分组条件，分组异或 int n1 = -1, n2 = -1; for (int i : array) { if ((i \u0026amp; mask) == mask) { if (n1 == -1) n1 = i; else n1 ^= i; } else { if (n2 == -1) n2 = i; else n2 ^= i; } } num1[0] = n1; num2[0] = n2; } "});index.add({'id':133,'href':'/interview/docs/leetcode/findKthLargest/','title':"数组中的第K个最大元素",'content':"数组中的第K个最大元素 题目 在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。\n示例 1: 输入: [3,2,1,5,6,4] 和 k = 2 输出: 5 示例 2: 输入: [3,2,3,1,2,4,5,5,6] 和 k = 4 输出: 4 解题思路  利用快排的思想，当排序到 k 后，停止排序，输出结果  public static int findKthLargest(int[] nums, int k) { fastSort(nums, 0, nums.length - 1); return nums[nums.length - k]; } public static void fastSort(int[] nums, int start, int end) { if (nums.length \u0026lt;= 1) { return; } if (start \u0026gt; end) { return; } if (end \u0026lt; 0 || start \u0026lt; 0 || end \u0026gt; nums.length - 1 || start \u0026gt; nums.length - 1) { return; } int left = start, right = end; int keyIndex = (left + right) / 2; while (left \u0026lt; right) { while (right \u0026gt; keyIndex \u0026amp;\u0026amp; nums[right] \u0026gt; nums[keyIndex]) { right--; } if (right \u0026gt; keyIndex) { swap(nums, keyIndex, right); keyIndex = right; } while (left \u0026lt; keyIndex \u0026amp;\u0026amp; nums[left] \u0026lt; nums[keyIndex]) { left++; } if (left \u0026lt; keyIndex) { swap(nums, left, keyIndex); keyIndex = left; } left++; } fastSort(nums, keyIndex + 1, end); fastSort(nums, start, keyIndex - 1); } "});index.add({'id':134,'href':'/interview/docs/offer/InversePairs/','title':"数组中的逆序对",'content':"题目 牛客网\n在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组,求出这个数组中的逆序对的总数P。并将P对1000000007取模的结果输出。 即输出P%1000000007\n输入描述: 题目保证输入的数组中没有的相同的数字\n数据范围：\n\t对于%50的数据,size\u0026lt;=10^4 对于%75的数据,size\u0026lt;=10^5 对于%100的数据,size\u0026lt;=2*10^5 解题思路 1. 使用归并排序的方式，划分子数组 2. 两个子数组进行对比，有两个分别指向两个数组末尾的指针 `f,s`，数组分割下标为 `mid`，如果 `array[f] \u0026gt; array[s]`那么，就有`s - mid`个 `array[f]` 的逆序 3. 依此类推，最终将数组排序，并且获得结果  public int InversePairs(int[] array) { long[] sum = {0}; if (array == null || array.length == 0) { return (int) sum[0]; } int[] temp = new int[array.length]; mergeSort(array, 0, array.length - 1, temp, sum); return (int) (sum[0] % 1000000007); } private void mergeSort(int[] array, int start, int end, int[] temp, long[] sum) { if (start == end) { return; } int mid = (start + end) / 2; mergeSort(array, start, mid, temp, sum); mergeSort(array, mid + 1, end, temp, sum); int f = mid, s = end; int t = end; while (f \u0026gt;= start \u0026amp;\u0026amp; s \u0026gt;= mid + 1) { if (array[f] \u0026gt; array[s]) { temp[t--] = array[f--]; sum[0] += s - mid; } else { temp[t--] = array[s--]; } } while (f \u0026gt;= start) { temp[t--] = array[f--]; } while (s \u0026gt;= mid + 1) { temp[t--] = array[s--]; } for (int i = end, j = end; i \u0026gt;= start; ) { array[j--] = temp[i--]; } } "});index.add({'id':135,'href':'/interview/docs/offer/Duplicate/','title':"数组中重复的数字",'content':"题目 在一个长度为n的数组里的所有数字都在0到 n-1 的范围内。 数组中某些数字是重复的，但不知道有几个数字是重复的。也不知道每个数字重复几次。请找出数组中任意一个重复的数字。 例如，如果输入长度为7的数组{2,3,1,0,2,5,3}，那么对应的输出是第一个重复的数字2。\n解题思路 解法一  由于数组内数字在 0 ~ n-1 的范围内，可以将数组按 数字做下标 进行重排序 将 n 放置到 num[n] 上，交换之前再判定在 num[n] 上是否为相同数字  public boolean duplicate(int numbers[], int length, int[] duplication) { if (numbers == null || numbers.length == 0) return false; for (int i = 0; i \u0026lt; numbers.length; i++) { while (numbers[i] != i) { int number = numbers[i]; int wrongNum = numbers[number]; if (number == wrongNum) { duplication[0] = number; return true; } swap(numbers, i, number); } } return false; } private static void swap(int[] nums, int i, int j) { int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; } 解法二  把数字 1 ~ n 划分为 1 ~ m、m+1 ~ n，统计两个子数组中每个数字在 1~n 出现的次数 如果出现的次数大于 m，那么重复数字一定在 1 ~ m 中 继续这样进行划分，可以找到重复数组  "});index.add({'id':136,'href':'/interview/docs/offer/NumberOfOneBetweenOneAndN/','title':"整数中",'content':"题目 牛客网\n求出1~13的整数中 1 出现的次数,并算出 100~1300 的整数中1出现的次数？为此他特别数了一下 1~13 中包含1的数字有 1、10、11、12、13 因此共出现 6 次,但是对于后面问题他就没辙了。ACMer 希望你们帮帮他,并把问题更加普遍化,可以很快的求出任意非负整数区间中1出现的次数（从1 到 n 中1出现的次数）。\n解题思路  假定   \\(n=21345\\)  将数字分为首位和非首位两个部分 对于首位为 1 的情况，如果首位 \\(1\\)  那么 \\(sum=sum+10^{len(n)-1}\\)  ，如果首位 \\(=1\\)  那么 \\(sum=sum+1\\)   对于非首位 1，指定其中一位为 1，根据排列组合有 \\(10^{len(n)-2}\\times(len(n)-1)\\)  个。那么非首位 1 总共有 \\(2\\times10^{len(n)-2}\\times(len(n)-1)\\)    public int NumberOf1Between1AndN_Solution(int n) { int[] res = {0}; NumberOf1Between1AndN(res, n); return res[0]; } private void NumberOf1Between1AndN(int[] res, int n) { //假设 num=21345 String num = String.valueOf(n); int firstNum = num.charAt(0) - '0'; if (num.length() == 1) { if (firstNum \u0026gt; 0) res[0]++; return; } String nextNum = num.substring(1); int nextN = Integer.valueOf(nextNum); //数字 10000 ～ 19999 的第一位中的个数 if (firstNum \u0026gt; 1) { res[0] += Math.pow(10, num.length() - 1); } else if (firstNum == 1) { res[0] += nextN + 1; } //1346 ～ 21345 除第一位之外的数的个数 res[0] += firstNum * (num.length() - 1) * Math.pow(10, num.length() - 2); NumberOf1Between1AndN(res, nextN); } "});index.add({'id':137,'href':'/interview/docs/offer/fibonacci/','title':"斐波纳切数列",'content':"题目 牛客网\n大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。n\u0026lt;=39\n解题思路  递归计算很慢，是最简单的算法  public int Fibonacci(int n) { if (n == 0) { return 0; } if (n == 1) { return 1; } int l = 1, ll = 0; for (int i = 2; i \u0026lt;= n; i++) { int t = ll + l; ll = l; l = t; } return l; } "});index.add({'id':138,'href':'/interview/docs/offer/find-minimum-in-rotated-sorted-array/','title':"旋转数组的最小数字",'content':"题目 牛客网\n把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非减排序的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。\n解题思路  旋转之后的数组存在两个上升序列，最小元素在两个上升序列的中间 用两个指针在两个序列中找到最大和最小的值，这样 end 指向的数则为最小  public int minNumberInRotateArray(int[] array) { if (array.length == 0) { return 0; } int start = 0, end = array.length - 1; while (end - start != 1) { int mid = (start + end) / 2; if (array[mid] \u0026gt;= array[start]) { start = mid; } if (array[mid] \u0026lt;= array[end]) { end = mid; } } return array[end]; } "});index.add({'id':139,'href':'/interview/docs/leetcode/lengthOfLongestSubstring/','title':"无重复字符的最长子串",'content':"头条重点\n题目 给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。\n输入: \u0026quot;abcabcbb\u0026quot; 输出: 3 解释: 因为无重复字符的最长子串是 \u0026quot;abc\u0026quot;，所以其长度为 3。 解题思路  用 Map 记录字符所在位置，当遇到重复字符时，移动 start 指针 替换 Map 中下标，并计算子串长度  public int lengthOfLongestSubstring(String str) { if (str == null || str.length() == 0) return 0; HashMap\u0026lt;Character, Integer\u0026gt; temp = new HashMap\u0026lt;\u0026gt;(); char[] chars = str.toCharArray(); int res = 0, start = 0; for (int i = 0; i \u0026lt; chars.length; i++) { if (temp.containsKey(chars[i])) { start = Math.max(temp.put(chars[i], i) + 1, start); } temp.put(chars[i], i); res = Math.max(res, i - start + 1); } return res; } "});index.add({'id':140,'href':'/interview/docs/offer/replay-space/','title':"替换空格",'content':"题目 牛客网\n请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为 We%20Are%20Happy。\n解题思路  通过字符串中空格的个数，计算新字符串长度 两个指针进行字符串拷贝，当遇到‘ ’时替换为 %20  public String replaceSpace(StringBuffer str) { char[] chars = str.toString().toCharArray(); StringBuilder res = new StringBuilder(); for (char c : chars) { if (c == ' ') res.append(\u0026quot;%20\u0026quot;); else res.append(c); } return res.toString(); } "});index.add({'id':141,'href':'/interview/docs/leetcode/maxSubArray/','title':"最大子序和",'content':"头条重点\n题目 给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n示例: 输入: [-2,1,-3,4,-1,2,1,-5,4], 输出: 6 解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。 进阶: 如果你已经实现复杂度为 O(n) 的解法，尝试使用更为精妙的分治法求解。\n解题思路   动态规划：   \\(f(i)=\\begin{cases}num[i]\u0026f(i-1)+num[i]num[i]\\end{cases}\\)    用result[i]保存以数字nums[i]结尾的最大子序和，然后不断更新result数组的最大值即可。总的时间复杂度O(n)\n  public int maxSubArray(int[] nums) { if (nums.length == 0) { return 0; } if (nums.length == 1) { return nums[0]; } int[] res = new int[nums.length]; res[0] = nums[0]; int max = res[0]; for (int i = 1; i \u0026lt; nums.length; i++) { int curMax = nums[i] + res[i - 1]; if (curMax \u0026gt; nums[i]) { res[i] = curMax; } else { res[i] = nums[i]; } max = Math.max(max, res[i]); } return max; } "});index.add({'id':142,'href':'/interview/docs/leetcode/MinStack/','title':"最小栈",'content':"头条重点\n题目 设计一个支持 push，pop，top 操作，并能在常数时间内检索到最小元素的栈。\npush(x) \u0026ndash; 将元素 x 推入栈中。 pop() \u0026ndash; 删除栈顶的元素。 top() \u0026ndash; 获取栈顶元素。 getMin() \u0026ndash; 检索栈中的最小元素。\n示例: MinStack minStack = new MinStack(); minStack.push(-2); minStack.push(0); minStack.push(-3); minStack.getMin(); --\u0026gt; 返回 -3. minStack.pop(); minStack.top(); --\u0026gt; 返回 0. minStack.getMin(); --\u0026gt; 返回 -2. 解题思路 class MinStack { /** initialize your data structure here. */ public MinStack() { } private LinkedList\u0026lt;Integer\u0026gt; stack = new LinkedList\u0026lt;\u0026gt;(); private Queue\u0026lt;Integer\u0026gt; minStack = new PriorityQueue\u0026lt;\u0026gt;(); public void push(int x) { stack.offerFirst(x); minStack.offer(x); } public void pop() { Integer poll = stack.pollFirst(); if (poll != null) { minStack.remove(poll); } } public int top() { Integer first = stack.peekFirst(); return first == null ? 0 : first; } public int getMin() { Integer first = minStack.peek(); return first == null ? 0 : first; } } "});index.add({'id':143,'href':'/interview/docs/basic/algo/mst/','title':"最小生成树算法",'content':"最小生成树算法   连通图：在无向图G中，若从顶点i到顶点j有路径，则称顶点i和顶点j是连通的。若图G中任意两个顶点都连通，则称G为连通图。\n  生成树：一个连通图的生成树是该连通图的一个极小连通子图，它含有全部顶点，但只有构成一个数的(n-1)条边。\n  最小生成树：对于一个带权连通无向图G中的不同生成树，各树的边上的 权值之和最小。构造最小生成树的准则有三条：\n 必须只使用该图中的边来构造最小生成树。 必须使用且仅使用(n-1)条边来连接图中的n个顶点。 不能使用产生回路的边。    Prim算法 假设G=(V,E)是一个具有n个顶点的带权连通无向图，T(U,TE)是G的最小生成树，其中U是T的顶点集，TE是T的边集，则由G构造从起始顶点v出发的最小生成树T的步骤为：\n  初始化U={v}，以v到其他顶点的所有边为候选边(U中所有点到其他顶点的边)。\n  重复以下步骤(n-1)次，使得其他(n-1)个顶点被加入到U中。\n  从候选边中挑选权值最小的边加入TE，设该边在V-U(这里是集合减)中的顶点是k，将k加入U中。\n  考察当前V-U中的所有顶点j，修改候选边，若边(k,j)的权值小于原来和顶点j关联的候选边，则用(k,j)取代后者作为候选边。\n    Kruskal算法 假设G=(V,E)是一个具有n个顶点的带权连通无向图，T(U,TE)是G的最小生成树，其中U是T的顶点集，TE是T的边集，则由G构造从起始顶点v出发的最小生成树T的步骤为：\n  置U的初始值等于V(即包含G中的全部顶点)，TE的初始值为空\n  将图G中的边按权值从小到大的顺序依次选取，若选取的边未使生成树T形成回路，则加入TE，否则放弃，知道TE中包含(n-1)条边为止。\n  "});index.add({'id':144,'href':'/interview/docs/offer/GetLeastNumbers/','title':"最小的",'content':"题目 牛客网\n输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。\n解题思路 Partition 该算法基于 Partition\npublic ArrayList\u0026lt;Integer\u0026gt; GetLeastNumbers_Solution_Partition(int[] input, int k) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (k \u0026gt; input.length || k \u0026lt; 1) { return res; } int start = 0, end = input.length - 1; int index = partition(input, start, end); while (index != k - 1) { if (index \u0026gt; k - 1) { end = index - 1; index = partition(input, start, end); } else { start = index + 1; index = partition(input, start, end); } } for (int i = 0; i \u0026lt; input.length \u0026amp;\u0026amp; i \u0026lt; k; i++) { res.add(input[i]); } return res; } private int partition(int[] nums, int start, int end) { int left = start, right = end; int key = nums[left]; while (left \u0026lt; right) { while (left \u0026lt; right \u0026amp;\u0026amp; nums[right] \u0026gt; key) { right--; } if (left \u0026lt; right) { nums[left] = nums[right]; left++; } while (left \u0026lt; right \u0026amp;\u0026amp; nums[left] \u0026lt;= key) { left++; } if (left \u0026lt; right) { nums[right] = nums[left]; right++; } } nums[left] = key; return left; } 小根堆算法 该算法基于小根堆，适合海量数据，时间复杂度为：n*logk\npublic ArrayList\u0026lt;Integer\u0026gt; GetLeastNumbers_Solution(int[] input, int k) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (k \u0026gt; input.length||k==0) { return res; } for (int i = input.length - 1; i \u0026gt;= 0; i--) { minHeap(input, 0, i); swap(input, 0, i); res.add(input[i]); if (res.size() == k) break; } return res; } private void minHeap(int[] heap, int start, int end) { if (start == end) { return; } int childLeft = start * 2 + 1; int childRight = childLeft + 1; if (childLeft \u0026lt;= end) { minHeap(heap, childLeft, end); if (heap[childLeft] \u0026lt; heap[start]) { swap(heap, start, childLeft); } } if (childRight \u0026lt;= end) { minHeap(heap, childRight, end); if (heap[childRight] \u0026lt; heap[start]) { swap(heap, start, childRight); } } } private void swap(int[] nums, int a, int b) { int t = nums[a]; nums[a] = nums[b]; nums[b] = t; } "});index.add({'id':145,'href':'/interview/docs/offer/GetLeastNumbersSolution/','title':"最小的",'content':"题目 牛客网\n输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。\n解题思路  利用堆排序原理，计算出最小的 k 个数  public ArrayList\u0026lt;Integer\u0026gt; GetLeastNumbers_Solution(int[] input, int k) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (k \u0026gt; input.length || k == 0) { return res; } for (int i = input.length - 1; i \u0026gt;= 0; i--) { minHeap(input, 0, i); swap(input, 0, i); res.add(input[i]); if (res.size() == k) break; } return res; } private void minHeap(int[] heap, int start, int end) { if (start == end) { return; } int childLeft = start * 2 + 1; int childRight = childLeft + 1; if (childLeft \u0026lt;= end) { minHeap(heap, childLeft, end); if (heap[childLeft] \u0026lt; heap[start]) { swap(heap, start, childLeft); } } if (childRight \u0026lt;= end) { minHeap(heap, childRight, end); if (heap[childRight] \u0026lt; heap[start]) { swap(heap, start, childRight); } } } private void swap(int[] nums, int a, int b) { int t = nums[a]; nums[a] = nums[b]; nums[b] = t; } "});index.add({'id':146,'href':'/interview/docs/basic/algo/path/','title':"最短路径算法",'content':"最短路径算法 Dijkstra —— 贪心算法  从一个顶点到其余顶点的最短路径\n 设G=(V,E)是一个带权有向图，把图中顶点集合V分成两组，第1组为已求出最短路径的顶点（用S表示，初始时S只有一个源点，以后每求得一条最短路径v,...k，就将k加到集合S中，直到全部顶点都加入S）。第2组为其余未确定最短路径的顶点集合（用U表示），按最短路径长度的递增次序把第2组的顶点加入S中。\n步骤： 1. 初始时，S只包含源点，即`S={v}`，顶点v到自己的距离为0。U包含除v外的其他顶点，v到U中顶点i的距离为边上的权。 2. 从U中选取一个顶点u，顶点v到u的距离最小，然后把顶点u加入S中。 3. 以顶点u为新考虑的中间点，修改v到U中各个点的距离。 4. 重复以上步骤知道S包含所有顶点。 Floyd —— 动态规划 Floyd 算法是解决任意两点间的最短路径的一种算法，可以正确处理有向图或负权（但不可存在负权回路）的最短路径问题。该算法的时间复杂度为   \\(O(N^{3})\\)  ，空间复杂度为 \\(O(N^{2})\\)  设 \\(D_{i,j,k}\\)  为从 \\(i\\)  到 \\(j\\)  的只以 \\((1..k)\\)  集合中的节点为中间节点的最短路径的长度。\n$$ D_{i,j,k}=\\begin{cases} D_{i,j,k-1} \u0026amp; 最短路径不经过 k\\\nD_{i,k,k-1}+D_{k,j,k-1} \u0026amp; 最短路径经过 k \\end{cases} $$\n因此， \\(D_{i,j,k}=min(D_{i,k,k-1}+D_{k,j,k-1},D_{i,j,k-1})\\)  。伪代码描述如下：\n// let dist be a |V| × |V| array of minimum distances initialized to ∞ (infinity) for each vertex v dist[v][v] ← 0 for each edge (u,v) dist[u][v] ← w(u,v) // the weight of the edge (u,v) for k from 1 to |V| for i from 1 to |V| for j from 1 to |V| if dist[i][j] \u0026gt; dist[i][k] + dist[k][j] dist[i][j] ← dist[i][k] + dist[k][j] end if "});index.add({'id':147,'href':'/interview/docs/offer/LongestNoRepeatSubString/','title':"最长不含重复字符的子字符串",'content':"题目 LeetCode\n给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。\n输入: \u0026quot;abcabcbb\u0026quot; 输出: 3 解释: 因为无重复字符的最长子串是 \u0026quot;abc\u0026quot;，所以其长度为 3。 解题思路  用 Map 记录字符所在位置，当遇到重复字符时，移动 start 指针 替换 Map 中下标，并计算子串长度  public int longestNoRepeatSubString(String str) { if (str == null || str.length() == 0) return 0; HashMap\u0026lt;Character, Integer\u0026gt; temp = new HashMap\u0026lt;\u0026gt;(); char[] chars = str.toCharArray(); int res = 0, start = 0; for (int i = 0; i \u0026lt; chars.length; i++) { if (temp.containsKey(chars[i])) { start = Math.max(temp.put(chars[i], i) + 1, start); } temp.put(chars[i], i); res = Math.max(res, i - start + 1); } return res; } "});index.add({'id':148,'href':'/interview/docs/leetcode/longestCommonPrefix/','title':"最长公共前缀",'content':"题目 编写一个函数来查找字符串数组中的最长公共前缀。\n如果不存在公共前缀，返回空字符串 \u0026ldquo;\u0026quot;。\n示例 1: 输入: [\u0026quot;flower\u0026quot;,\u0026quot;flow\u0026quot;,\u0026quot;flight\u0026quot;] 输出: \u0026quot;fl\u0026quot; 解题思路  找到最短字符串 多个字符串逐个字符比较  public String longestCommonPrefix(String[] strs) { if (strs.length == 0) { return \u0026quot;\u0026quot;; } int minLen = strs[0].length(); for (String str : strs) { minLen = Math.min(minLen, str.length()); } char[][] data = new char[strs.length][minLen]; for (int i = 0; i \u0026lt; strs.length; i++) { char[] chars = strs[i].toCharArray(); System.arraycopy(chars, 0, data[i], 0, minLen); } StringBuilder res = new StringBuilder(); for (int i = 0; i \u0026lt; minLen; i++) { for (int j = 1; j \u0026lt; data.length; j++) { if (data[j - 1][i] != data[j][i]) { return res.toString(); } } res.append(data[0][i]); } return res.toString(); } "});index.add({'id':149,'href':'/interview/docs/leetcode/longestConsecutive/','title':"最长连续序列",'content':"题目 给定一个未排序的整数数组，找出最长连续序列的长度。\n要求算法的时间复杂度为 O(n)。\n示例: 输入: [100, 4, 200, 1, 3, 2] 输出: 4 解释: 最长连续序列是 [1, 2, 3, 4]。它的长度为 4。 解题思路  用 Set 保存所有数字 遍历数组，查找当前数字之前、之后的数，并计算个数  public static int longestConsecutive(int[] nums) { if (nums.length \u0026lt;= 1) { return nums.length; } Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); for (int num : nums) { set.add(num); } int pre, after, max = 0; for (int num : nums) { int temp = 1; set.remove(num); pre = num; after = num; while (set.contains(--pre)) { temp++; set.remove(pre); } while (set.contains(++after)) { temp++; set.remove(after); } max = Math.max(max, temp); if (max \u0026gt; nums.length / 2) { return max; } } return max; } "});index.add({'id':150,'href':'/interview/docs/leetcode/findLengthOfLCIS/','title':"最长连续递增序列",'content':"题目 给定一个未经排序的整数数组，找到最长且连续的的递增序列。\n示例 1: 输入: [1,3,5,4,7] 输出: 3 解释: 最长连续递增序列是 [1,3,5], 长度为3。 尽管 [1,3,5,7] 也是升序的子序列, 但它不是连续的，因为5和7在原数组里被4隔开。 示例 2: 输入: [2,2,2,2,2] 输出: 1 解释: 最长连续递增序列是 [2], 长度为1。 解题思路  用两个变量记录序列开始和结束的下标 从左到右遍历，如果下一个节点小当前节点则移动 start，否则移动end，并更新 max  public static int findLengthOfLCIS(int[] nums) { if (nums.length == 0) { return 0; } if (nums.length == 1) { return 1; } int start = 0, end = 0; int max = 1; for (int i = 1; i \u0026lt; nums.length; i++) { if (nums[i] \u0026gt; nums[i - 1]) { end = i; max = Math.max(max, end - start + 1); } else { start = i; } } return max; } "});index.add({'id':151,'href':'/interview/docs/leetcode/findCircleNum/','title':"朋友圈",'content':"朋友圈 头条重点\n题目 班上有 N 名学生。其中有些人是朋友，有些则不是。他们的友谊具有是传递性。如果已知 A 是 B 的朋友，B 是 C 的朋友，那么我们可以认为 A 也是 C 的朋友。所谓的朋友圈，是指所有朋友的集合。\n给定一个 N * N 的矩阵 M，表示班级中学生之间的朋友关系。如果M[i][j] = 1，表示已知第 i 个和 j 个学生互为朋友关系，否则为不知道。你必须输出所有学生中的已知的朋友圈总数。\n示例 1: 输入: [[1,1,0], [1,1,0], [0,0,1]] 输出: 2 说明：已知学生0和学生1互为朋友，他们在一个朋友圈。 第2个学生自己在一个朋友圈。所以返回2。 示例 2: 输入: [[1,1,0], [1,1,1], [0,1,1]] 输出: 1 说明：已知学生0和学生1互为朋友，学生1和学生2互为朋友，所以学生0和学生2也是朋友，所以他们三个在一个朋友圈，返回1。 注意：\n N 在[1,200]的范围内。 对于所有学生，有M[i][i] = 1。 如果有M[i][j] = 1，则有M[j][i] = 1。  解题思路  逐个遍历所有学生，将他所有朋友标记  public int findCircleNum(int[][] M) { if (M.length == 0) { return 0; } int[] marks = new int[M.length]; int total = 0; for (int i = 0; i \u0026lt; M.length; i++) { if (marks[i] != 1) { total++; dfs(M, marks, i); } } return total; } private void dfs(int[][] M, int[] marks, int i) { marks[i] = 1; for (int j = 0; j \u0026lt; M[i].length; j++) { if (M[i][j] == 1 \u0026amp;\u0026amp; marks[j] != 1) { dfs(M, marks, j); } } } "});index.add({'id':152,'href':'/interview/docs/offer/MovingCount/','title':"机器人的运动范围",'content':"题目 地上有一个m行和n列的方格。一个机器人从坐标 0,0 的格子开始移动，每一次只能向左，右，上，下四个方向移动一格，但是不能进入行坐标和列坐标的数位之和大于k的格子。 例如，当k为 18 时，机器人能够进入方格（35,37），因为3+5+3+7 = 18。但是，它不能进入方格（35,38），因为3+5+3+8 = 19。请问该机器人能够达到多少个格子？\n解题思路  "});index.add({'id':153,'href':'/interview/docs/basic/algo/search/','title':"查找算法",'content':"查找算法 ASL 由于查找算法的主要运算是关键字的比较，所以通常把查找过程中对关键字的平均比较次数（平均查找长度）作为衡量一个查找算法效率的标准。ASL= ∑(n,i=1) Pi*Ci，其中n为元素个数，Pi是查找第i个元素的概率，一般为Pi=1/n，Ci是找到第i个元素所需比较的次数。\n顺序查找 原理是让关键字与队列中的数从最后一个开始逐个比较，直到找出与给定关键字相同的数为止，它的缺点是效率低下。时间复杂度o(n)。\n折半查找 折半查找要求线性表是有序表。搜索过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。这种搜索算法每一次比较都使搜索范围缩小一半。折半搜索每次把搜索区域减少一半，时间复杂度为O(log n)。\n 可以借助二叉判定树求得折半查找的平均查找长度：log2(n+1)-1。 折半查找在失败时所需比较的关键字个数不超过判定树的深度，n个元素的判定树的深度和n个元素的完全二叉树的深度相同log2(n)+1。  public int binarySearchStandard(int[] num, int target){ int start = 0; int end = num.length - 1; while(start \u0026lt;= end){ //注意1 int mid = start + ((end - start) \u0026gt;\u0026gt; 1); if(num[mid] == target) return mid; else if(num[mid] \u0026gt; target){ end = mid - 1; //注意2 } else{ start = mid + 1; //注意3 } } return -1; }   如果是start \u0026lt; end，那么当target等于num[num.length-1]时，会找不到该值。\n  因为num[mid] \u0026gt; target, 所以如果有num[index] == target, index一定小于mid，能不能写成end = mid呢？举例来说：num = {1, 2, 5, 7, 9}; 如果写成end = mid，当循环到start = 0, end = 0时（即num[start] = 1, num[end] = 1时），mid将永远等于0，此时end也将永远等于0，陷入死循环。也就是说寻找target = -2时，程序将死循环。\n  因为num[mid] \u0026lt; target, 所以如果有num[index] == target, index一定大于mid，能不能写成start = mid呢？举例来说：num = {1, 2, 5, 7, 9}; 如果写成start = mid，当循环到start = 3, end = 4时（即num[start] = 7, num[end] = 9时），mid将永远等于3，此时start也将永远等于3，陷入死循环。也就是说寻找target = 9时，程序将死循环。\n  分块查找 分块查找又称索引顺序查找，它是一种性能介于顺序查找和折半查找之间的查找方法。分块查找由于只要求索引表是有序的，对块内节点没有排序要求，因此特别适合于节点动态变化的情况。\n"});index.add({'id':154,'href':'/interview/docs/offer/IsPopOrder/','title':"栈的压入",'content':"题目 牛客网\n输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否可能为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4,5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的）\n解题思路  通过 Stack 进行模拟 push，当 pop 的节点等于 Stack 的 top 节点时，pop Stack 最后如果 Stack 剩余数据，则判定为 false  public boolean IsPopOrder(int[] pushA, int[] popA) { if (pushA.length != popA.length) { return false; } if (pushA.length == 0) { return false; } LinkedList\u0026lt;Integer\u0026gt; stack = new LinkedList\u0026lt;\u0026gt;(); int j = 0; for (int value : pushA) { stack.addLast(value); while (stack.peekLast() != null \u0026amp;\u0026amp; popA[j] == stack.getLast()) { j++; stack.removeLast(); } } return stack.isEmpty(); } "});index.add({'id':155,'href':'/interview/docs/basic/algo/tree/','title':"树",'content':"树 二叉树 L、D、R分别表示遍历左子树、访问根结点和遍历右子树\n 先序遍历：DLR 中序遍历：LDR 后序遍历：LRD   仅有前序和后序遍历，不能确定一个二叉树，必须有中序遍历的结果\n 二叉树的性质  性质1：在二叉树中第 i 层的结点数最多为2^(i-1)（i ≥ 1） 性质2：高度为k的二叉树其结点总数最多为2^k－1（ k ≥ 1） 性质3：对任意的非空二叉树 T ，如果叶结点的个数为 n0，而其度为 2 的结点数为 n2，则：n0 = n2 + 1  满二叉树 深度为k，且有2^k-1个节点称之为满二叉树；\n 性质4：第i层上的节点数为2^(i-1)；  完全二叉树 深度为k，有n个节点的二叉树，当且仅当其每一个节点都与深度为k的满二叉树中，序号为1至n的节点对应时，称之为完全二叉树。\n 性质5：对于具有n个结点的完全二叉树的高度为log2(n)+1  求完全二叉树的叶子结点个数：\n二叉树的构造 //n 表示当前结点字符 Node* tree(vector\u0026lt;char\u0026gt; data, int n) { Node* node; if (n \u0026gt;= data.size()) return NULL; if (data[n] == \u0026#39;#\u0026#39;) return NULL; node = new Node; node-\u0026gt;data = data[n]; node-\u0026gt;left = tree(data, n + 1); node-\u0026gt;right = tree(data, n + 2); return node; } 堆 堆通常是一个可以被看做一棵树的数组对象。堆的实现通过构造二叉堆（binary heap），实为二叉树的一种；\n 任意节点小于（或大于）它的所有后裔，最小元（或最大元）在堆的根上（堆序性）。 堆总是一棵完全树。即除了最底层，其他层的节点都被元素填满，且最底层尽可能地从左到右填入。  将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。常见的堆有二叉堆、斐波那契堆等。\n通常堆是通过一维数组来实现的。在数组起始位置为1的情形中：\n 父节点i的左子节点在位置(2*i); 父节点i的右子节点在位置(2*i+1); 子节点i的父节点在位置(i/2);  霍夫曼树 霍夫曼树又称最优二叉树，是一种带权路径长度最短的二叉树。所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度（若根结点为0层，叶结点到根结点的路径长度为叶结点的层数）。树的路径长度是从树根到每一结点的路径长度之和，记为WPL=（W1L1+W2L2+W3L3+\u0026hellip;+WnLn），N个权值Wi（i=1,2,\u0026hellip;n）构成一棵有N个叶结点的二叉树，相应的叶结点的路径长度为Li（i=1,2,\u0026hellip;n）。可以证明霍夫曼树的WPL是最小的。\n霍夫曼树构造  根据给定的n个权值(W1,W2...Wn)，使对应节点构成n个二叉树的森林T=(T1,T2...Tn)，其中每个二叉树Ti(1 \u0026lt;= i \u0026lt;= n)中都有一个带权值为Wi的根节点，其左、右子树均为空。 在森林T中选取两个节点权值最小的子树，分别作为左、右子树构造一个新的二叉树，且置新的二叉树的根节点的权值为其左右子树上根节点权值之和。 在森林T中，用新得到的二叉树替代选取的两个二叉树。 重复2和3，直到T只包含一个树为止。这个数就是霍夫曼树。   定理：对于具有n个叶子节点的霍夫曼树，共有2n-1个节点。这是由于霍夫曼树只有度为0和度为2的结点，根据二叉树的性质 n0 = n2 + 1，因此度为2的结点个数为n-1个，总共有2n-1个节点。\n 霍夫曼编码 对于一个霍夫曼树，所有左链接取'0\u0026rsquo;、右链接取'1\u0026rsquo;。从树根至树叶依序记录所有字母的编码。\n带权路径  结点的权：若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。 结点的带权路径：从根结点到该结点之间的路径长度与该结点的权的乘积。 树的带权路径：所有叶子结点的带权路径长度之和，记为WPL。  二叉排序树 二叉查找树，也称二叉搜索树、有序二叉树，排序二叉树，是指一棵空树或者具有下列性质的二叉树：\n 任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。  二分查找的时间复杂度是O(log(n))，最坏情况下的时间复杂度是O(n)（相当于顺序查找）\n平衡二叉树 平衡树是计算机科学中的一类改进的二叉查找树。一般的二叉查找树的查询复杂度是跟目标结点到树根的距离（即深度）有关，因此当结点的深度普遍较大时，查询的均摊复杂度会上升，为了更高效的查询，平衡树应运而生了。平衡指所有叶子的深度趋于平衡，更广义的是指在树上所有可能查找的均摊复杂度偏低。\nAVL树 AVL树是最先发明的 自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为一，所以它也被称为高度平衡树。\n 它的左子树和右子树都是平衡二叉树。 左子树和右子树的深度之差的绝对值不超过1。  增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。\n 右旋：左结点转到根节点位置。 左旋：右节点转到根节点位置。   高度为k的AVL树，节点数N最多2^k -1，即满二叉树；\n 红黑树 红黑树是一种自平衡二叉查找树，每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求：\n 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。   如果一条路径上的顶点除了起点和终点可以相同外，其它顶点均不相同，则称此路径为一条简单路径；起点和终点相同的简单路径称为回路（或环）。\n  红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。\n 这些约束确保了红黑树的关键特性：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限 允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。\n在很多树数据结构的表示中，一个节点有可能只有一个子节点，而叶子节点包含数据。用这种范例表示红黑树是可能的，但是这会改变一些性质并使算法复杂。为此，本文中我们使用\u0026quot;nil叶子\u0026quot;或\u0026quot;空（null）叶子\u0026rdquo;，如上图所示，它不包含数据而只充当树在此结束的指示。这些节点在绘图中经常被省略，导致了这些树好像同上述原则相矛盾，而实际上不是这样。与此有关的结论是所有节点都有两个子节点，尽管其中的一个或两个可能是空叶子。\n因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的只读操作与普通二叉查找树上的只读操作相同。然而，在红黑树上进行插入操作和删除操作会导致不再符合红黑树的性质。恢复红黑树的性质需要少量（O(log n)）的颜色变更（实际是非常快速的）和不超过三次树旋转（对于插入操作是两次）。虽然插入和删除很复杂，但操作时间仍可以保持为O(log n)次。\nB树 B树是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，复杂度均为   \\(O(n)\\)  。总的来说，B树是一个泛化的二叉查找树，一个节点可以拥有两个以上的子节点。但其与自平衡二叉查找树不同，B树更适合大数据块的存储系统，例如：磁盘。\n在B树中，内部（非叶子）节点可以拥有可变数量的子节点（数量范围预先定义好）。当数据被插入或从一个节点中移除，它的子节点数量发生变化。为了维持在预先设定的数量范围内，内部节点可能会被 合并 或者 分离。因为子节点数量有一定的允许范围，所以B树不需要像其他自平衡查找树那样频繁地重新保持平衡，但是由于节点 没有被完全填充，可能浪费了一些空间。子节点数量的上界和下界依特定的实现而设置。例如，在一个2-3 B树（通常简称2-3树），每一个内部节点只能有 2 或 3 个子节点。\n根据 Knuth 的定义，一个 m 阶的B树是一个有以下属性的树：\n 每一个节点最多有 m 个子节点 每一个非叶子节点（除根节点）最少有 \\(m\\div 2\\)  个子节点 如果根节点不是叶子节点，那么它至少有两个子节点 有 k 个子节点的非叶子节点拥有 k − 1 个键 所有的叶子节点都在同一层  每一个内部节点的键将节点的子树分开。例如，如果一个内部节点有 3 个子节点（子树），那么它就必须有两个键： a1 和 a2 。左边子树的所有值都必须小于 a1 ，中间子树的所有值都必须在 a1 和a2 之间，右边子树的所有值都必须大于 a2 。\nB树内的节点可分为三类：\n 内部节点：内部节点是除叶子节点和根节点之外的所有节点。它们通常被表示为一组有序的元素和指向子节点的指针。 根节点：根节点拥有的子节点数量的上限和内部节点相同，但是没有下限。 叶子节点：叶子节点对元素的数量有相同的限制，但是没有子节点，也没有指向子节点的指针。  B树的查找 在B树中的查找给定关键字的方法 类似于二叉排序树上的查找，不同的是在每个节点上确定向下查找的路径不一定是二路的，而是n+1路的。因为节点内的关键字序列key[1..n]有序，故既可以使用顺序查找，也可以使用二分查找。在一棵B树上查找关键字为k的方法为：将k与根节点中的key[i]进行比较：\n 若k=key[i]，则查找成功； 若k\u0026lt;key[1]，则沿指针ptr[0]所指的子树继续查找； 若key[i]\u0026lt;k\u0026lt;key[i+1]，则沿着指针ptr[i]所指的子树继续查找； 若k\u0026gt;key[n]，则沿着指针ptr[n]所指的子树继续查找。  B树的插入 将关键字k插入到B树的过程分两步完成：\n  利用B树的查找算法查找出该关键字的插入节点(注意B树的插入节点一定属于最低非叶子节点层)。\n  判断该节点是否还有空位，即判断该节点是否满足n \u0026lt; m-1，若满足：直接把关键字k插入到该节点合适位置上；若不满足：分裂节点，取一新节点，把原节点上的关键字和k按升序排列后，从中间位置(m/2)处把关键字(不包括中间位置的关键字)分成两部分，左部分所含关键字放在旧节点中，右部分关键字放在新节点中，中间位置的关键字连同新节点的存储位置插入到双亲节点。如果双亲节点的关键字个数也超出max则再分裂。\n  B树的删除 首先查找B树中需删除的元素，如果该元素在B树中存在，则将该元素在其结点中进行删除；如果删除该元素后，首先判断该元素是否有左右孩子结点，如果有，则上移孩子结点中的某相近元素到父节点中，然后是移动之后的情况；如果没有，直接删除后，然后是移动之后的情况。\n删除元素，移动相应元素之后，如果某结点中元素数目（即关键字数）小于Min(m/2)-1，则需要看其某相邻兄弟结点是否丰满，如果丰满，则向父节点借一个元素来满足条件；如果其相邻兄弟都刚脱贫，即借了之后其结点数目小于Min(m/2)-1，则该结点与其相邻的某一兄弟结点进行“合并”成一个结点，\nB+树 B+ 树是 B 树的变体，也是一种多路搜索树。m阶的 B+ 树和 B 树的主要差异如下：\n 在B+树中，具有n个关键字的节点含有n个子树，即每个关键字对应一个子树，而在B树中，具有n个关键字的节点含有(n+1)个子树。 在B+树中，每个节点(除根节点外)中的关键字个数n的取值范围是[m/2] \u0026lt;= n \u0026lt;= m，根节点n的取值范围2 \u0026lt;=n \u0026lt;=m；而在B树中，除根节点外，其他所有非叶子节点的关键字个数：[m/2]-1 \u0026lt;= n \u0026lt;= m-1，根节点关键字个数为1 \u0026lt;= n \u0026lt;= m-1 B+树中所有叶子节点包含了全部关键字，即其他非叶子节点中的关键字包含在叶子节点中，而在B树中，关键字是不重复的。 B+树中所有非叶子节点仅起到索引的作用，即节点中每个索引项值含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。而在B树中，每个关键字对应一个记录的存储地址。 在 B+ 树所有叶子节点链接成一个不定长的线性表。  B+树的查找 在B+树中可以采用两种查找方式：\n 直接从最小关键字开始顺序查找。 从B+树的根节点开始随机查找。这种查找方式与B树的查找方式类似，只是在分支节点上的关键字与查找值相等时，查找并不会结束，要继续查到叶子节点为止，此时若查找成功，则按所给指针取出对应元素。  在B+树中，不管查找是否成功，每次查找都是经历一条树从根节点到叶子节点的路径。\nB+树的插入  首先，查找要插入其中的节点的位置。接着把值插入这个节点中。 如果没有节点处于违规状态则处理结束。 如果某个节点有过多元素，则把它分裂为两个节点，每个都有最小数目的元素。在树上递归向上继续这个处理直到到达根节点，如果根节点被分裂，则创建一个新根节点。为了使它工作，元素的最小和最大数目典型的必须选择为使最小数不小于最大数的一半。  B+树的删除  首先，查找要删除的值。接着从包含它的节点中删除这个值。 如果没有节点处于违规状态则处理结束。 如果节点处于违规状态则有两种可能情况：  它的兄弟节点，可以把一个或多个它的子节点转移到当前节点，而把它返回为合法状态。如果是这样，在更改父节点和两个兄弟节点的分离值之后处理结束。 它的兄弟节点由于处在低边界上而没有额外的子节点。在这种情况下把两个兄弟节点合并到一个单一的节点中，而且我们递归到父节点上，因为它被删除了一个子节点。持续这个处理直到当前节点是合法状态或者到达根节点，在其上根节点的子节点被合并而且合并后的节点成为新的根节点。    B+树的优势所在 为什么说B+树比B树更适合实际应用中操作系统的文件索引和数据库索引？\n B+树的中间节点能存储更多指针 B+树的查询效率更加稳定：关键字查询的路径长度相同 减少回溯：由于B+树中叶子节点存在指针，所以在范围查找时不需要回溯到父节点，直接类型链表遍历即可，减少IO  Trie树 Trie树，又称前缀树，字典树， 是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。\nTrie树查询和插入时间复杂度都是 O(n)，是一种以空间换时间的方法。当节点树较多的时候，Trie 树占用的内存会很大。\nTrie树常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。\n"});index.add({'id':156,'href':'/interview/docs/offer/HasSubtree/','title':"树的子结构",'content':"题目 牛客网\n输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构）\n解题思路  遍历查找相等根节点 通过递归查找当前根节点下是否包含子树 root2  public boolean HasSubtree(TreeNode root1, TreeNode root2) { if (root2 == null) { return false; } LinkedList\u0026lt;TreeNode\u0026gt; pipeline = new LinkedList\u0026lt;\u0026gt;(); pipeline.addLast(root1); while (!pipeline.isEmpty()) { TreeNode node = pipeline.pop(); if (node == null) { continue; } pipeline.addLast(node.left); pipeline.addLast(node.right); if (node.val == root2.val \u0026amp;\u0026amp; isSub(node, root2)) { return true; } } return false; } private boolean isSub(TreeNode root1, TreeNode root2) { if (root1 == null \u0026amp;\u0026amp; root2 == null) { return true; } if (root1 == null) { return false; } if (root2 == null) { return true; } if (root1.val == root2.val) { return isSub(root1.left, root2.left) \u0026amp;\u0026amp; isSub(root1.right, root2.right); } else { return false; } } "});index.add({'id':157,'href':'/interview/docs/offer/PatternMatch/','title':"正则表达式匹配",'content':"请实现一个函数用来匹配包括'.'和'*'的正则表达式。模式中的字符'.'表示任意一个字符，而'*'表示它前面的字符可以出现任意次（包含0次）。 在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串\u0026quot;aaa\u0026quot;与模式\u0026quot;a.a\u0026quot;和\u0026quot;ab*ac*a\u0026quot;匹配，但是与\u0026quot;aa.a\u0026quot;和\u0026quot;ab*a\u0026quot;均不匹配\n解题思路  对于 * 有三种匹配模式：匹配0次，1次以及多次 对于 . 只有一种匹配模式  public boolean match(char[] str, char[] pattern) { if (str.length == 0 \u0026amp;\u0026amp; new String(pattern).replaceAll(\u0026quot;.\\\\*\u0026quot;, \u0026quot;\u0026quot;).length() == 0) { return true; } return match(str, 0, pattern, 0); } private boolean match(char[] str, int i, char[] pattern, int j) { if (i == str.length \u0026amp;\u0026amp; j == pattern.length) { return true; } if (j \u0026gt;= pattern.length) return false; if (j + 1 \u0026lt; pattern.length \u0026amp;\u0026amp; pattern[j + 1] == '*') { if ((i \u0026lt; str.length \u0026amp;\u0026amp; pattern[j] == str[i]) || (pattern[j] == '.' \u0026amp;\u0026amp; i != str.length)) { return match(str, i + 1, pattern, j + 2) || match(str, i + 1, pattern, j) || match(str, i, pattern, j + 2); } else { return match(str, i, pattern, j + 2); } } if ((i \u0026lt; str.length \u0026amp;\u0026amp; pattern[j] == str[i]) || (pattern[j] == '.' \u0026amp;\u0026amp; i != str.length)) { return match(str, i + 1, pattern, j + 1); } return false; } "});index.add({'id':158,'href':'/interview/docs/offer/sum/','title':"求",'content':"题目 牛客网\n求1+2+3+\u0026hellip;+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。\n解题思路  利用递归代替循环  public int Sum_Solution(int n) { int ans = n; boolean t = ((ans != 0) \u0026amp;\u0026amp; ((ans += Sum_Solution(n - 1)) != 0)); return ans; } "});index.add({'id':159,'href':'/interview/docs/java/annotation/','title':"注解",'content':"注解 注解(Annotation)是 Java1.5 中引入的一个重大修改之一，为我们在代码中添加信息提供了一种形式化的方法，使我们可以在稍后某个时刻非常方便的使用这些数据。注解在一定程度上是把元数据与源代码结合在一起，而不是保存在外部文档中。注解的含义可以理解为 java 中的元数据。元数据是描述数据的数据。\n注解是一个继承自java.lang.annotation.Annotation的接口\n可见性 根据注解在程序不同时期的可见性，可以把注解区分为：\n source：注解会在编译期间被丢弃，不会编译到 class 文件 class：注解会被编译到 class 文件中，但是在运行时不能获取 runtime：注解会被编译到 class 文件中，并且能够在运行时通过反射获取  继承     有@Inherited 没有@Inherited     子类的类上能否继承到父类的类上的注解？ 否 能   子类实现了父类上的抽象方法 否 否   子类继承了父类上的方法 能 能   子类覆盖了父类上的方法 否 否    @Inherited 只是可控制对类名上注解是否可以被继承。不能控制方法上的注解是否可以被继承。\n注解的实现机制  注解是继承自：java.lang.annotation.Annotation 的接口  ... Compiled from \u0026quot;TestAnnotation.java\u0026quot; public interface TestAnnotation extends java.lang.annotation.Annotation ... 注解内部的属性是在编译期间确定的  ... SourceFile: \u0026quot;SimpleTest.java\u0026quot; RuntimeVisibleAnnotations: 0: #43(#44=s#45) ... 注解在运行时会生成 Proxy 代理类，并使用 AnnotationInvocationHandler.memberValues 来进行数据读取  ... default: //从 Map 中获取数据 Object var6 = this.memberValues.get(var4); if (var6 == null) { throw new IncompleteAnnotationException(this.type, var4); } else if (var6 instanceof ExceptionProxy) { throw ((ExceptionProxy)var6).generateException(); } else { if (var6.getClass().isArray() \u0026amp;\u0026amp; Array.getLength(var6) != 0) { var6 = this.cloneArray(var6); } return var6; } } ... 参考链接  java注解是怎么实现的？  "});index.add({'id':160,'href':'/interview/docs/offer/MaxInWindows/','title':"滑动窗口的最大值",'content':"题目 牛客网\n给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}； 针对数组{2,3,4,2,6,2,5,1}的滑动窗口有以下6个： {[2,3,4],2,6,2,5,1}， {2,[3,4,2],6,2,5,1}， {2,3,[4,2,6],2,5,1}， {2,3,4,[2,6,2],5,1}， {2,3,4,2,[6,2,5],1}， {2,3,4,2,6,[2,5,1]}。\n解题思路  使用一个队列来保存最大值和次大的值  public ArrayList\u0026lt;Integer\u0026gt; maxInWindows(int[] num, int size) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (size == 0) return res; LinkedList\u0026lt;Integer\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; num.length; i++) { while (queue.peekFirst() != null \u0026amp;\u0026amp; i - queue.peekFirst() \u0026gt;= size) { queue.removeFirst(); } while (queue.peekLast() != null \u0026amp;\u0026amp; i - queue.peekLast() \u0026gt;= size) { queue.removeLast(); } if (queue.isEmpty()) { queue.addFirst(i); } else { if (num[i] \u0026gt; num[queue.peekFirst()]) { queue.clear(); queue.addFirst(i); } else { while (num[i] \u0026gt; num[queue.peekLast()]) { queue.removeLast(); } queue.addLast(i); } } if (i \u0026gt;= size - 1) res.add(num[queue.peekFirst()]); } return res; } "});index.add({'id':161,'href':'/interview/docs/leetcode/detectCycle/','title':"环形链表 II",'content':"环形链表 II 题目 给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。\n解题思路  首先通过快慢指针确定链表是否有环 再使用一个指针从头节点与快慢指针相遇节点同步长前进，最终找到环的入口  public ListNode detectCycle(ListNode head) { ListNode fast = head, slow = head; ListNode meetNode = null; while (fast != null \u0026amp;\u0026amp; fast.next != null) { fast = fast.next.next; slow = slow.next; if (fast == slow) { meetNode = fast; break; } } if (meetNode == null) { return meetNode; } while (head != meetNode) { head = head.next; if (head == meetNode) { break; } meetNode = meetNode.next; } return meetNode; } "});index.add({'id':162,'href':'/interview/docs/offer/two-stack-fifo/','title':"用两个栈实现一个队列",'content':"题目 牛客网\n用两个栈来实现一个队列，完成队列的 Push 和 Pop 操作。 队列中的元素为int类型。\n解题思路  用 stack1 作为 push 队列，将元素 push 到 stack1 用 stack2 作为 pop 队列，当 stack2 为空时则将 stack1 的数据 push 到 stack2，否则直接 pop stack2  相当于将两个 stack 拼接：-\u0026gt; stack1 \u0026lt;::\u0026gt; stack2 -\u0026gt;\nStack\u0026lt;Integer\u0026gt; pushStack = new Stack\u0026lt;\u0026gt;(); Stack\u0026lt;Integer\u0026gt; popStack = new Stack\u0026lt;\u0026gt;(); public void push(int node) { pushStack.push(node); } public int pop() { if (popStack.isEmpty()) { while (!pushStack.isEmpty()) { popStack.push(pushStack.pop()); } } if (popStack.isEmpty()) return -1; else return popStack.pop(); } "});index.add({'id':163,'href':'/interview/docs/leetcode/mySqrt/','title':"的平方根",'content':"头条重点\n题目 实现 int sqrt(int x) 函数。\n计算并返回 x 的平方根，其中 x 是非负整数。\n由于返回类型是整数，结果只保留整数的部分，小数部分将被舍去。\n示例 1: 输入: 4 输出: 2 示例 2: 输入: 8 输出: 2 说明: 8 的平方根是 2.82842...,由于返回类型是整数，小数部分将被舍去。 解题思路  牛顿迭代法：   \\(a_{i}=(x/a_{i-1}+a_{i-1})/2\\)    public int mySqrt(int x) { double a = 1, diff = 0; do { a = (x / a + a) / 2.0; diff = Math.abs(a * a - x); } while (diff \u0026gt; 0.1); return (int) a; } "});index.add({'id':164,'href':'/interview/docs/leetcode/getIntersectionNode/','title':"相交链表",'content':"题目 编写一个程序，找到两个单链表相交的起始节点。\n解题思路  首先将两个链表中长的一个向前遍历，直到两个链表长度一致 两个链表同时向前遍历，便可找到交点  public ListNode getIntersectionNode(ListNode headA, ListNode headB) { if (headA == null || headB == null) { return null; } if (headA == headB) { return headA; } int lenA = 1; int lenB = 1; ListNode temp = headA; while (temp.next != null) { temp = temp.next; lenA++; } ListNode tailA = temp; temp = headB; while (temp.next != null) { temp = temp.next; lenB++; } ListNode tailB = temp; if (tailB != tailA) { return null; } if (lenA \u0026gt; lenB) { for (int i = 0; i \u0026lt; lenA - lenB \u0026amp;\u0026amp; headA != null; i++) { headA = headA.next; } } else if (lenA \u0026lt; lenB) { for (int i = 0; i \u0026lt; lenB - lenA \u0026amp;\u0026amp; headB != null; i++) { headB = headB.next; } } while (!headA.equals(headB)) { headA = headA.next; headB = headB.next; } return headA; } "});index.add({'id':165,'href':'/interview/docs/offer/hasPath/','title':"矩阵中的路径",'content':"题目 请设计一个函数，用来判断在一个矩阵中是否存在一条包含某字符串所有字符的路径。路径可以从矩阵中的任意一个格子开始，每一步可以在矩阵中向左，向右，向上，向下移动一个格子。如果一条路径经过了矩阵中的某一个格子，则之后不能再次进入这个格子。 例如 a b c e s f c s a d e e 这样的 3 X 4 矩阵中包含一条字符串\u0026quot;bcced\u0026quot;的路径，但是矩阵中不包含\u0026quot;abcb\u0026quot;路径，因为字符串的第一个字符b占据了矩阵中的第一行第二个格子之后，路径不能再次进入该格子。\n解题思路  简单的回溯查找  static int[][] steps = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}}; public boolean hasPath(char[] matrix, int rows, int cols, char[] str) { char[][] _matrix = new char[rows][cols]; int k = 0; for (int i = 0; i \u0026lt; _matrix.length; i++) { for (int j = 0; j \u0026lt; _matrix[i].length; j++) { _matrix[i][j] = matrix[k++]; } } int[][] flag = new int[rows][cols]; for (int i = 0; i \u0026lt; _matrix.length; i++) { for (int j = 0; j \u0026lt; _matrix[i].length; j++) { if (_matrix[i][j] == str[0]) { if (hasPath(_matrix, flag, i, j, str, 0)) { return true; } } } } return false; } private boolean hasPath(char[][] matrix, int[][] flag, int x, int y, char[] str, int index) { if (x \u0026lt; 0 || y \u0026lt; 0) return false; if (x \u0026gt;= matrix.length || y \u0026gt;= matrix[0].length) return false; if (flag[x][y] == 1) return false; boolean subRes = false; if (matrix[x][y] == str[index]) { if (index == str.length - 1) return true; flag[x][y] = 1; for (int[] step : steps) { subRes |= hasPath(matrix, flag, x + step[0], y + step[1], str, index + 1); } flag[x][y] = 0; } return subRes; } "});index.add({'id':166,'href':'/interview/docs/architecture/design/tinyURL/','title':"短链接",'content':"短链接 使用场景(Scenario) 微博和Twitter都有140字数的限制，如果分享一个长网址，很容易就超出限制，发布出去。短网址服务可以把一个长网址变成短网址，方便在社交网络上传播。\n需求(Needs) 很显然，要尽可能的短。长度设计为多少才合适呢？\n短网址的长度 当前互联网上的网页总数大概是 45亿(参考 短网址_短网址资讯mrw.so)，45亿 超过了 2^{32}=4294967296232=4294967296，但远远小于64位整数的上限值，那么用一个64位整数足够了。微博的短网址服务用的是长度为 7 的字符串，这个字符串可以看做是62进制的数，那么最大能表示{62}^7=3521614606208627=3521614606208个网址，远远大于 45亿。所以长度为7就足够了。一个64位整数如何转化为字符串呢？，假设我们只是用大小写字母加数字，那么可以看做是62进制数，log_{62{(2^{64}-1)=10.7log62(264−1)=10.7，即字符串最长11就足够了。实际生产中，还可以再短一点，比如新浪微博采用的长度就是7，因为 62^7=3521614606208627=3521614606208，这个量级远远超过互联网上的URL总数了，绝对够用了。现代的web服务器（例如Apache, Nginx）大部分都区分URL里的大小写了，所以用大小写字母来区分不同的URL是没问题的。因此，正确答案：长度不超过7的字符串，由大小写字母加数字共62个字母组成。\n一对一还是一对多映射？ 一个长网址，对应一个短网址，还是可以对应多个短网址？ 这也是个重大选择问题。一般而言，一个长网址，在不同的地点，不同的用户等情况下，生成的短网址应该不一样，这样，在后端数据库中，可以更好的进行数据分析。如果一个长网址与一个短网址一一对应，那么在数据库中，仅有一行数据，无法区分不同的来源，就无法做数据分析了。\n以这个7位长度的短网址作为唯一ID，这个ID下可以挂各种信息，比如生成该网址的用户名，所在网站，HTTP头部的 User Agent等信息，收集了这些信息，才有可能在后面做大数据分析，挖掘数据的价值。短网址服务商的一大盈利来源就是这些数据。\n正确答案：一对多\n如何计算短网址 现在我们设定了短网址是一个长度为7的字符串，如何计算得到这个短网址呢？\n最容易想到的办法是哈希，先hash得到一个64位整数，将它转化为62进制整，截取低7位即可。但是哈希算法会有冲突，如何处理冲突呢，又是一个麻烦。这个方法只是转移了矛盾，没有解决矛盾，抛弃。\n正确答案：分布式发号器(Distributed ID Generator)\n如何存储 如果存储短网址和长网址的对应关系？以短网址为 primary key, 长网址为value, 可以用传统的关系数据库存起来，例如MySQL,PostgreSQL，也可以用任意一个分布式 KV 数据库，例如Redis, LevelDB。\n301还是302重定向 这也是一个有意思的问题。这个问题主要是考察你对301和302的理解，以及浏览器缓存机制的理解。\n301是永久重定向，302是临时重定向。短地址一经生成就不会变化，所以用301是符合http语义的。但是如果用了301， Google，百度等搜索引擎，搜索的时候会直接展示真实地址，那我们就无法统计到短地址被点击的次数了，也无法收集用户的Cookie, User Agent 等信息，这些信息可以用来做很多有意思的大数据分析，也是短网址服务商的主要盈利来源。\n所以，正确答案是302重定向。\n可以抓包看看mrw.so的短网址是怎么做的，使用 Chrome 浏览器，访问这个URL http://mrw.so/4UD39p，是我事先发微博自动生成的短网址。来抓包看看返回的结果是啥，可见新浪微博用的就是302临时重定向。\n"});index.add({'id':167,'href':'/interview/docs/basic/os/disk/','title':"磁盘与文件",'content':"磁盘与文件 磁盘 磁盘是可以持久存储的设备，根据存储介质的不同，常见磁盘可以分为两类：机械磁盘和固态磁盘\n机械磁盘，也称为硬盘驱动器，通常缩写为HDD。机械磁盘主要有盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位到数据所在的磁道，然后才能访问数据。最小读写单位是 扇区 ，一般大小为512字节。\n固态磁盘，通常缩写为SSD，有固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续I/O还是随机I/O的性能，都比机械磁盘要好得多。\n连续 I/O 还可以通过预读的方式，来减少I/O请求的次数，这也是其性能优异的一个原因。很多性能优化的方案，也都会从这个角度出发，来优化I/O性能。最小读写单位是 页，通常大小是 4KB ，8KB 等。\n磁盘调度 磁盘访问延迟 = 队列时间 + 控制器时间 + 寻道时间 + 旋转时间 + 传输时间\n磁盘调度的目的是减小延迟，其中前两项可以忽略，寻道时间是主要矛盾。\n磁盘调度算法   FCFS：先进先出的调度策略，这个策略具有公平的优点，因为每个请求都会得到处理，并且是按照接收到的顺序进行处理。\n  SSTF(Shortest-seek-time First 最短寻道时间优先)：选择使磁头从当前位置开始移动最少的磁盘I/O请求，所以 SSTF 总是选择导致最小寻道时间的请求。总是选择最小寻找时间并不能保证平均寻找时间最小，但是能提供比 FCFS 算法更好的性能，会存在饥饿现象（会导致较远的I/O请求不能满足）。\n  SCAN：SSTF+中途不回折，每个请求都有处理机会。SCAN 要求磁头仅仅沿一个方向移动，并在途中满足所有未完成的请求，直到它到达这个方向上的最后一个磁道，或者在这个方向上没有其他请求为止。由于磁头移动规律与电梯运行相似，SCAN 也被称为电梯算法。\n   SCAN 算法对最近扫描过的区域不公平，因此，它在访问局部性方面不如 FCFS 算法和 SSTF 算法好。\n   C-SCAN：SCAN+直接移到另一端，两端请求都能很快处理。把扫描限定在一个方向，当访问到某个方向的最后一个磁道时，磁道返回磁盘相反方向磁道的末端，并再次开始扫描。其中“C”是Circular（环）的意思。\n  LOOK(C-LOOK)：釆用SCAN算法和C-SCAN算法时磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，即磁头移动只需要到达最远端的一个请求即可返回，不需要到达磁盘端点。这种形式的SCAN算法和C-SCAN算法称为LOOK和C-LOOK调度。这是因为它们在朝一个给定方向移动前会查看是否有请求。\n  文件系统 文件系统是对存储设备上的文件，进行组织管理的一种机制。而 Linux 在各种文件系统实现上，抽象了一层虚拟文件系统 VFS ，它定义了一组，所有文件系统都支持的，数据结构和标准接口。VFS 内部通过目录项，索引节点，逻辑块以及超级块等数据结构，来管理文件。\n 目录项：记录了文件的名字，以及文件与其他目录项之间的目录关系。 索引节点：记录了文件的元数据 逻辑块：是由连续磁盘扇区构成的最小读写单元，用来存储文件系统 超级块：用来记录文件系统整体的状态，如索引节点和逻辑块的使用情况等。  其中，目录项是一个内存缓存；而超级块，索引节点和逻辑块，都是存储在磁盘中的持久数据。\n如果每次都读写 512 字节这么小的单位的话，效率很低。所以，文件系统会把连续的扇区或页，组成逻辑块，然后以逻辑块作为最小单元来管理数据。常见的逻辑块的大小是 4KB ，也就是连续8个扇区，或者单独的一个页，都可以组成一个逻辑块。\n通用块层 为了减小不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理各种不同的块设备。 通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层。它主要有两个功能：\n 同虚拟文件系统的功能类似：向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。 I/O调度：对文件系统和应用程序发来的I/O请求排队，并通过重新排序，请求合并等方式，提高磁盘读写的效率。Linux 内核支持四种 I/O 调度算法，分别是 NONE , NOOP , CFQ 以及 DeadLine  IO 栈 可以把 Linux 存储系统的I/O栈，由上到下分为三个层次，分别是文件系统层，通用块层和设备层。\n 文件系统层：包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过调用块层，来存储和管理磁盘数据。 调用块层：包扣块设备I/O队列和I/O调度器。它会对文件系统的I/O请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。 设备层：包扣存储设备和相应的驱动程序，负责最终物理设备的I/O操作。  Linux文件权限 Linux文件采用10个标志位来表示文件权限，如下所示：\n-rw-r--r-- 1 skyline staff 20B 1 27 10:34 1.txt drwxr-xr-x 5 skyline staff 170B 12 23 19:01 ABTableViewCell 第一个字符一般用来区分文件和目录，其中：\n d：表示是一个目录，事实上在ext2fs中，目录是一个特殊的文件。 －：表示这是一个普通的文件。 l: 表示这是一个符号链接文件，实际上它指向另一个文件。 b、c：分别表示区块设备和其他的外围设备，是特殊类型的文件。 s、p：这些文件关系到系统的数据结构和管道，通常很少见到。  第2～10个字符当中的每3个为一组，左边三个字符表示所有者权限，中间3个字符表示与所有者同一组的用户的权限，右边3个字符是其他用户的权限。\n这三个一组共9个字符，代表的意义如下：\n r(Read，读取)：对文件而言，具有读取文件内容的权限；对目录来说，具有浏览目录的权限 w(Write,写入)：对文件而言，具有新增、修改文件内容的权限；对目录来说，具有删除、移动目录内文件的权限。 x(eXecute，执行)：对文件而言，具有执行文件的权限；对目录来说该用户具有进入目录的权限。  权限的掩码可以使用十进制数字表示：\n 如果可读，权限是二进制的100，十进制是4； 如果可写，权限是二进制的010，十进制是2； 如果可运行，权限是二进制的001，十进制是1；  chmod命令 chmod命令非常重要，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。\n该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。\n 文字设定法  chmod ［who］ ［+ | - | =］ ［mode］ 文件名\n命令中各选项的含义为：\n操作对象who可是下述字母中的任一个或者它们的组合：\n u 表示“用户（user）”，即文件或目录的所有者。 g 表示“同组（group）用户”，即与文件属主有相同组ID的所有用户。 o 表示“其他（others）用户”。 a 表示“所有（all）用户”。它是系统默认值。  操作符号可以是：\n   添加某个权限。     取消某个权限。   = 赋予给定权限并取消其他所有权限（如果有的话）。  设置mode所表示的权限可用下述字母的任意组合：\n r 可读。 w 可写。 x 可执行。 X 只有目标文件对某些用户是可执行的或该目标文件是目录时才追加x 属性。 s 在文件执行时把进程的属主或组ID置为该文件的文件属主。方式“u＋s”设置文件的用户ID位，“g＋s”设置组ID位。 t 保存程序的文本到交换设备上。 u 与文件属主拥有一样的权限。 g 与和文件属主同组的用户拥有一样的权限。 o 与其他用户拥有一样的权限。  文件名：以空格分开的要改变权限的文件列表，支持通配符。\n在一个命令行中可给出多个权限方式，其间用逗号隔开。例如：chmod g+r，o+r example 使同组和其他用户对文件example 有读权限。\n数字设定法  直接使用数字表示的权限来更改：\n例： $ chmod 644 mm.txt chgrp命令 功能：改变文件或目录所属的组。\n语法：chgrp ［选项］ group filename\n例：$ chgrp - R book /opt/local /book 改变/opt/local /book/及其子目录下的所有文件的属组为book。\nchown命令 功能：更改某个文件或目录的属主和属组。这个命令也很常用。例如root用户把自己的一个文件拷贝给用户xu，为了让用户xu能够存取这个文件，root用户应该把这个文件的属主设为xu，否则，用户xu无法存取这个文件。\n语法：chown ［选项］ 用户或组 文件\n说明：chown将指定文件的拥有者改为指定的用户或组。用户可以是用户名或用户ID。组可以是组名或组ID。文件是以空格分开的要改变权限的文件列表，支持通配符。\n例：把文件shiyan.c的所有者改为wang。 chown wang shiyan.c "});index.add({'id':168,'href':'/interview/docs/offer/MaxGift/','title':"礼物的最大值",'content':"题目 在一个 m*n 的棋盘中的每一个格都放一个礼物，每个礼物都有一定的价值（价值大于0）.你可以从棋盘的左上角开始拿各种里的礼物，并每次向左或者向下移动一格，直到到达棋盘的右下角。给定一个棋盘及上面个的礼物，请计算你最多能拿走多少价值的礼物？\n比如说现在有一个如下的棋盘:\n[1,3,1] [1,5,1] [4,2,1] 在这个棋盘中，按照 1 -\u0026gt; 3 -\u0026gt; 5 -\u0026gt; 2 -\u0026gt; 1 可以拿到最多价值的礼物。\n解题思路  动态规划，定义   \\(f(x,y)\\)  表示x,y点上能获取的最大数 状态转移方程： \\(f(x,y)=\\max(f(x-1,y),f(x,y-1))+g(x,y)\\)   可以考虑使用一维数组进行记录  public int maxGift(int[][] matrix) { for (int i = 0; i \u0026lt; matrix.length; i++) { for (int j = 0; j \u0026lt; matrix[i].length; j++) { int a = i \u0026gt; 0 ? matrix[i - 1][j] : 0; int b = j \u0026gt; 0 ? matrix[i][j - 1] : 0; matrix[i][j] += Math.max(a, b); } } System.out.println(Arrays.deepToString(matrix)); return matrix[matrix.length - 1][matrix[0].length - 1]; } "});index.add({'id':169,'href':'/interview/docs/offer/FirstNotRepeatingChar/','title':"第一个只出现一次的字符",'content':"题目 牛客网\n在一个字符串(0\u0026lt;=字符串长度\u0026lt;=10000，全部由字母组成)中找到第一个只出现一次的字符,并返回它的位置, 如果没有则返回 -1（需要区分大小写）.\n解题思路  通过 LinkedHashMap 记录数组顺序，然后计算字符出现的次数 遍历找到第一个只出现 1次 的字符  public int FirstNotRepeatingChar(String str) { LinkedHashMap\u0026lt;Character, Integer\u0026gt; data = new LinkedHashMap\u0026lt;\u0026gt;(); char[] chars = str.toCharArray(); for (char c : chars) { Integer count = data.getOrDefault(c, 0); data.put(c, count + 1); } Character res = null; for (Character c : data.keySet()) { if (data.get(c) == 1) { res = c; break; } } if (res == null) { return -1; } for (int i = 0; i \u0026lt; chars.length; i++) { if (chars[i] == res) { return i; } } return -1; } "});index.add({'id':170,'href':'/interview/docs/leetcode/salary/','title':"第二高的薪水",'content':"头条重点\n题目 编写一个 SQL 查询，获取 Employee 表中第二高的薪水（Salary） 。\n+----+--------+ | Id | Salary | +----+--------+ | 1 | 100 | | 2 | 200 | | 3 | 300 | +----+--------+ 例如上述 Employee 表，SQL查询应该返回 200 作为第二高的薪水。如果不存在第二高的薪水，那么查询应返回 null。\n+---------------------+ | SecondHighestSalary | +---------------------+ | 200 | +---------------------+ 解题思路  子查询  select IFNULL((select Distinct Salary from Employee order by Salary DESC limit 1,1),null) as SecondHighestSalary "});index.add({'id':171,'href':'/interview/docs/leetcode/simplifyPath/','title':"简化路径",'content':"头条重点\n题目 以 Unix 风格给出一个文件的绝对路径，你需要简化它。或者换句话说，将其转换为规范路径。\n在 Unix 风格的文件系统中，一个点（.）表示当前目录本身；此外，两个点 （..） 表示将目录切换到上一级（指向父目录）；两者都可以是复杂相对路径的组成部分。\n请注意，返回的规范路径必须始终以斜杠 / 开头，并且两个目录名之间必须只有一个斜杠 /。最后一个目录名（如果存在）不能以 / 结尾。此外，规范路径必须是表示绝对路径的最短字符串。\n示例 1： 输入：\u0026quot;/home/\u0026quot; 输出：\u0026quot;/home\u0026quot; 解释：注意，最后一个目录名后面没有斜杠。 示例 2： 输入：\u0026quot;/../\u0026quot; 输出：\u0026quot;/\u0026quot; 解释：从根目录向上一级是不可行的，因为根是你可以到达的最高级。 示例 3： 输入：\u0026quot;/home//foo/\u0026quot; 输出：\u0026quot;/home/foo\u0026quot; 解释：在规范路径中，多个连续斜杠需要用一个斜杠替换。 示例 4： 输入：\u0026quot;/a/./b/../../c/\u0026quot; 输出：\u0026quot;/c\u0026quot; 示例 5： 输入：\u0026quot;/a/../../b/../c//.//\u0026quot; 输出：\u0026quot;/c\u0026quot; 示例 6： 输入：\u0026quot;/a//b////c/d//././/..\u0026quot; 输出：\u0026quot;/a/b/c\u0026quot; 解题思路  利用栈的特性，将有效路径名压入 当遇到 .. 时 pop 栈 最后按顺序 pop 组成最终路径  public static String simplifyPath(String path) { ArrayDeque\u0026lt;String\u0026gt; stack = new ArrayDeque\u0026lt;\u0026gt;(); String[] split = path.split(\u0026quot;/\u0026quot;); for (String s : split) { if (s.isEmpty()) { continue; } switch (s) { case \u0026quot;..\u0026quot;: stack.pollLast(); break; case \u0026quot;.\u0026quot;: break; default: stack.offerLast(s); } } StringBuilder builder = new StringBuilder(\u0026quot;/\u0026quot;); for (String s : stack) { builder.append(s); builder.append(\u0026quot;/\u0026quot;); } if (builder.length() \u0026gt; 1) { builder.deleteCharAt(builder.length() - 1); } return builder.toString(); } "});index.add({'id':172,'href':'/interview/docs/basic/algo/','title':"算法",'content':"算法 "});index.add({'id':173,'href':'/interview/docs/architecture/base/','title':"系统架构基础",'content':"系统架构基础 分布式系统的最大难点，就是各个节点的状态如何同步。CAP 定理是这方面的基本定理，也是理解分布式系统的起点。\n1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。\nConsistency Availability Partition tolerance 它们的第一个字母分别是 C、A、P。Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。\nCAP 它指出对于一个分布式计算系统来说，不可能同时满足以下三点：\n 一致性（Consistency） （等同于所有节点访问同一份最新的数据副本） 可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据） 分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。）  数据一致性模型 一些分布式系统通过复制数据来提高系统的可靠性和容错性，并且将数据的不同的副本存放在不同的机器，由于维护数据副本的一致性代价高，因此许多系统采用弱一致性来提高性能，一些不同的一致性模型也相继被提出。\n 强一致性： 要求无论更新操作实在哪一个副本执行，之后所有的读操作都要能获得最新的数据。 弱一致性：用户读到某一操作对系统特定数据的更新需要一段时间，我们称这段时间为“不一致性窗口”。 最终一致性：是弱一致性的一种特例，保证用户最终能够读取到某操作对系统特定数据的更新。  一致性解决方案  分布式事务：两段提交 分布式锁 MQ 消息持久化 重试 幂等 Paxos 算法  服务可用性 可用性，意思是只要收到用户的请求，服务器就必须给出回应。\n高可用解决方案  负载均衡： 降级：当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。 熔断：对于目标服务的请求和调用大量超时或失败，这时应该熔断该服务的所有调用，并且对于后续调用应直接返回，从而快速释放资源，确保在目标服务不可用的这段时间内，所有对它的调用都是立即返回，不会阻塞的。再等到目标服务好转后进行接口恢复。 流量控制： 异地多活：  熔断是减少由于下游服务故障对自己的影响；而降级则是在整个系统的角度上，考虑业务整体流量，保护核心业务稳定。\n分区容错性 大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。\n般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。\n"});index.add({'id':174,'href':'/interview/docs/java/concurrent/interrupt/','title':"线程中断",'content':"线程中断 中断不是类似 linux 里面的命令 kill -9 pid，不是说我们中断某个线程，这个线程就停止运行了。中断代表线程状态，每个线程都关联了一个中断状态，是一个 true 或 false 的 boolean 值，初始值为 false。\n关于中断状态，我们需要重点关注 Thread 类中的以下几个方法：\n// Thread 类中的实例方法，持有线程实例引用即可检测线程中断状态 public boolean isInterrupted() {} // Thread 中的静态方法，检测调用这个方法的线程是否已经中断 // 注意：这个方法返回中断状态的同时，会将此线程的中断状态重置为 false // 所以，如果我们连续调用两次这个方法的话，第二次的返回值肯定就是 false 了 public static boolean interrupted() {} // Thread 类中的实例方法，用于设置一个线程的中断状态为 true public void interrupt() {} 我们说 中断一个线程，其实就是设置了线程的 interrupted status 为 true，至于说被中断的线程怎么处理这个状态，那是那个线程自己的事。如以下代码：\nwhile (!Thread.interrupted()) { doWork(); System.out.println(\u0026quot;我做完一件事了，准备做下一件，如果没有其他线程中断我的话\u0026quot;); }  这种代码就是会响应中断的，它会在干活的时候先判断下中断状态，不过，除了 JDK 源码外，其他用中断的场景还是比较少的，毕竟 JDK 源码非常讲究。\n 当然，中断除了是线程状态外，还有其他含义，否则也不需要专门搞一个这个概念出来了。如果线程处于以下三种情况，那么当线程被中断的时候，能自动感知到：\n  来自 Object 类的 wait()、wait(long)、wait(long, int)，来自 Thread 类的 join()、join(long)、join(long, int)、sleep(long)、sleep(long, int)\n 这几个方法的相同之处是，方法上都有: throws InterruptedException 如果线程阻塞在这些方法上（我们知道，这些方法会让当前线程阻塞），这个时候如果其他线程对这个线程进行了中断，那么这个线程会从这些方法中立即返回，抛出 InterruptedException 异常，同时重置中断状态为 false。\n   实现了 InterruptibleChannel 接口的类中的一些 I/O 阻塞操作，如 DatagramChannel 中的 connect 方法和 receive 方法等\n 如果线程阻塞在这里，中断线程会导致这些方法抛出 ClosedByInterruptException 并重置中断状态。\n   Selector 中的 select 方法\n 一旦中断，方法立即返回\n   对于以上 3 种情况是最特殊的，因为他们能自动感知到中断（这里说自动，当然也是基于底层实现），并且在做出相应的操作后都会重置中断状态为 false。\n那是不是只有以上 3 种方法能自动感知到中断呢？不是的，如果线程阻塞在 LockSupport.park(Object obj) 方法，也叫挂起，这个时候的中断也会导致线程唤醒，但是唤醒后不会重置中断状态，所以唤醒后去检测中断状态将是 true。\nInterruptedException 概述 它是一个特殊的异常，不是说 JVM 对其有特殊的处理，而是它的使用场景比较特殊。通常，我们可以看到，像 Object 中的 wait() 方法，ReentrantLock 中的 lockInterruptibly() 方法，Thread 中的 sleep() 方法等等，这些方法都带有 throws InterruptedException，我们通常称这些方法为阻塞方法（blocking method）。\n阻塞方法一个很明显的特征是，它们需要花费比较长的时间（不是绝对的，只是说明时间不可控），还有它们的方法结束返回往往依赖于外部条件，如 wait 方法依赖于其他线程的 notify，lock 方法依赖于其他线程的 unlock 等等。\n当我们看到方法上带有 throws InterruptedException 时，我们就要知道，这个方法应该是阻塞方法，我们如果希望它能早点返回的话，我们往往可以通过中断来实现。\n除了几个特殊类（如 Object，Thread等）外，感知中断并提前返回是通过轮询中断状态来实现的。我们自己需要写可中断的方法的时候，就是通过在合适的时机（通常在循环的开始处）去判断线程的中断状态，然后做相应的操作（通常是方法直接返回或者抛出异常）。当然，我们也要看到，如果我们一次循环花的时间比较长的话，那么就需要比较长的时间才能感知到线程中断了。\n处理中断 一旦中断发生，我们接收到了这个信息，然后怎么去处理中断呢？本小节将简单分析这个问题。\n我们经常会这么写代码：\ntry { Thread.sleep(10000); } catch (InterruptedException e) { // ignore } // go on 当 sleep 结束继续往下执行的时候，我们往往都不知道这块代码是真的 sleep 了 10 秒，还是只休眠了 1 秒就被中断了。这个代码的问题在于，我们将这个异常信息吞掉了。（对于 sleep 方法，我相信大部分情况下，我们都不在意是否是中断了，这里是举例）\nAQS 的做法很值得我们借鉴，我们知道 ReentrantLock 有两种 lock 方法：\npublic void lock() { sync.lock(); } public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } 前面我们提到过，lock() 方法不响应中断。如果 thread1 调用了 lock() 方法，过了很久还没抢到锁，这个时候 thread2 对其进行了中断，thread1 是不响应这个请求的，它会继续抢锁，当然它不会把“被中断”这个信息扔掉。我们可以看以下代码：\npublic final void acquire(int arg) { if (!tryAcquire(arg) \u0026amp;\u0026amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 我们看到，这里也没做任何特殊处理，就是记录下来中断状态。  // 这样，如果外层方法需要去检测的时候，至少我们没有把这个信息丢了  selfInterrupt();// Thread.currentThread().interrupt(); } 而对于 lockInterruptibly() 方法，因为其方法上面有 throws InterruptedException ，这个信号告诉我们，如果我们要取消线程抢锁，直接中断这个线程即可，它会立即返回，抛出 InterruptedException 异常。\n在并发包中，有非常多的这种处理中断的例子，提供两个方法，分别为响应中断和不响应中断，对于不响应中断的方法，记录中断而不是丢失这个信息。如 Condition 中的两个方法就是这样的：\nvoid await() throws InterruptedException; void awaitUninterruptibly(); 实例分析 有以下代码：\nsynchronized (this) { while (client == null) { try { this.wait(); } catch (InterruptedException e) { LOGGER.error(\u0026#34;InterruptedException:{}\u0026#34;, e); Thread.currentThread().interrupt(); } } } 上面的代码会造成什么问题？仔细分析可以发现，代码中如果抛出 InterruptedException，就会陷入死循环中，导致异常日志打爆。为什么会这样呢？首先我们来看下这两个方法：\n wait(): if any thread interrupted the current thread before or while the current thread was waiting for a notification. The interrupted status of the current thread is cleared when this exception is thrown. Thread.currentThread().interrupt():If none of the previous conditions hold then this thread's interrupt status will be set.  wait() 在当前线程有中断标志位时抛出中断异常；而 interrupt() 如果当前线程没有在wait()等阻塞操作，则标记中断。这样就陷入死循环，无限的打印 ERROR 日志。正确的处理 InterruptedException 是很重要的。\n"});index.add({'id':175,'href':'/interview/docs/leetcode/LRUCache/','title':"缓存机制",'content':"头条重点\n题目 运用你所掌握的数据结构，设计和实现一个 LRU (最近最少使用) 缓存机制。它应该支持以下操作： 获取数据 get 和 写入数据 put 。\n获取数据 get(key) - 如果密钥 (key) 存在于缓存中，则获取密钥的值（总是正数），否则返回 -1。 写入数据 put(key, value) - 如果密钥不存在，则写入其数据值。当缓存容量达到上限时，它应该在写入新数据之前删除最近最少使用的数据值，从而为新的数据值留出空间。\n进阶:\n你是否可以在 O(1) 时间复杂度内完成这两种操作？\n示例: LRUCache cache = new LRUCache( 2 /* 缓存容量 */ ); cache.put(1, 1); cache.put(2, 2); cache.get(1); // 返回 1 cache.put(3, 3); // 该操作会使得密钥 2 作废 cache.get(2); // 返回 -1 (未找到) cache.put(4, 4); // 该操作会使得密钥 1 作废 cache.get(1); // 返回 -1 (未找到) cache.get(3); // 返回 3 cache.get(4); // 返回 4 解题思路 class LRUCache extends LinkedHashMap\u0026lt;Integer, Integer\u0026gt;{ private final int capacity; public LRUCache(int capacity) { super(capacity*, 0.75f, true); this.capacity = capacity; } public int get(int key) { Integer integer = super.get(key); return integer == null ? -1 : integer; } public void put(int key, int value) { super.put(key, value); } @Override protected boolean removeEldestEntry(Map.Entry\u0026lt;Integer, Integer\u0026gt; eldest) { return size() \u0026gt; this.capacity; } } "});index.add({'id':176,'href':'/interview/docs/leetcode/validUtf8/','title':"编码验证",'content':"头条重点\n题目 UTF-8 中的一个字符可能的长度为 1 到 4 字节，遵循以下的规则：\n 对于 1 字节的字符，字节的第一位设为0，后面7位为这个符号的unicode码。 对于 n 字节的字符 (n \u0026gt; 1)，第一个字节的前 n 位都设为1，第 n+1 位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。  这是 UTF-8 编码的工作方式：\n Char. number range | UTF-8 octet sequence (hexadecimal) | (binary) --------------------+--------------------------------------------- 0000 0000-0000 007F | 0xxxxxxx 0000 0080-0000 07FF | 110xxxxx 10xxxxxx 0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx 0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 给定一个表示数据的整数数组，返回它是否为有效的 utf-8 编码。\n注意：输入是整数数组。只有每个整数的最低 8 个有效位用来存储数据。这意味着每个整数只表示 1 字节的数据。\n示例 1: data = [197, 130, 1], 表示 8 位的序列: 11000101 10000010 00000001. 返回 true 。 这是有效的 utf-8 编码，为一个2字节字符，跟着一个1字节字符。 解题思路 class Solution { public boolean validUtf8(int[] data) { int totalByteCount = 0; for (int item : data) { if (totalByteCount == 0) { totalByteCount = totalByteCount(item); if (totalByteCount == -1) { return false; } totalByteCount--; continue; } //10xxxxxx检查 if ((item \u0026amp; 0xC0) != 0x80) { return false; } totalByteCount--; } return totalByteCount == 0; } private int totalByteCount(int i) { if ((i \u0026amp; 0x80) == 0) { return 1; } if ((i \u0026amp; 0xE0) == 0xC0) { return 2; } if ((i \u0026amp; 0xF0) == 0xE0) { return 3; } if ((i \u0026amp; 0xF8) == 0xF0) { return 4; } return -1; } } "});index.add({'id':177,'href':'/interview/docs/basic/net/','title':"网络分层",'content':"网络分层 OSI    层 功能     应用层 网络进程到应用程序。针对特定应用规定各层协议、时序、表示等，进行封装 。在端系统中用软件来实现，如HTTP等   表示层 数据表示形式，加密和解密，把机器相关的数据转换成独立于机器的数据。规定数据的格式化表示 ，数据格式的转换等   会话层 主机间通讯，管理应用程序之间的会话。规定通信时序 ；数据交换的定界、同步，创建检查点等   传输层 在网络的各个节点之间可靠地分发数据包。所有传输遗留问题；复用；流量；可靠   网络层 在网络的各个节点之间进行地址分配、路由和（不一定可靠的）分发报文。路由（ IP寻址）；拥塞控制。   数据链路层 一个可靠的点对点数据直链。检错与纠错（CRC码）；多路访问；寻址   物理层 一个（不一定可靠的）点对点数据直链。定义机械特性；电气特性；功能特性；规程特性    "});index.add({'id':178,'href':'/interview/docs/basic/net/protocol/','title':"网络协议",'content':"底层网络协议 ARP（地址解析协议） 基本功能为透过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的顺利进行。在每台安装有TCP/IP协议的电脑或路由器里都有一个ARP缓存表，表里的IP地址与MAC地址是一对应的。\n当发送数据时，主机A会在自己的ARP缓存表中寻找是否有目标IP地址。如果找到就知道目标MAC地址为（00-BB-00-62-C2-02），直接把目标MAC地址写入帧里面发送就可；如果在ARP缓存表中没有找到相对应的IP地址，主机A就会在网络上发送一个 广播（ARP request），目标MAC地址是“FF.FF.FF.FF.FF.FF”，这表示向同一网段内的所有主机发出这样的询问：“192.168.38.11的MAC地址是什么？”网络上其他主机并不响应ARP询问，只有主机B接收到这个帧时，才向主机A做出这样的回应（ARP response）：“192.168.38.11的MAC地址是（00-BB-00-62-C2-02）”。这样，主机A就知道主机B的MAC地址，它就可以向主机B发送信息。同时它还更新自己的ARP缓存表，下次再向主机B发送信息时，直接从ARP缓存表里查找就可。ARP缓存表采用老化机制，在一段时间内如果表中的某一行没有使用，就会被删除，这样可以大大减少ARP缓存表的长度，加快查询速度。\n 当发送主机和目的主机不在同一个局域网中时，即便知道目的主机的MAC地址，两者也不能直接通信，必须经过路由转发才可以。所以此时，发送主机通过ARP协议获得的将不是目的主机的真实MAC地址，而是一台可以通往局域网外的路由器的MAC地址。于是此后发送主机发往目的主机的所有帧，都将发往该路由器，通过它向外发送。这种情况称为ARP代理（ARP Proxy）。\n ICMP（互联网控制消息协议） 它 用于TCP/IP网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，令管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。它与传输协议最大的不同：它一般不用于在两点间传输数据，而常常 用于返回的错误信息或是分析路由。\nICMP控制的内容包括但不仅限于：echo响应（ping）、目标网络不可达、目标端口不可达、禁止访问的网络、拥塞控制、重定向、TTL超时\u0026hellip;\n路由选择协议 路由选择协议分为：静态的和动态的。Internet中使用的是动态路由选择协议，在Internet的概念中，将整个互联网划分为许多个小的自治系统（AS）。AS的最主要的特征：一个AS对其他AS表现出的是一个单一 和一致的路由选择策略。\n由于AS的存在，路由选择协议又分为两种：\n 内部网关协议（IGP）：即在一个AS内部使用的路由选择协议，而这与互联网中其他AS选用什么路由协议无关。比如：OSPF 外部网关协议（EGP）：若源主机和目的主机不再同一个AS中，就需要使用一种协议将路由选择信息传递到另一个AS中，这就是EGP。比如：BGP。  OSPF（开放式最短路径优先） OSPF属于内部网关协议（IGP）的一种，使用Dijkstra提出的最短路径算法。\nOSPF提出了“区域（Area）”的概念，一个网络可以由单一区域或者多个区域组成。其中，一个特别的区域被称为骨干区域（Backbone Area），该区域是整个OSPF网络的核心区域，并且所有其他的区域都与之直接连接。所有的内部路由都通过骨干区域传递到其他非骨干区域。所有的区域都必须直接连接到骨干区域，如果不能创建直接连接，那么可以通过虚拟链路（Virtual-link）和骨干区域创建虚拟连接。\n划分区域的优点：\n  将洪泛法的范围限制在一个区域中。\n  减少每个区域内部路由信息交换的通信量。\n  OSPF使用的是分布式链路状态协议，使用 洪泛法向该路由器所有的相邻路由器发送信息。最终整个区域的所有路由器都得到一个这个信息的副本。这个副本就是 链路状态数据库（LSDB）用来保存当前网络拓扑结构，路由器上属于同一区域的链路状态数据库是相同的（属于多个区域的路由器会为每个区域维护一份链路状态数据库）。\n  OSPF使用 **“代价（Cost）”**作为路由度量。\n  只有当链路发生变化时才会更新信息。\n   如果同一个目的网络有多条路径，OSPF协议可以进行 负载均衡。\n BGP（边界网关协议） 由于BGP是工作在AS之间的协议，并且各个AS的情况复杂，所以 BGP只是力求找到一个可以到达目的网络且比较好的路由，而并不是寻找一条最佳路由。每一个AS都应该有一个**“BGP发言人“**，一般来说，两个BGP发言人是通过一个共享网络连接在一起的，BGP发言人往往是**BGP边界路由**，但也可以不是。\n一个BGP发言人与其他AS的BGP发言人要交换路由信息，首先要建立TCP连接，然后在此连接上交换BGP报文以建立BGP会话。当BGP发言人交换了路由信息后，就构造自治系统连通图，最后通过该图来进行路由选择。\nDHCP（动态主机设置协议） DHCP是一个局域网的网络协议，使用UDP协议工作，主要有两个用途：\n 用于内部网络或网络服务供应商自动分配IP地址给用户 用于内部网络管理员作为对所有电脑作中央管理的手段  动态主机设置协议（DHCP）是一种使网络管理员能够集中管理和自动分配IP网络地址的通信协议。在IP网络中，每个连接Internet的设备都需要分配唯一的IP地址。DHCP使网络管理员能从中心结点监控和分配IP地址。当某台计算机移到网络中的其它位置时，能自动收到新的IP地址。\nDHCP使用了 租约 的概念，或称为计算机IP地址的有效期。租用时间是不定的，主要取决于用户在某地连接Internet需要多久，这对于教育行业和其它用户频繁改变的环境是很实用的。通过较短的租期，DHCP能够在一个计算机比可用IP地址多的环境中动态地重新配置网络。DHCP支持为计算机分配静态地址，如需要永久性IP地址的Web服务器。\nNAT（地址转换协议） NAT是一种 在IP封包通过路由器或防火墙时重写来源IP地址或目的IP地址的技术。这种技术被普遍使用在有多台主机但只通过一个公有IP地址访问因特网的私有网络中。\n"});index.add({'id':179,'href':'/interview/docs/offer/ReverseSentence/','title':"翻转单词顺序列",'content':"题目 牛客网\n牛客最近来了一个新员工 Fish ，每天早晨总是会拿着一本英文杂志，写些句子在本子上。同事Cat对Fish写的内容颇感兴趣，有一天他向Fish借来翻看，但却读不懂它的意思。例如，“student. a am I”。后来才意识到，这家伙原来把句子单词的顺序翻转了，正确的句子应该是“I am a student.”。Cat对一一的翻转这些单词顺序可不在行，你能帮助他么？\n解题思路 public String ReverseSentence(String str) { if(str == null || str.trim().equals(\u0026quot;\u0026quot;)) return str; String[] split = str.split(\u0026quot; \u0026quot;); StringBuilder builder = new StringBuilder(); for (int i = split.length - 1; i \u0026gt;= 0; i--) { builder.append(split[i]); if (i != 0) builder.append(\u0026quot; \u0026quot;); } return builder.toString(); } "});index.add({'id':180,'href':'/interview/docs/leetcode/reverseWords/','title':"翻转字符串里的单词",'content':"题目 给定一个字符串，逐个翻转字符串中的每个单词。\n示例 1： 输入: \u0026quot;the sky is blue\u0026quot; 输出: \u0026quot;blue is sky the\u0026quot; 说明：\n 无空格字符构成一个单词。 输入字符串可以在前面或者后面包含多余的空格，但是反转后的字符不能包括。 如果两个单词间有多余的空格，将反转后单词间的空格减少到只含一个。  解题思路  按空格拆分字符串为字符串数组 t 逆序遍历字符串数组 t，并组成新的字符串  public String reverseWords(String s) { String trimed = s.trim(); String[] split = trimed.split(\u0026quot; \u0026quot;); StringBuilder builder = new StringBuilder(); for (int i = split.length - 1; i \u0026gt;= 0; i--) { String t = split[i]; if (t.trim().isEmpty()) { continue; } builder.append(t).append(\u0026quot; \u0026quot;); } return builder.toString().trim(); } "});index.add({'id':181,'href':'/interview/docs/offer/MaxProfit/','title':"股票的最大利润",'content':"题目 一只股票在某些时间节点的价格为{9,11,8,5,7,12,16,14}。如果我们能在价格为 5 的时候买入并在价格为 16 时卖出，则能获得最大的利润为 11.\n解题思路  要先买入才能卖出，先找最低价格点 再找最低价格之后的最高价格，用 maxProfit 表示最大利润  public int maxProfit(int[] nums) { if (nums == null || nums.length == 0) return 0; int min = Integer.MAX_VALUE; int maxProfit = 0; for (int i = 0; i \u0026lt; nums.length; i++) { min = Math.min(min, nums[i]); maxProfit = Math.max(maxProfit, nums[i] - min); } return maxProfit; } "});index.add({'id':182,'href':'/interview/docs/offer/IsNumeric/','title':"表示数值的字符串",'content':"题目 请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。例如，字符串\u0026quot;+100\u0026rdquo;,\u0026ldquo;5e2\u0026rdquo;,\u0026quot;-123\u0026rdquo;,\u0026ldquo;3.1416\u0026quot;和\u0026rdquo;-1E-16\u0026quot;都表示数值。 但是\u0026quot;12e\u0026rdquo;,\u0026ldquo;1a3.14\u0026rdquo;,\u0026ldquo;1.2.3\u0026rdquo;,\u0026ldquo;+-5\u0026quot;和\u0026quot;12e+4.3\u0026quot;都不是。\n解题思路  数字符合 A[.[B]][e|EC] 和 .B[e|EC] 的表达式，其中 A 表示整数部分，B 表示小数部分，C 表示指数部分 A 可以有正负，但是 B 没有 e|E 之前、之后都必须有数字  public boolean isNumeric(char[] str) { if (str == null || str.length == 0) return false; int index = scanInteger(str, 0); boolean numeric = index != 0; //小数 if (index \u0026lt; str.length \u0026amp;\u0026amp; str[index] == '.') { index++; int pre = index; index = scanUnsignedInteger(str, index); //1. 小数可以没有整数部分 //2. 小数后可以没有数字 //3. 小数后可以有数字 numeric |= index != pre; } //指数 if (index \u0026lt; str.length \u0026amp;\u0026amp; (str[index] == 'e' || str[index] == 'E')) { index++; int pre = index; index = scanInteger(str, index); //1. e或者E之前必须有数字 //2. e或者E之后必须有数字 numeric \u0026amp;= index != pre; } return numeric \u0026amp;\u0026amp; index == str.length; } private int scanInteger(char[] str, int s) { if (s \u0026lt; str.length \u0026amp;\u0026amp; (str[s] == '+' || str[s] == '-')) s++; return scanUnsignedInteger(str, s); } private int scanUnsignedInteger(char[] str, int s) { while (s \u0026lt; str.length \u0026amp;\u0026amp; str[s] \u0026gt;= '0' \u0026amp;\u0026amp; str[s] \u0026lt;= '9') { s++; } return s; } "});index.add({'id':183,'href':'/interview/docs/basic/os/arch/','title':"计算机体系结构",'content':"计算机体系结构 冯·诺依曼体系结构   计算机处理的数据和指令一律用二进制数表示\n  顺序执行程序\n计算机运行过程中，把要执行的程序和处理的数据首先存入主存储器（内存），计算机执行程序时，将自动地并按顺序从主存储器中取出指令一条一条地执行，这一概念称作顺序执行程序。\n  计算机硬件由运算器、控制器、存储器、输入设备和输出设备五大部分组成。\n  数据的机内表示 二进制表示 机器数 由于计算机中符号和数字一样，都必须用二进制数串来表示，因此，正负号也必须用0,1来表示。\n原码 原码用第一位表示符号, 其余位表示值. 比如如果是8位二进制:\n[+1]原 = 0000 0001 [-1]原 = 1000 0001 第一位是符号位. 因为第一位是符号位, 所以8位二进制数的取值范围就是: [1111 1111 , 0111 1111] 即 [-127 , 127] 原码是人脑最容易理解和计算的表示方式\n反码  正数的反码是其本身 负数的反码是在其原码的基础上, 符号位不变，其余各个位取反.  [+1] = [00000001]原 = [00000001]反 [-1] = [10000001]原 = [11111110]反 可见如果一个反码表示的是负数，人脑无法直观的看出来它的数值， 通常要将其转换成原码再计算。\n补码  正数的补码就是其本身 负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1。 (即在反码的基础上+1)  [+1] = [00000001]原 = [00000001]反 = [00000001]补 [-1] = [10000001]原 = [11111110]反 = [11111111]补 1+（-1)= 00000001 + 11111111 = 00000000 = 0 对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值.\n 在计算机系统中，数值一律用补码来表示和存储。原因在于，使用补码，可以将符号位和数值域统一处理；同时，加法和减法也可以统一处理。此外，补码与原码相互转换，其运算过程是相同的，不需要额外的硬件电路。\n 定点数与浮点数 定点数是小数点固定的数。在计算机中没有专门表示小数点的位，小数点的位置是约定默认的。一般固定在机器数的最低位之后，或是固定在符号位之后。前者称为定点纯整数，后者称为定点纯小数。\n 定点数表示法简单直观，但是 数值表示的范围太小，运算时容易产生溢出。\n 浮点数是小数点的位置可以变动的数。为增大数值表示范围，防止溢出，采用浮点数表示法。浮点表示法类似于十进制中的科学计数法。\n在计算机上，通常使用2为基数的幂数来表式。一个浮点数a由两个数m和e来表示：a = m × b^e。在任意一个这样的系统中，我们选择一个基数b（记数系统的基）和精度p（即使用多少位来存储）。m （即尾数）是形如±d.ddd...ddd的p位数（每一位是一个介于0到b-1之间的整数，包括0和b-1）。如果m的第一位是非0整数，m称作正规化的。e是指数。\n| 数符± | 阶码e | 尾数m | 数符表示尾数的符号位，阶码表示幂次，尾数表示规格化后的小数值。\n 32位单精度：单精度二进制小数，使用32位存储。1 8 23 位长 64位双精度：双精度二进制小数，使用64位存储。1 11 52 位长  位、字节、字   位(Bit)：电子计算机中最小的数据单位。每一位的状态只能是0或1。\n  字节(Byte)：8个二进制位构成1个字节，它是存储空间的基本计量单位。1个字节可以储存1个英文字母或者半个汉字，换句话说，1个汉字占据2个字节的存储空间。\n  字(Word)：由若干个字节构成，字的位数叫做字长，不同档次的机器有不同的字长。例如一台8位机，它的1个字就等于1个字节，字长为8位。如果是一台16位机，那么，它的1个字就由2个字节构成，字长为16位。字是计算机进行数据处理和运算的单位。\n  字节序 字节顺序是指占内存多于一个字节类型的数据在内存中的存放顺序，通常有小端、大端两种字节顺序。\n  小端字节序：低字节数据存放在内存低地址处，高字节数据存放在内存高地址处。\n  大端字节序：高字节数据存放在低地址处，低字节数据存放在高地址处。\n  基于X86平台的PC机是小端字节序的，而有的嵌入式平台则是大端字节序的。所有网络协议也都是采用大端字节序的方式来传输数据的。所以有时我们也会把大端字节序方式称之为网络字节序。\n比如数字 0x12345678 在两种不同字节序CPU中的存储顺序如下所示： Big Endian 低地址 高地址 ----------------------------------------------------\u0026gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | 12 | 34 | 56 | 78 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Little Endian 低地址 高地址 ----------------------------------------------------\u0026gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | 78 | 56 | 34 | 12 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 从上面两图可以看出，采用Big Endian方式存储数据是符合我们人类的思维习惯的。 联合体union的存放顺序是所有成员都从低地址开始存放，利用该特性，就能判断CPU对内存采用Little-endian还是Big-endian模式读写。\n字节对齐 现代计算机中内存空间都是按照字节划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定类型变量的时候经常在特定的内存地址访问，这就需要各种类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐。\n  为什么要进行字节对齐？\n 某些平台只能在特定的地址处访问特定类型的数据; 最根本的原因是效率问题，字节对齐能提高存取数据的速度。    比如有的平台每次都是从偶地址处读取数据,对于一个int型的变量,若从偶地址单元处存放,则只需一个读取周期即可读取该变量，但是若从奇地址单元处存放，则需要2个读取周期读取该变量。\n  字节对齐的原则\n  数据成员对齐规则：结构体或联合体的数据成员，第一个数据成员放在 offset 为0的地方，以后每个数据成员存储的起始位置要从该成员大小或者成员的子成员大小（只要该成员有子成员，比如说是数组，结构体等）的整数倍开始（比如int在32位机为4字节,则要从4的整数倍地址开始存储）。\n  结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。(struct a里存有struct b,b里有char,int ,double等元素,那b应该从8的整数倍开始存储。)\n  收尾工作：结构体的总大小，也就是sizeof的结果，必须是其内部最大成员的整数倍，不足的要补齐。\n    "});index.add({'id':184,'href':'/interview/docs/basic/os/device/','title':"设备管理",'content':"设备管理 外部设备分为两大类：\n 存储型设备：以存储大量信息和快速检索为目标，在系统中存储持久性信息。 I/O型设备：如显示器、打印机等。  I/O硬件原理 I/O系统 通常把I/O设备及其接口线路、控制部件、通道和管理软件称为I/O系统，把计算机的内存和设备介质之间的信息传送操作称为I/O操作。可按照不同方式对设备进行分类：按I/O操作特性分为输入型设备、输出型设备和存储型设备；按I/O信息交换单位分为字符设备和块设备。\n 输入、输出型设备通常是字符设备，存储型设备通常是块设备。\n 存储型设备又分为顺序存储设备和直接存取设备。前者严格依赖信息的物理位置进行读写和定位，如磁带。后者的特点是存取任何一个物理块所需要的时间几乎不依赖于此信息所处的位置，如磁盘。\nI/O控制方式 轮询方式 轮询方式又称程序直接控制方式，使用查询指令测试设备控制器的忙闲状态位，确定内存和设备是否能交换数据。轮询方式采用三条指令：查询指令，查询设备是否就绪；读写指令，当设备就绪时执行数据交换；转移指令，当设备未就绪时执行转移指令指向查询指令继续查询。可见，在这种方式下CPU和设备只能串行工作。\n中断方式 在这种方式下CPU和设备之间传输数据的过程如下：\n  进程发出启动I/O指令，CPU加载控制信息到设备控制器的寄存器，然后进程继续执行不涉及本次I/O数据的任务，或放弃CPU等待设备I/O操作完成。\n  设备控制器检查寄存器的内容，按照I/O指令的要求执行相应I/O操作，一旦传输完成，设备控制器发出I/O中断请求信号。\n  CPU收到并响应I/O中断后，转向设备的I/O中断处理程序执行。\n  中断处理程序执行数据读取操作，将I/O缓冲寄存器的内容写入内存，操作结束后退出中断处理程序，返回发生中断前的状态。\n  进程调度程序在适当的时候让得到数据的进程恢复执行。\n  在I/O中断方式中，如果设备控制器的数据缓冲区较小，当缓冲器装满后便会发生中断，那么在数据传输过程中发生中断次数会很多，这样就消耗了大量CPU时间。\nDMA方式 虽然中断方式提高了CPU利用率，但是在响应中断请求后必须停止现行程序，转入中断处理程序并参与数据传输操作。在DMA(Direct Memory Access)方式中，内存和设备之间有一条数据通路成块地传送数据，无须CPU干预，实际数据传输操作由DMA直接完成。为实现DMA，至少需要以下逻辑部件：\n  内存地址寄存器：存放内存中需要交换数据的地址，DMA传送之前由程序送入首地址；DMA传送过程中，每次交换数据都把地址寄存器的内容加1。\n  字计数器：记录传送数据的总字数，每次传送一个字就把字计数器减1。\n  数据缓冲寄存器或数据缓冲区：暂存每次传送的数据。\n  设备地址寄存器：存放I/O信息的地址，如磁盘的柱面号。\n  中断机制和控制逻辑：用于向CPU提出I/O中断请求及CPU发来的I/O命令，管理DMA的传送过程。\n  通道方式 通道又称I/O处理器，能完成内存和设备之间的信息传送，与CPU并行地执行操作。采用I/O通道设计后，I/O操作过程如下：CPU在执行主程序时遇到I/O请求，启动在指定通道上选址的设备，一旦启动成功，通道开始控制设备进行操作，这时CPU就可以执行其他任务并与通道并行工作，直到I/O操作完成；当通道发出I/O操作结束中断时，处理器才响应并停止当前工作，转向I/O操作结束事件。\n"});index.add({'id':185,'href':'/interview/docs/fromwork/spring/design-partten/','title':"设计模式",'content':"设计模式  代理模式：AOP 单例模式：默认 Bean 为单例 工厂模式：BeanFactory IOC：依赖倒置 or 依赖注入 MVC：spring web 模版方法模式：JdbcTemplate  "});index.add({'id':186,'href':'/interview/docs/offer/reOrderArray/','title':"调整数组顺序使奇数位于偶数前面",'content':"题目 牛客网\n输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。\n解题思路  需要保证排序的稳定性 采用冒泡算法进行排序  public void reOrderArray(int[] array) { if (array.length \u0026lt;= 1) { return; } for (int i = array.length - 1; i \u0026gt;= 0; i--) { for (int j = i; j \u0026lt; array.length - 1; j++) { if (array[j] % 2 == 0 \u0026amp;\u0026amp; array[j + 1] % 2 == 1) swap(array, j, j + 1); } } } private void swap(int[] array, int a, int b) { int t = array[a]; array[a] = array[b]; array[b] = t; } "});index.add({'id':187,'href':'/interview/docs/basic/algo/skip_list/','title':"跳跃表",'content':"跳跃表 跳跃列表是一种数据结构。它允许快速查询一个有序连续元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是 O(log n) ，优于普通队列的 O(n)。\n快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。跳过的元素的方法可以是 随机性选择 或 确定性选择，其中前者更为常见。\n在查找目标元素时，从顶层列表、头元素起步。算法沿着每层链表搜索，直至找到一个大于或等于目标的元素，或者到达当前层列表末尾。如果该元素等于目标元素，则表明该元素已被找到；如果该元素大于目标元素或已到达链表末尾，则退回到当前层的上一个元素，然后转入下一层进行搜索。\n跳跃列表不像平衡树等数据结构那样提供对最坏情况的性能保证：由于用来建造跳跃列表采用随机选取元素进入更高层的方法，在小概率情况下会生成一个不平衡的跳跃列表（最坏情况例如最底层仅有一个元素进入了更高层，此时跳跃列表的查找与普通列表一致）。但是在实际中它通常工作良好，随机化平衡方案也比平衡二叉查找树等数据结构中使用的确定性平衡方案容易实现。跳跃列表在并行计算中也很有用：插入可以在跳跃列表不同的部分并行地进行，而不用对数据结构进行全局的重新平衡。\n跳跃表插入一个元素：\n实现 因为跳跃列表中的元素可以在多个列表中，所以每个元素可以有多于一个指针。跳跃列表的插入和删除的实现与普通的链表操作类似，但高层元素必须在进行多个链表中进行插入或删除。\npackage io.github.hadyang.leetcode.algo; import lombok.Getter; import lombok.Setter; import java.util.Arrays; import java.util.Random; /** * @author haoyang.shi */ public class SkipList\u0026lt;K extends Comparable\u0026lt;K\u0026gt;, V\u0026gt; { @Getter @Setter static final class Node\u0026lt;K extends Comparable\u0026lt;K\u0026gt;, V\u0026gt; { private K key; private V value; private Node\u0026lt;K, V\u0026gt; up, down, pre, next; Node(K key, V value) { this.key = key; this.value = value; } @Override public String toString() { return \u0026quot;Node{\u0026quot; + \u0026quot;key=\u0026quot; + key + \u0026quot;, value=\u0026quot; + value + \u0026quot;, hashcode=\u0026quot; + hashCode() + \u0026quot;, up=\u0026quot; + (up == null ? \u0026quot;null\u0026quot; : up.hashCode()) + \u0026quot;, down=\u0026quot; + (down == null ? \u0026quot;null\u0026quot; : down.hashCode()) + \u0026quot;, pre=\u0026quot; + (pre == null ? \u0026quot;null\u0026quot; : pre.hashCode()) + \u0026quot;, next=\u0026quot; + (next == null ? \u0026quot;null\u0026quot; : next.hashCode()) + '}'; } } private Node\u0026lt;K, V\u0026gt; head;//k,v都是NULL private Integer levels = 0; private Integer length = 0; private Random random = new Random(System.currentTimeMillis()); public SkipList() { createNewLevel(); } public void put(K key, V value) { if (key == null || value == null) { return; } Node\u0026lt;K, V\u0026gt; newNode = new Node\u0026lt;\u0026gt;(key, value); insertNode(newNode); } private void insertNode(Node\u0026lt;K, V\u0026gt; newNode) { Node\u0026lt;K, V\u0026gt; curNode = findNode(newNode.getKey()); if (curNode.getKey() == null) { insertNext(curNode, newNode); } else if (curNode.getKey().compareTo(newNode.getKey()) == 0) { //update curNode.setValue(newNode.getValue()); return; } else { insertNext(curNode, newNode); } int currentLevel = 1; Node\u0026lt;K, V\u0026gt; oldTop = newNode; while (random.nextInt(100) \u0026lt; 50) { Node\u0026lt;K, V\u0026gt; newTop = new Node\u0026lt;\u0026gt;(newNode.getKey(), null); if (currentLevel \u0026gt;= levels) { createNewLevel(); } while (curNode.getPre() != null \u0026amp;\u0026amp; curNode.getUp() == null) { curNode = curNode.getPre(); } if (curNode.getUp() == null) { continue; } curNode = curNode.getUp(); Node\u0026lt;K, V\u0026gt; curNodeNext = curNode.getNext(); curNode.setNext(newTop); newTop.setPre(curNode); newTop.setDown(oldTop); oldTop.setUp(newTop); newTop.setNext(curNodeNext); oldTop = newTop; currentLevel++; } } private void createNewLevel() { Node\u0026lt;K, V\u0026gt; newHead = new Node\u0026lt;\u0026gt;(null, null); if (this.head == null) { this.head = newHead; this.levels++; return; } this.head.setUp(newHead); newHead.setDown(this.head); this.head = newHead; this.levels++; } private void insertNext(Node\u0026lt;K, V\u0026gt; curNode, Node\u0026lt;K, V\u0026gt; newNode) { Node\u0026lt;K, V\u0026gt; curNodeNext = curNode.getNext(); newNode.setNext(curNodeNext); if (curNodeNext != null) { curNodeNext.setPre(newNode); } curNode.setNext(newNode); newNode.setPre(curNode); this.length++; } public V get(K key) { Node\u0026lt;K, V\u0026gt; node = findNode(key); if (key.equals(node.getKey())) { return node.getValue(); } return null; } private Node\u0026lt;K, V\u0026gt; findNode(K key) { Node\u0026lt;K, V\u0026gt; curNode = this.head; for (; ; ) { while (curNode.getNext() != null \u0026amp;\u0026amp; curNode.getNext().getKey().compareTo(key) \u0026lt;= 0) { curNode = curNode.getNext(); } if (curNode.getDown() != null) { curNode = curNode.getDown(); } else { break; } } return curNode; } public void print() { Node\u0026lt;K, V\u0026gt; curI = this.head; String[][] strings = new String[levels][length + 1]; for (String[] string : strings) { Arrays.fill(string, \u0026quot;0\u0026quot;); } while (curI.getDown() != null) { curI = curI.getDown(); } System.out.println(\u0026quot;levels:\u0026quot; + levels + \u0026quot;_\u0026quot; + \u0026quot;length:\u0026quot; + length); int i = 0; while (curI != null) { Node\u0026lt;K, V\u0026gt; curJ = curI; int j = levels - 1; while (curJ != null) { strings[j][i] = String.valueOf(curJ.getKey()); if (curJ.getUp() == null) { break; } curJ = curJ.getUp(); j--; } if (curI.getNext() == null) { break; } curI = curI.getNext(); i++; } for (String[] string : strings) { System.out.println(Arrays.toString(string)); } } public static void main(String[] args) { SkipList\u0026lt;Integer, String\u0026gt; skipList = new SkipList\u0026lt;\u0026gt;(); skipList.put(2, \u0026quot;B\u0026quot;); skipList.put(1, \u0026quot;A\u0026quot;); skipList.put(3, \u0026quot;C\u0026quot;); skipList.print(); System.out.println(skipList.get(2)); } } "});index.add({'id':188,'href':'/interview/docs/java/operator/','title':"运算符",'content':"运算符优先级 优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。\n相同优先级中，按结合顺序计算。大多数运算是从左至右计算，只有三个优先级是从右至左结合的，它们是单目运算符、条件运算符、赋值运算符。\n基本的优先级需要记住：\n 指针最优，单目运算优于双目运算。如正负号。 先乘除（模），后加减。 先算术运算，后移位运算，最后位运算。请特别注意：1 \u0026lt;\u0026lt; 3 + 2 \u0026amp; 7等价于 (1 \u0026lt;\u0026lt; (3 + 2)) \u0026amp; 7. 逻辑运算最后计算。  优先级表    运算符 结合性     [ ] . ( ) (方法调用) 从左向右   ! ~ ++ -- +(一元运算) -(一元运算) 从右向左   * / % 从左向右   + -　 从左向右   \u0026lt;\u0026lt; \u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; 从左向右   \u0026lt; \u0026lt;= \u0026gt; \u0026gt;= instanceof 从左向右   == != 从左向右   \u0026amp; 从左向右   ^ 从左向右   | 从左向右   \u0026amp;\u0026amp; 从左向右   || 从左向右   ?: 从右向左   = += -= *= /= %= \u0026amp;= |= ^= \u0026lt;\u0026lt;= \u0026gt;\u0026gt;= \u0026gt;\u0026gt;= 从右向左   , 从左到右     无符号右移运算符 \u0026gt;\u0026gt;\u0026gt;，无符号右移的规则只记住一点：忽略了符号位扩展，0 补最高位。无符号右移规则和右移运算是一样的，只是填充时不管左边的数字是正是负都用 0 来填充，无符号右移运算只针对负数计算，因为对于正数来说这种运算没有意义。无符号右移运算符 \u0026gt;\u0026gt;\u0026gt; 只是对 32 位和 64 位的值有意义\n "});index.add({'id':189,'href':'/interview/docs/offer/FindGreatestSumOfSubArray/','title':"连续子数组的最大和",'content':"题目 牛客网\n例如:{6,-3,-2,7,-15,1,2,2},连续子向量的最大和为8(从第0个开始,到第3个为止)。给一个数组，返回它的最大连续子序列的和，你会不会被他忽悠住？(子向量的长度至少是1)\n解题思路 通过动态规划计算最大和，   \\(f(i)\\)  定义为以第 \\(i\\)  个数字结尾的子数组的最大和，那么 \\(max(f(i))\\)  就有以下公式：\n$$ max(f(i))=\\begin{cases} num[i] \u0026amp; i=0 or f(i)\u0026lt;0\\\nnum[i]+f(i) \u0026amp; i\\ne0 and f(i)\u0026gt;0 \\end{cases} $$\npublic int FindGreatestSumOfSubArray(int[] array) { if (array == null || array.length == 0) { return 0; } int max = array[0]; int sum = 0; for (int a : array) { if (sum + a \u0026gt; a) { sum += a; } else { sum = a; } if (sum \u0026gt; max) { max = sum; } } return max; } "});index.add({'id':190,'href':'/interview/docs/offer/reConstructBinaryTree/','title':"重建二叉树",'content':"[](https://www.nowcoder.com/practice/8a19cbe657394eeaac2f6ea9b0f6fcf6?tpId=13\u0026amp;tqId=11157\u0026amp;tPage=1\u0026amp;rp=1\u0026amp;ru=%2Fta%2Fcoding-interviews\u0026amp;qru=%2Fta%2Fcoding-interviews%2Fquestion-ranking)\n输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。\n解题思路  通过前序遍历找到 root 节点 那么在 中序遍历中 root 节点的左侧则是左子树，右侧是右子树 依次类推，递归生成节点的左子树和右子树 构建过程由下往上  public TreeNode reConstructBinaryTree(int[] pre, int[] in) { Map\u0026lt;Integer, Integer\u0026gt; preIndex = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; pre.length; i++) { preIndex.put(pre[i], i); } return buildTree(preIndex, in, 0, in.length - 1); } private TreeNode buildTree(Map\u0026lt;Integer, Integer\u0026gt; preIndex, int[] in, int start, int end) { if (start == end) { return new TreeNode(in[start]); } int indexOfRoot = start; for (int i = start; i \u0026lt;= end; i++) { if (preIndex.get(in[i]) \u0026lt; preIndex.get(in[indexOfRoot])) { indexOfRoot = i; } } TreeNode root = new TreeNode(in[indexOfRoot]); if (start \u0026lt;= indexOfRoot - 1) root.left = buildTree(preIndex, in, start, indexOfRoot - 1); if (indexOfRoot + 1 \u0026lt;= end) root.right = buildTree(preIndex, in, indexOfRoot + 1, end); return root; } "});index.add({'id':191,'href':'/interview/docs/offer/FindKthToTail/','title':"链表中倒数第",'content':"题目 牛客网\n输入一个链表，输出该链表中倒数第k个结点。\n解题思路  两个指针，快指针先走 k 步，然后慢指针在向前移动，当快指针遍历结束，慢指针指向倒数第 k 个节点 需要考虑倒数 k 个节点不存在的情况  public ListNode FindKthToTail(ListNode head, int k) { if (head == null) { return null; } ListNode cursor = head; ListNode cursorK = head; int i = 0; while (cursorK != null) { cursorK = cursorK.next; if (i \u0026gt;= k) { cursor = cursor.next; } i++; } if (i \u0026lt; k) { return null; } return cursor; } "});index.add({'id':192,'href':'/interview/docs/offer/EntryNodeOfLoop/','title':"链表中环的入口结点",'content':"题目 给一个链表，若其中包含环，请找出该链表的环的入口结点，否则，输出null。\n解题思路  首先通过 快慢指针（快：每次走两步；慢：每次走一步）确定是否有环 当有环时，再从头节点出发，与快指针按 相同速度 向前移动，当 cursor = fast 则找到环入口  public ListNode EntryNodeOfLoop(ListNode pHead) { if (pHead == null || pHead.next == null) return null; ListNode fast = pHead, slow = pHead; while (fast.next != null) { slow = slow.next; fast = fast.next.next; if (fast == slow) break; } if (fast != slow) return null; ListNode cursor = pHead; while (cursor != fast) { cursor = cursor.next; fast = fast.next; } return cursor; } "});index.add({'id':193,'href':'/interview/docs/offer/mirror-tree/','title':"镜像二叉树",'content':"题目 镜像二叉树\n操作给定的二叉树，将其变换为源二叉树的镜像。\n输入描述:\n二叉树的镜像定义：源二叉树 8 / \\ 6 10 / \\ / \\ 5 7 9 11 镜像二叉树 8 / \\ 10 6 / \\ / \\ 11 9 7 5 解题思路  从上到下进行左右节点交换  public void Mirror(TreeNode root) { if (root == null) return; TreeNode temp = root.left; root.left = root.right; root.right = temp; Mirror(root.left); Mirror(root.right); } "});index.add({'id':194,'href':'/interview/docs/java/collection/','title':"集合框架",'content':"集合框架 Java集合框架提供了数据持有对象的方式，提供了对数据集合的操作。Java集合框架位于java.util包下，主要有三个大类：Collection、Map接口以及对集合进行操作的工具类。\nCollection  List  ArrayList：线程不同步。默认初始容量为10，当数组大小不足时增长率为当前长度的50%。 Vector：线程同步。默认初始容量为10，当数组大小不足时增长率为当前长度的100%。它的同步是通过Iterator方法加synchronized实现的。 Stack：线程同步。继承自Vector，添加了几个方法来完成栈的功能。 LinkedList：线程不同步。双端队列形式。   Set：Set是一种不包含重复元素的Collection，Set最多只有一个null元素。  HashSet：线程不同步，内部使用HashMap进行数据存储，提供的方法基本都是调用HashMap的方法，所以两者本质是一样的。集合元素可以为NULL。 NavigableSet：添加了搜索功能，可以对给定元素进行搜索：小于、小于等于、大于、大于等于，放回一个符合条件的最接近给定元素的 key。 TreeSet：线程不同步，内部使用NavigableMap操作。默认元素“自然顺序”排列，可以通过Comparator改变排序。 EnumSet：线程不同步。内部使用Enum数组实现，速度比HashSet快。只能存储在构造函数传入的枚举类的枚举值。    Map  HashMap：线程不同步。根据key的hashcode进行存储，内部使用静态内部类Node的数组进行存储，默认初始大小为16，每次扩大一倍。当发生Hash冲突时，采用拉链法（链表）。可以接受为null的键值(key)和值(value)。JDK 1.8中：当单个桶中元素个数大于等于8时，链表实现改为红黑树实现；当元素个数小于6时，变回链表实现。由此来防止hashCode攻击。 LinkedHashMap：保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的. 也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关。 TreeMap：线程不同步，基于 *红黑树- （Red-Black tree）的NavigableMap 实现，能够把它保存的记录根据键排序,默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。 HashTable：线程安全，HashMap的迭代器(Iterator)是fail-fast迭代器。HashTable不能存储NULL的key和value。 ConcurrentHashmap：支持并发操作的 Hash 表，ConcurrentHashmap 具有和 HashTable 同样的功能，并且具有相应的方法。即使所有操作都是线程安全的，但是并不需要进行加锁。  工具类  Collections、Arrays：集合类的一个工具类/帮助类，其中提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程安全等各种操作。 Comparable、Comparator：一般是用于对象的比较来实现排序，两者略有区别。   类设计者没有考虑到比较问题而没有实现Comparable接口。这是我们就可以通过使用Comparator，这种情况下，我们是不需要改变对象的。 一个集合中，我们可能需要有多重的排序标准，这时候如果使用Comparable就有些捉襟见肘了，可以自己继承Comparator提供多种标准的比较器进行排序。     "});index.add({'id':195,'href':'/interview/docs/java/oop/','title':"面向对象基础",'content':"面向对象基础 面向对象三要素：封装、继承、多态\n 封装：封装的意义，在于明确标识出允许外部使用的所有成员函数和数据项，或者叫接口。 继承：  继承基类的方法，并做出自己的扩展； 声明某个子类兼容于某基类（或者说，接口上完全兼容于基类），外部调用者可无需关注其差别（内部机制会自动把请求派发dispatch到合适的逻辑）。   多态：基于对象所属类的不同，外部对同一个方法的调用，实际执行的逻辑不同。很显然，多态实际上是依附于继承的第二种含义的。  多态 方法签名：方法名 + 参数列表(参数类型、个数、顺序)\n重写 子类重写父类方法，只有实例方法可以被重写，重写后的方法必须仍为实例方法。成员变量和静态方法都不能被重写，只能被隐藏。\n重写实例方法：超类Parent中有实例方法A，子类child定义了与A 相同签名和子集返回类型 的实例方法B，子类对象ChildObj只能调用自己的实例方法B。\n 方法的重写（override）两同两小一大原则：\n   方法名相同，参数类型相同    子类返回类型小于等于父类方法返回类型    子类抛出异常小于等于父类方法抛出异常    子类访问权限大于等于父类方法访问权限   注意：\n  不能重写static静态方法。(形式上可以写，但本质上不是重写，属于下面要讲的隐藏)\n  重写方法可以改变其它的方法修饰符，如final,synchronized,native。不管被重写方法中有无final修饰的参数，重写方法都可以增加、保留、去掉这个参数的 final 修饰符(参数修饰符不属于方法签名)。\n  重载 在同一个类中，有多个方法名相同，参数列表不同（参数个数不同，参数类型不同），与方法的返回值无关，与权限修饰符无关。编译器通过对方法签名的识别即可静态编译出不同的方法。这也是java中重载与重写的区别之一。\n 重载只是一种语言特性，与多态无关，与面向对象也无关。多态是为了实现接口重用。\n Java中方法是可以和类名同名的，和构造方法唯一的区别就是，构造方法没有返回值。\n隐藏 隐藏与覆盖在形式上极其类似(语法规则)，但有着本质的区别：只有成员变量(不管是不是静态)和静态方法可以被隐藏。\n成员变量 超类 Parent 中有成员变量 A ，子类 Child 定义了与 A 同名的成员变量 B ，子类对象 ChildObj 调用的是自己的成员变量 B。如果把子类对象 ChildObj 转换为超类对象 ParentObj ，ParentObj 调用的是超类的成员变量 A ！\n  隐藏成员变量时，只要同名即可，可以更改变量类型(无论基本类型还是隐藏类型)\n  不能隐藏超类中的 private 成员变量，换句话说，只能隐藏可以访问的成员变量。\n  隐藏超类成员变量 A 时，可以降低或提高子类成员变量B的访问权限，只要A不是 private。\n  隐藏成员变量与是否静态无关！静态变量可以隐藏实例变量，实例变量也可以隐藏静态变量。\n  可以隐藏超类中的final成员变量。\n  静态方法 超类 Parent 有静态方法 A ，子类 Child 定义了与 A 相同签名和子集返回类型 的静态方法 B ，子类对象 ChildObj 调用的是自己的静态方法 B 。如果把子类对象 ChildObj 转换为超类对象 ParentObj ，ParentObj 调用的是超类的静态方法 A ！\n 隐藏后的方法必须仍为静态方法\n "});index.add({'id':196,'href':'/interview/docs/fromwork/mybatis/question/','title':"面试题",'content':"面试题  #{}是预编译处理，${}是字符串替换。 Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值； Mybatis在处理${}时，就是把${}替换成变量的值。 使用#{}可以有效的防止SQL注入，提高系统安全性。 通常一个Xml映射文件，都会写一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？ Dao接口，就是人们常说的Mapper接口，接口的全限名，就是映射文件中的namespace的值，接口的方法名，就是映射文件中MappedStatement的id值，接口方法内的参数，就是传递给sql的参数。Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement。在Mybatis中，每一个\u0026lt;select\u0026gt;、\u0026lt;insert\u0026gt;、\u0026lt;update\u0026gt;、\u0026lt;delete\u0026gt;标签，都会被解析为一个MappedStatement对象。 Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。 Dao接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。 参考连接 Mybatis 的常见面试题\n"});index.add({'id':197,'href':'/interview/docs/java/questions/','title':"面试题",'content':"面试题 如何用数组实现队列？ 用数组实现队列时要注意 溢出 现象，这时我们可以采用循环数组的方式来解决，即将数组收尾相接。使用front指针指向队列首位，tail指针指向队列末位。\n 内部类访问局部变量的时候，为什么变量必须加上final修饰？ 因为生命周期不同。局部变量在方法结束后就会被销毁，但内部类对象并不一定，这样就会导致内部类引用了一个不存在的变量。\n所以编译器会在内部类中生成一个局部变量的拷贝，这个拷贝的生命周期和内部类对象相同，就不会出现上述问题。\n但这样就导致了其中一个变量被修改，两个变量值可能不同的问题。为了解决这个问题，编译器就要求局部变量需要被final修饰，以保证两个变量值相同。\n在JDK8之后，编译器不要求内部类访问的局部变量必须被final修饰，但局部变量值不能被修改（无论是方法中还是内部类中），否则会报编译错误。利用javap查看编译后的字节码可以发现，编译器已经加上了final。\n long s = 499999999 * 499999999 在上面的代码中，s的值是多少？ 根据代码的计算结果，s的值应该是-1371654655，这是由于Java中右侧值的计算默认是int类型。\n NIO相关，Channels、Buffers、Selectors NIO(Non-blocking IO)为所有的原始类型提供(Buffer)缓存支持，字符集编码解码解决方案。 Channel ：一个新的原始I/O 抽象。 支持锁和内存映射文件的文件访问接口。提供多路(non-bloking) 非阻塞式的高伸缩性网络I/O 。\n   IO NIO     面向流 面向缓冲   阻塞IO 非阻塞IO   无 选择器    流与缓冲 Java NIO和IO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。\nJava NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。\n阻塞与非阻塞IO Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 Java NIO的非阻塞模式，是线程向某通道发送请求读取数据，仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，当然它不会保持线程阻塞。所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。所以一个单独的线程现在可以管理多个输入和输出通道。\n选择器（Selectors） Java NIO 的 选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。\n 反射的用途 Java反射机制可以让我们在编译期(Compile Time)之外的运行期(Runtime)检查类，接口，变量以及方法的信息。反射还可以让我们在运行期实例化对象，调用方法，通过调用get/set方法获取变量的值。同时我们也可以通过反射来获取泛型信息，以及注解。还有更高级的应用\u0026ndash;动态代理和动态类加载（ClassLoader.loadclass()）。\n下面列举一些比较重要的方法：\n getFields：获取所有 public 的变量。 getDeclaredFields：获取所有包括 private , protected 权限的变量。 setAccessible：设置为 true 可以跳过Java权限检查，从而访问private权限的变量。 getAnnotations：获取注解，可以用在类和方法上。  获取方法的泛型参数：\nmethod = Myclass.class.getMethod(\u0026quot;setStringList\u0026quot;, List.class); Type[] genericParameterTypes = method.getGenericParameterTypes(); for(Type genericParameterType : genericParameterTypes){ if(genericParameterType instanceof ParameterizedType){ ParameterizedType aType = (ParameterizedType) genericParameterType; Type[] parameterArgTypes = aType.getActualTypeArguments(); for(Type parameterArgType : parameterArgTypes){ Class parameterArgClass = (Class) parameterArgType; System.out.println(\u0026quot;parameterArgClass = \u0026quot; + parameterArgClass); } } } 动态代理：\n//Main.java public static void main(String[] args) { HelloWorld helloWorld=new HelloWorldImpl(); InvocationHandler handler=new HelloWorldHandler(helloWorld); //创建动态代理对象 HelloWorld proxy=(HelloWorld)Proxy.newProxyInstance( helloWorld.getClass().getClassLoader(), helloWorld.getClass().getInterfaces(), handler); proxy.sayHelloWorld(); } //HelloWorldHandler.java public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object result = null; //调用之前 doBefore(); //调用原始对象的方法 result=method.invoke(obj, args); //调用之后 doAfter(); return result; } 通过反射获取方法注解的参数：\nClass aClass = TheClass.class; Annotation[] annotations = aClass.getAnnotations(); for(Annotation annotation : annotations){ if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\u0026quot;name: \u0026quot; + myAnnotation.name()); System.out.println(\u0026quot;value: \u0026quot; + myAnnotation.value()); } }   非静态内部类能定义静态方法吗？ public class OuterClass{ private static float f = 1.0f; class InnerClass{ public static float func(){return f;} } } 以上代码会出现编译错误，因为只有静态内部类才能定义静态方法。\n Lock 和 Synchronized 有什么区别？  使用方法的区别  - **Synchronized**：在需要同步的对象中加入此控制，`synchronized`可以加在方法上，也可以加在特定代码块中，括号中表示需要锁的对象。 - **Lock**：需要显示指定起始位置和终止位置。一般使用`ReentrantLock`类做为锁，多个线程中必须要使用一个`ReentrantLock`类做为对象才能保证锁的生效。且在加锁和解锁处需要通过`lock()`和`unlock()`显示指出。所以一般会在`finally`块中写`unlock()`以防死锁。  性能的区别  `synchronized`是托管给JVM执行的，而`lock`是java写的控制锁的代码。在Java1.5中，`synchronize`是性能低效的。因为这是一个重量级操作，需要调用操作接口，导致有可能加锁消耗的系统时间比加锁以外的操作还多。相比之下使用Java提供的Lock对象，性能更高一些。但是到了Java1.6，发生了变化。`synchronize`在语义上很清晰，可以进行很多优化，有适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在Java1.6上`synchronize`的性能并不比Lock差。 - **Synchronized**：采用的是CPU悲观锁机制，即线程获得的是独占锁。独占锁意味着 **其他线程只能依靠阻塞来等待线程释放锁**。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。 - **Lock**：用的是乐观锁方式。所谓乐观锁就是，**每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止**。乐观锁实现的机制就是`CAS`操作。我们可以进一步研究`ReentrantLock`的源代码，会发现其中比较重要的获得锁的一个方法是`compareAndSetState`。这里其实就是调用的CPU提供的特殊指令。  ReentrantLock：具有更好的可伸缩性：比如时间锁等候、可中断锁等候、无块结构锁、多个条件变量或者锁投票。   float 变量如何与 0 比较？ folat类型的还有double类型的，这些小数类型在趋近于0的时候直接等于0的可能性很小，一般都是无限趋近于0，因此不能用==来判断。应该用|x-0|\u0026lt;err来判断，这里|x-0|表示绝对值，err表示限定误差。\n//用程序表示就是 fabs(x) \u0026lt; 0.00001f  如何新建非静态内部类？ 内部类在声明的时候必须是 Outer.Inner a，就像int a 一样，至于静态内部类和非静态内部类new的时候有点区别：\n Outer.Inner a = new Outer().new Inner()（非静态，先有Outer对象才能 new 内部类） Outer.Inner a = new Outer.Inner()（静态内部类）   Java标识符命名规则 可以包含：字母、数字、$、_(下划线)，不可用数字开头，不能是 Java 的关键字和保留字。\n 你知道哪些JDK中用到的设计模式？   装饰模式：java.io\n  单例模式：Runtime类\n  简单工厂模式：Integer.valueOf方法\n  享元模式：String常量池、Integer.valueOf(int i)、Character.valueOf(char c)\n  迭代器模式：Iterator\n  职责链模式：ClassLoader的双亲委派模型\n  解释器模式：正则表达式java.util.regex.Pattern\n   ConcurrentHashMap如何保证线程安全 JDK 1.7及以前：\nConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同部分进行的修改。ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hash table，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就可以并发进行。\nJDK 1.8：\nSegment虽保留，但已经简化属性，仅仅是为了兼容旧版本。\n插入时使用CAS算法：unsafe.compareAndSwapInt(this, valueOffset, expect, update)。 CAS(Compare And Swap)意思是如果valueOffset位置包含的值与expect值相同，则更新valueOffset位置的值为update，并返回true，否则不更新，返回false。插入时不允许key或value为null\n与Java8的HashMap有相通之处，底层依然由“数组”+链表+红黑树；\n底层结构存放的是TreeBin对象，而不是TreeNode对象；\nCAS作为知名无锁算法，那ConcurrentHashMap就没用锁了么？当然不是，当hash值与链表的头结点相同还是会synchronized上锁，锁链表。\n i++在多线程环境下是否存在问题，怎么解决？ 虽然递增操作++i是一种紧凑的语法，使其看上去只是一个操作，但这个操作并非原子的，因而它并不会作为一个不可分割的操作来执行。实际上，它包含了三个独立的操作：读取count的值，将值加1，然后将计算结果写入count。这是一个“读取 - 修改 - 写入”的操作序列，并且其结果状态依赖于之前的状态。所以在多线程环境下存在问题。\n要解决自增操作在多线程环境下线程不安全的问题，可以选择使用Java提供的原子类，如AtomicInteger或者使用synchronized同步方法。\n new与newInstance()的区别   new是一个关键字，它是调用new指令创建一个对象，然后调用构造方法来初始化这个对象，可以使用带参数的构造器\n  newInstance()是Class的一个方法，在这个过程中，是先取了这个类的不带参数的构造器Constructor，然后调用构造器的newInstance方法来创建对象。\n   Class.newInstance不能带参数，如果要带参数需要取得对应的构造器，然后调用该构造器的Constructor.newInstance(Object \u0026hellip; initargs)方法\n  你了解哪些JDK1.8的新特性？   接口的默认方法和静态方法，JDK8允许我们给接口添加一个非抽象的方法实现，只需要使用default关键字即可。也可以定义被static修饰的静态方法。\n  对HashMap进行了改进，当单个桶的元素个数大于6时就会将实现改为红黑树实现，以避免构造重复的hashCode的攻击\n  多并发进行了优化。如ConcurrentHashMap实现由分段加锁、锁分离改为CAS实现。\n  JDK8拓宽了注解的应用场景，注解几乎可以使用在任何元素上，并且允许在同一个地方多次使用同一个注解\n  Lambda表达式\n   你用过哪些JVM参数？   Xms 堆最小值\n  Xmx 堆最大值\n  Xmn: 新生代容量\n  XX:SurvivorRatio 新生代中Eden与Surivor空间比例\n  Xss 栈容量\n  XX:PermSize 方法区初始容量\n  XX:MaxPermSize 方法区最大容量\n  XX:+PrintGCDetails 收集器日志参数\n   如何打破 ClassLoader 双亲委托？ 重写loadClass()方法。\n hashCode() \u0026amp;\u0026amp; equals() hashcode() 返回该对象的哈希码值，支持该方法是为哈希表提供一些优点，例如，java.util.Hashtable 提供的哈希表。\n在 Java 应用程序执行期间，在同一对象上多次调用 hashCode 方法时，必须一致地返回相同的整数，前提是对象上 equals 比较中所用的信息没有被修改（equals默认返回对象地址是否相等）。如果根据 equals(Object) 方法，两个对象是相等的，那么在两个对象中的每个对象上调用 hashCode 方法都必须生成相同的整数结果。\n以下情况不是必需的：如果根据 equals(java.lang.Object) 方法，两个对象不相等，那么在两个对象中的任一对象上调用 hashCode 方法必定会生成不同的整数结果。但是，程序员应该知道，为不相等的对象生成不同整数结果可以提高哈希表的性能。\n实际上，由 Object 类定义的 hashCode 方法确实会针对不同的对象返回不同的整数。（这一般是通过将该对象的内部地址转换成一个整数来实现的，但是 JavaTM 编程语言不需要这种实现技巧I。）\n  hashCode的存在主要是用于查找的快捷性，如 Hashtable，HashMap等，hashCode 是用来在散列存储结构中确定对象的存储地址的；\n  如果两个对象相同，就是适用于 equals(java.lang.Object) 方法，那么这两个对象的 hashCode 一定要相同；\n  如果对象的 equals 方法被重写，那么对象的 hashCode 也尽量重写，并且产生 hashCode 使用的对象，一定要和 equals 方法中使用的一致，否则就会违反上面提到的第2点；\n  两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里”。\n   Thread.sleep() \u0026amp; Thread.yield() sleep()和yield()都会释放CPU。\nsleep()使当前线程进入停滞状态，所以执行sleep()的线程在指定的时间内肯定不会执行；yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。\nsleep()可使优先级低的线程得到执行的机会，当然也可以让同优先级和高优先级的线程有执行的机会；yield()只能使同优先级的线程有执行的机会。\n"});index.add({'id':198,'href':'/interview/docs/offer/PrintMatrix/','title':"顺时针打印矩阵",'content':"题目 [](https://www.nowcoder.com/practice/9b4c81a02cd34f76be2659fa0d54342a?tpId=13\u0026amp;tqId=11172\u0026amp;rp=1\u0026amp;ru=%2Fta%2Fcoding-interviews\u0026amp;qru=%2Fta%2Fcoding-interviews%2Fquestion-ranking\u0026amp;tPage=1)\n输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10.\n解题思路  通过4个指针，表示可打印区域，并对区域进行收缩 非 n*n 的矩阵，对于剩余非 4 边遍历的元素，要考虑边界  public ArrayList\u0026lt;Integer\u0026gt; printMatrix(int[][] matrix) { ArrayList\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); if (matrix.length == 0) { return res; } if (matrix.length == 1) { for (int i : matrix[0]) { res.add(i); } return res; } int top = 0, bottom = matrix.length - 1, left = 0, right = matrix[0].length - 1; for (; left \u0026lt;= right \u0026amp;\u0026amp; top \u0026lt;= bottom; ) { if (top == bottom) { for (int i = left; i \u0026lt;= right; i++) { res.add(matrix[top][i]); } break; } if (left == right) { for (int i = top; i \u0026lt;= bottom; i++) { res.add(matrix[i][left]); } break; } for (int p = left; p \u0026lt;= right; p++) { res.add(matrix[top][p]); } top++; for (int p = top; p \u0026lt;= bottom; p++) { res.add(matrix[p][right]); } right--; for (int p = right; p \u0026gt;= left; p--) { res.add(matrix[bottom][p]); } bottom--; for (int p = bottom; p \u0026gt;= top; p--) { res.add(matrix[p][left]); } left++; } return res; } "});index.add({'id':199,'href':'/interview/docs/offer/power/','title':"题目",'content':"牛客网\n给定一个 double 类型的浮点数 base 和 int 类型的整数 exponent 。求 base 的 exponent 次方。\n解题思路  当 n 为偶数时，   \\(a^n = a^{n/2} * a^{n/2}\\)   当 n 为奇数时， \\(a^n = a^{n/2} * a^{n/2} * a\\)   可以利用类似斐波纳切的方式，利用递归来进行求解  public double Power(double base, int exponent) { if (base == 0) { return 0; } if (base == 1) { return 1; } int t_exponent = Math.abs(exponent); double t = PositivePower(base, t_exponent); return exponent \u0026gt; 0 ? t : 1 / t; } private double PositivePower(double base, int exponent) { if (exponent == 0) { return 1; } if (exponent == 1) { return base; } double t = PositivePower(base, exponent \u0026gt;\u0026gt; 1); t *= t; if ((exponent \u0026amp; 0x01) == 1) { t *= base; } return t; } "});index.add({'id':200,'href':'/interview/docs/architecture/concurrent/flow-control/','title':"高并发下的流量控制",'content':"高并发下的流量控制 这个时候如果不做任何保护措施，服务器就会承受很大的处理压力，请求量很高，服务器负载也很高，并且当请求超过服务器承载极限的时候，系统就会崩溃，导致所有人都不能访问。\n为了应用服务的高可用，一个常用的办法是对大流量的请求（秒杀/抢购）进行限流，拦截掉大部分请求，只允许一部分请求真正进入后端服务器，这样就可以防止大量请求造成系统压力过大导致的系统崩溃，从而保护服务正常可用。\n令牌桶(Token Bucket)、漏桶(leaky bucket)和 计数器 算法是最常用的三种限流的算法。\n限流算法 计数器 计数器限流算法也是比较常用的，主要用来限制总并发数。比如限流 qps 为 100 ，算法的实现思路就是从第一个请求进来开始计时，在接下去的 1s 内，每来一个请求，就把计数加 1 ，如果累加的数字达到了 100 ，那么后续的请求就会被全部拒绝。等到 1s 结束后，把计数恢复成 0 ，重新开始计数。\n这种实现方式有一个弊端：如果我在单位时间 1s 内的前 10ms ，已经通过了 100 个请求，那后面的 990ms ，只能眼巴巴的把请求拒绝，这种现象称为 突刺现象。\n漏桶 为了消除 突刺现象，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。\n不管服务调用方多么不稳定，通过漏桶算法进行限流，每 10 毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。\n在算法实现方面，可以 准备一个队列，用来保存请求，另外通过一个线程池定期从队列中获取请求并执行，可以一次性获取多个并发执行。\n这种算法，在使用过后也存在弊端：无法应对短时间的突发流量，同时它的优点也是可以平滑网络上的突发流量，请求可以被整形成稳定的流量。\n令牌桶 从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。\n在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。\n放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置 qps 为 100 ，那么限流器初始化完成一秒后，桶中就已经有 100 个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的 100 个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。\n实现思路：可以 准备一个队列，用来保存令牌，另外通过一个线程池定期生成令牌放到队列中，每来一个请求，就从队列中获取一个令牌，并继续执行。\n 漏桶 VS 令牌桶：两者主要区别在于“漏桶算法”能够强行限制数据的传输速率，而“令牌桶算法”在能够限制数据的平均传输速率外，还允许某种程度的突发传输。在“令牌桶算法”中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，所以它适合于具有突发特性的流量。\n 集群限流 Redis 请求窗口  采用redis 的计时和计数方式,在规定的时间窗口期,允许通过的最大请求数量\n 比如为了限制某个资源被每个用户或者商户的访问次数，5s 只能访问 2 次，或者一天只能调用 1000 次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。\n如何实现？为了控制访问次数，肯定需要一个计数器，而且这个计数器只能保存在第三方服务，比如redis。\n大概思路：每次有相关操作的时候，就向 redis 服务器发送一个 incr 命令，比如需要限制某个用户访问 /index 接口的次数，只需要拼接用户 id 和接口名生成 redis 的 key ，每次该用户访问此接口时，只需要对这个 key 执行 incr 命令，在这个 key 带上过期时间，就可以实现指定时间的访问频率。\nNginx 限流 Nginx按请求速率限速模块使用的是漏桶算法，即能够强行保证请求的实时处理速度不会超过设置的阈值。\nNginx官方版本限制IP的连接和并发分别有两个模块：\n limit_req_zone 用来限制单位时间内的请求数，即速率限制,采用的漏桶算法 \u0026ldquo;leaky bucket\u0026rdquo;。 limit_req_conn 用来限制同一时间连接数，即并发限制。  "});index.add({'id':201,'href':'/interview/docs/basic/os/questions/','title':"Index",'content':"面试题 PE文件 PE文件的全称是Portable Executable，意为可移植的可执行的文件，常见的EXE、DLL、OCX、SYS、COM都是PE文件，PE文件是微软Windows操作系统上的程序文件（可能是间接被执行，如DLL）。\n 什么是活锁？与死锁有和区别？ 活锁指的是 任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。 活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。\n活锁应该是一系列进程在轮询地等待某个不可能为真的条件为真。活锁的时候进程是不会blocked，这会导致耗尽CPU资源。\n为解决活锁可以引入一些随机性，例如如果检测到冲突，那么就暂停随机的一定时间进行重试。这回大大减少碰撞的可能性。典型的例子是以太网的CSMA/CD检测机制。\n 直接寻址与间接寻址？ 寻址方式就是处理器根据指令中给出的地址信息来寻找物理地址的方式，是确定本条指令的数据地址以及下一条要执行的指令地址的方法。在操作系统中分为指令寻址和操作数寻址。\n指令寻址：在内存中查找指令的方式。\n 顺序寻址方式：即采用PC计数器来计数指令的顺序； 跳跃寻址方式：下条指令的地址码不是由程序计数器给出，而是由本条指令给出。  操作数寻址：形成操作数的有效地址的方法称为操作数的寻址方式。\n 立即寻址：操作数作为指令的一部分而直接写在指令中； 直接寻址：直接寻址是一种基本的寻址方法。在指令格式的地址的字段中直接指出操作数在内存的地址。由于操作数的地址直接给出而不需要经过某种变换，所以称这种寻址方式为直接寻址方式。 简介寻址：间接寻址是相对直接寻址而言的，在间接寻址的情况下，指令地址字段中的形式地址不是操作数的真正地址，而是操作数地址的指示器，或者说此形式地址单元的内容才是操作数的有效地址。   如何从用户态切换到内核态？  程序请求系统服务，执行系统调用 程序运行期间产生中断事件，运行程序被中断，转向中断处理程序处理 程序运行时产生异常事件，运行程序被打断，转向异常处理程序。  这三种情况都是通过中断机制发生，可以说 中断和异常是用户态到内核态转换的仅有途径。\n 实时操作系统和分时操作系统的区别？  分时操作系统：多个联机用户同时适用一个计算机系统在各自终端上进行交互式会话，程序、数据和命令均在会话过程中提供，以问答方式控制程序运行。系统把处理器的时间划分为时间片轮流分配给各个连接终端。 实时操作系统：当外部时间或数据产生时，能够对其予以接受并以足够快的速度进行处理，所得结果能够在规定时间内控制生产过程或对控制对象作出快速响应，并控制所有实时任务协调的操作系统。因而，提供及时响应和高可靠性是其主要特点。实时操作系统有硬实时和软实时之分，硬实时要求在规定的时间内必须完成操作，这是在操作系统设计时保证的；软实时则只要按照任务的优先级，尽可能快地完成操作即可。我们通常使用的操作系统在经过一定改变之后就可以变成实时操作系统。  下面还要补充一个批处理操作系统：批处理是指用户将一批作业提交给操作系统后就不再干预，由操作系统控制它们自动运行。这种采用批量处理作业技术的操作系统称为批处理操作系统。批处理操作系统分为单道批处理系统和多道批处理系统。批处理操作系统不具有交互性，它是为了提高CPU的利用率而提出的一种操作系统。\n如果某个操作系统兼有批处理、分时和实时处理的全部或两种功能，我们称为通用操作系统。\n"});index.add({'id':202,'href':'/interview/docs/leetcode/zigzagLevelOrder/','title':"Index",'content':""});index.add({'id':203,'href':'/interview/docs/','title':"Docs",'content':""});index.add({'id':204,'href':'/interview/','title':"Introduction",'content':"Summary 本文档收集整理 计算机、Java 相关基础知识，有问题欢迎提 issue 👏\n页面生成工具：Hugo\n主题：hugo-book\n预览地址：Interview\n"});})();